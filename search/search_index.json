{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"CWL guide for Earth Observation This is a guide for learning how to use the Common Workflow Language in the Earth Observation domain. This guide provides a light introduction to: The Common Workflow Language , an open standard for describing command-line tool based workflows Containers as these provide a self-contained environment to run tools (e.g. GDAL, SNAP or OTB) YAML ( Y AML A in't M arkup L anguage) a human-readable data-serialization language used to create CWL documents and their parameters file SpatioTemporal Asset Catalog (STAC) as a specification to abstract the EO acquisition's files (data or metadata) and ease the access to bands or manifests This guide includes: a set of tutorials for learning how to use CWL with Earth Observation. a number of How-to guides showing how typical EO Earth Observation use cases are implemented with CWL a reference section with pointers to the CWL open standards a section with explanations of the concepts used. This guide leads EO application developers to learn how to create OGC Application Packages using CWL and STAC according to OGC's Best Practices for Earth Observation Application Packages.","title":"Introduction"},{"location":"#cwl-guide-for-earth-observation","text":"This is a guide for learning how to use the Common Workflow Language in the Earth Observation domain. This guide provides a light introduction to: The Common Workflow Language , an open standard for describing command-line tool based workflows Containers as these provide a self-contained environment to run tools (e.g. GDAL, SNAP or OTB) YAML ( Y AML A in't M arkup L anguage) a human-readable data-serialization language used to create CWL documents and their parameters file SpatioTemporal Asset Catalog (STAC) as a specification to abstract the EO acquisition's files (data or metadata) and ease the access to bands or manifests This guide includes: a set of tutorials for learning how to use CWL with Earth Observation. a number of How-to guides showing how typical EO Earth Observation use cases are implemented with CWL a reference section with pointers to the CWL open standards a section with explanations of the concepts used. This guide leads EO application developers to learn how to create OGC Application Packages using CWL and STAC according to OGC's Best Practices for Earth Observation Application Packages.","title":"CWL guide for Earth Observation"},{"location":"requirements/","text":"Requirements to run the examples in the guide To learn how to use CWL in the Earth Observation context, you'll need two tools: A CWL runner Docker CWL runner CWL is a set of open standards for describing computational workflows. These workflows are executed using a CWL runner and there are several implementations of such runners. We recommend cwltool and one of the easiest way to install it is to use micromamba and install cwltool in the base environment. Linux Install micromamba wget -qO- https://micromamba.snakepit.net/api/micromamba/linux-64/latest | tar -xvj bin/micromamba --strip-components=1 sudo mv bin/micromamba /usr/local/bin/micromamba sudo chmod +x /usr/local/bin/micromamba Initialize the shell: micromamba shell init -s bash -p ~/micromamba source ~/.bashrc Install cwltool micromamba activate micromamba install -c conda-forge cwltool Test the installation with: which cwltool This must return the path to the cwltool executable. MacOS X Install micromamba : curl -Ls https://micromamba.snakepit.net/api/micromamba/osx-64/latest | tar -xvj bin/micromamba sudo mv bin/micromamba /usr/local/bin/micromamba sudo chmod +x /usr/local/bin/micromamba Initialize the shell with: micromamba shell init -s zsh -p ~/micromamba source ~/.zshrc Activate micromamba and install cwltool in the base environment: micromamba activate micromamba install -c conda-forge cwltool Windows TBW. Test the CWL runner installation with: cwltool --help This must return the path to the cwltool executable. Docker Linux For Linux users, check how to install docker here: https://docs.docker.com/engine/install/#server. Mac OS X Install Docker Desktop following the instructions found in https://docs.docker.com/desktop/mac/install/. Windows 10 Pro Install Docker Desktop following the instructions found in https://docs.docker.com/desktop/windows/install/. Testing your docker installation Test your installation in a terminal with: $ docker run hello-world After the container image pull, this returns: Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ $ docker images hello-world This outputs: REPOSITORY TAG IMAGE ID SIZE hello-world latest d1165f221234 13336 References cwltool software repository: https://github.com/common-workflow-language/cwltool docker installation: https://docs.docker.com/engine/install/","title":"Requirements"},{"location":"requirements/#requirements-to-run-the-examples-in-the-guide","text":"To learn how to use CWL in the Earth Observation context, you'll need two tools: A CWL runner Docker","title":"Requirements to run the examples in the guide"},{"location":"requirements/#cwl-runner","text":"CWL is a set of open standards for describing computational workflows. These workflows are executed using a CWL runner and there are several implementations of such runners. We recommend cwltool and one of the easiest way to install it is to use micromamba and install cwltool in the base environment.","title":"CWL runner"},{"location":"requirements/#linux","text":"Install micromamba wget -qO- https://micromamba.snakepit.net/api/micromamba/linux-64/latest | tar -xvj bin/micromamba --strip-components=1 sudo mv bin/micromamba /usr/local/bin/micromamba sudo chmod +x /usr/local/bin/micromamba Initialize the shell: micromamba shell init -s bash -p ~/micromamba source ~/.bashrc Install cwltool micromamba activate micromamba install -c conda-forge cwltool Test the installation with: which cwltool This must return the path to the cwltool executable.","title":"Linux"},{"location":"requirements/#macos-x","text":"Install micromamba : curl -Ls https://micromamba.snakepit.net/api/micromamba/osx-64/latest | tar -xvj bin/micromamba sudo mv bin/micromamba /usr/local/bin/micromamba sudo chmod +x /usr/local/bin/micromamba Initialize the shell with: micromamba shell init -s zsh -p ~/micromamba source ~/.zshrc Activate micromamba and install cwltool in the base environment: micromamba activate micromamba install -c conda-forge cwltool","title":"MacOS X"},{"location":"requirements/#windows","text":"TBW.","title":"Windows"},{"location":"requirements/#test-the-cwl-runner-installation-with","text":"cwltool --help This must return the path to the cwltool executable.","title":"Test the CWL runner installation with:"},{"location":"requirements/#docker","text":"","title":"Docker"},{"location":"requirements/#linux_1","text":"For Linux users, check how to install docker here: https://docs.docker.com/engine/install/#server.","title":"Linux"},{"location":"requirements/#mac-os-x","text":"Install Docker Desktop following the instructions found in https://docs.docker.com/desktop/mac/install/.","title":"Mac OS X"},{"location":"requirements/#windows-10-pro","text":"Install Docker Desktop following the instructions found in https://docs.docker.com/desktop/windows/install/.","title":"Windows 10 Pro"},{"location":"requirements/#testing-your-docker-installation","text":"Test your installation in a terminal with: $ docker run hello-world After the container image pull, this returns: Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ $ docker images hello-world This outputs: REPOSITORY TAG IMAGE ID SIZE hello-world latest d1165f221234 13336","title":"Testing your docker installation"},{"location":"requirements/#references","text":"cwltool software repository: https://github.com/common-workflow-language/cwltool docker installation: https://docs.docker.com/engine/install/","title":"References"},{"location":"101/about/","text":"About the 101 section 101 (pronounced \"one-oh-one\") is a topic for beginners in any area. It has all the basic principles and concepts that are expected in a particular field. To fully grasp the power of CWL combined with EO tools and toolboxes, there a few concepts that should be well understood. These are: Containers : we use containers to run the EO tools and toolboxes. This ensures the portability of the CWL documents created and reduces the tools installation friction YAML : the YAML ( Y AML A in't M arkup L anguage) is extensivly used to create CWL documents and associated parameters files. CWL : the Common Workflow Language is the main goal of this guide. The CWL 101 provides the basic concepts used in this guide.","title":"About the 101 section"},{"location":"101/about/#about-the-101-section","text":"101 (pronounced \"one-oh-one\") is a topic for beginners in any area. It has all the basic principles and concepts that are expected in a particular field. To fully grasp the power of CWL combined with EO tools and toolboxes, there a few concepts that should be well understood. These are: Containers : we use containers to run the EO tools and toolboxes. This ensures the portability of the CWL documents created and reduces the tools installation friction YAML : the YAML ( Y AML A in't M arkup L anguage) is extensivly used to create CWL documents and associated parameters files. CWL : the Common Workflow Language is the main goal of this guide. The CWL 101 provides the basic concepts used in this guide.","title":"About the 101 section"},{"location":"101/containers/","text":"Containers 101 Why are containers needed? The numerous dependencies and compatibilities between tools, librairies, dependencies, OS may lead to the problem known as the matrix from hell : the development or runtime stack required to build or run an end-to-end application. Containers provide a solution for the problem known as the matrix from hell : the development or runtime stack required to build or run an end-to-end application and ease the creation of the environments. What containers can do Containers simplify software installation by providing a complete known-good runtime for software and its dependencies. Containers allow running each tool with its own dependencies in separate and isolated containers. What are containers Containers share the kernel: linux host can run linux based containers. To run a linux container on Windows, Windows runs a container on linux virtual machine running under the hood. Containers vs Images An Image is a template, containers are instantiations of an image.","title":"Containers 101"},{"location":"101/containers/#containers-101","text":"","title":"Containers 101"},{"location":"101/containers/#why-are-containers-needed","text":"The numerous dependencies and compatibilities between tools, librairies, dependencies, OS may lead to the problem known as the matrix from hell : the development or runtime stack required to build or run an end-to-end application. Containers provide a solution for the problem known as the matrix from hell : the development or runtime stack required to build or run an end-to-end application and ease the creation of the environments.","title":"Why are containers needed?"},{"location":"101/containers/#what-containers-can-do","text":"Containers simplify software installation by providing a complete known-good runtime for software and its dependencies. Containers allow running each tool with its own dependencies in separate and isolated containers.","title":"What containers can do"},{"location":"101/containers/#what-are-containers","text":"Containers share the kernel: linux host can run linux based containers. To run a linux container on Windows, Windows runs a container on linux virtual machine running under the hood.","title":"What are containers"},{"location":"101/containers/#containers-vs-images","text":"An Image is a template, containers are instantiations of an image.","title":"Containers vs Images"},{"location":"101/gdal/","text":"GDAL 101","title":"GDAL 101"},{"location":"101/gdal/#gdal-101","text":"","title":"GDAL 101"},{"location":"101/orfeo-toolbox/","text":"Orfeo Toolbox 101","title":"Orfeo Toolbox 101"},{"location":"101/orfeo-toolbox/#orfeo-toolbox-101","text":"","title":"Orfeo Toolbox 101"},{"location":"101/snap/","text":"SNAP 101 Graph Processing Framework The SNAP architecture provides a flexible Graph Processing Framework (GPF) allowing the creation of processing graphs for batch processing and customized processing chains. A graph is a set of nodes connected by edges. In this case, the nodes are the processing steps called operators. The edges will show the direction in which the data is being passed between nodes; therefore it will be a directed graph. A graph can have no loops or cycles, so it will be a Directed Acyclic Graph (DAG). The sources of the graph will be the data product readers, and the sinks can be either a product writer or an image displayed. An operator can have one or more image sources and other parameters that define the operation. Two or more operators may be connected together so that the first operator becomes an image source to the next operator. By linking one operator to another, an imaging graph or processing chain can be created The graph processor will not introduce any intermediate files unless a writer is optionally added anywhere in the sequence. Graphs offer the following advantages: - no intermediate files written, no I/O overhead - reusability of processing chains - simple and comprehensive operator configuration - reusability of operator configurations SNAP EO Data Processors are implemented as GPF operators and can be invoked using the GPF Graph Processing Tool gpt which can be found in the bin directory of a SNAP installation. The following command will dump the gpt print out a short description of what the tool is for and describes the arguments and options of the tool. A list of available operators is displayed according to the toolboxes installed. docker run --rm docker.io/snap-gpt gpt -h The partial output: Usage: gpt <op>|<graph-file> [options] [<source-file-1> <source-file-2> ...] Description: This tool is used to execute SNAP raster data operators in batch-mode. The operators can be used stand-alone or combined as a directed acyclic graph (DAG). Processing graphs are represented using XML. More info about processing graphs, the operator API, and the graph XML format can be found in the SNAP documentation. Arguments: <op> Name of an operator. See below for the list of <op>s. <graph-file> Operator graph file (XML format). <source-file-i> The <i>th source product file. The actual number of source file arguments is specified by <op>. May be optional for operators which use the -S option. Options: -h Displays command usage. If <op> is given, the specific operator usage is displayed. -e Displays more detailed error messages. Displays a stack trace, if an exception occurs. -t <file> The target file. Default value is 'target.dim'. -f <format> Output file format, e.g. 'GeoTIFF', 'HDF5', 'BEAM-DIMAP'. If not specified, format will be derived from the target filename extension, if any, otherwise the default format is 'BEAM-DIMAP'. Ony used, if the graph in <graph-file> does not specify its own 'Write' operator. -p <file> A (Java Properties) file containing processing parameters in the form <name>=<value> or a XML file containing a parameter DOM for the operator. Entries in this file are overwritten by the -P<name>=<value> command-line option (see below). The following variables are substituted in the parameters file: ${system.<java-sys-property>} ${operatorName} (given by the <op> argument) ${graphFile} (given by the <graph-file> argument) ${targetFile} (pull path given by the -t option) ${targetDir} (derived from -t option) ${targetName} (derived from -t option) ${targetBaseName} (derived from -t option) ${targetFormat} (given by the -f option) -c <cache-size> Sets the tile cache size in bytes. Value can be suffixed with 'K', 'M' and 'G'. Must be less than maximum available heap space. If equal to or less than zero, tile caching will be completely disabled. The default tile cache size is '1,073,741,824M'. -q <parallelism> Sets the maximum parallelism used for the computation, i.e. the maximum number of parallel (native) threads. The default parallelism is '16'. -x Clears the internal tile cache after writing a complete row of tiles to the target product file. This option may be useful if you run into memory problems. -S<source>=<file> Defines a source product. <source> is specified by the operator or the graph. In an XML graph, all occurrences of ${<source>} will be replaced with references to a source product located at <file>. -P<name>=<value> Defines a processing parameter, <name> is specific for the used operator or graph. In an XML graph, all occurrences of ${<name>} will be replaced with <value>. Overwrites parameter values specified by the '-p' option. -D<name>=<value> Defines a system property for this invocation. -v <dir> A directory containing any number of Velocity templates. Each template generates a text output file along with the target product. This feature has been added to support a flexible generation of metadata files. See http://velocity.apache.org/ and option -m. -m <file> A (Java Properties) file containing (constant) metadata in the form <name>=<value> or any XML file. Its primary usage is to provide an additional context to be used from within the Velocity templates. See option -v. --diag Displays version and diagnostic information. Operators: Aatsr.SST Computes sea surface temperature (SST) from (A)ATSR products. AATSR.Ungrid Ungrids (A)ATSR L1B products and extracts geolocation and pixel field of view data. AdaptiveThresholding Detect ships using Constant False Alarm Rate detector. AddElevation Creates a DEM band ... Warp Create Warp Function And Get Co-registrated Images WdviOp Weighted Difference Vegetation Index retrieves the Isovegetation lines parallel to soil line. Soil line has an arbitrary slope and passes through origin Wind-Field-Estimation Estimate wind speed and direction Write Writes a data product to a file. The gpt can process individual operators or a graph of connected operators. Type: docker run --rm docker.io/snap-gpt gpt <operator-name> \u2013h to get usage information of an operator provided via <operator-name> . The usage text of an operator also displays an XML template clipping of the operators configuration when used in a graph. Example: docker run --rm docker.io/snap-gpt gpt Calibration \u2013h This outputs: Usage: gpt Calibration [options] Description: Calibration of products Source Options: -Ssource=<file> Sets source 'source' to <filepath>. This is a mandatory source. Parameter Options: -PauxFile=<string> The auxiliary file Value must be one of 'Latest Auxiliary File', 'Product Auxiliary File', 'External Auxiliary File'. Default value is 'Latest Auxiliary File'. -PcreateBetaBand=<boolean> Create beta0 virtual band Default value is 'false'. -PcreateGammaBand=<boolean> Create gamma0 virtual band Default value is 'false'. -PexternalAuxFile=<file> The antenna elevation pattern gain auxiliary data file. -PoutputBetaBand=<boolean> Output beta0 band Default value is 'false'. -PoutputGammaBand=<boolean> Output gamma0 band Default value is 'false'. -PoutputImageInComplex=<boolean> Output image in complex Default value is 'false'. -PoutputImageScaleInDb=<boolean> Output image scale Default value is 'false'. -PoutputSigmaBand=<boolean> Output sigma0 band Default value is 'true'. -PselectedPolarisations=<string,string,string,...> The list of polarisations -PsourceBands=<string,string,string,...> The list of source bands. Graph XML Format: <graph id=\"someGraphId\"> <version>1.0</version> <node id=\"someNodeId\"> <operator>Calibration</operator> <sources> <source>${source}</source> </sources> <parameters> <sourceBands>string,string,string,...</sourceBands> <auxFile>string</auxFile> <externalAuxFile>file</externalAuxFile> <outputImageInComplex>boolean</outputImageInComplex> <outputImageScaleInDb>boolean</outputImageScaleInDb> <createGammaBand>boolean</createGammaBand> <createBetaBand>boolean</createBetaBand> <selectedPolarisations>string,string,string,...</selectedPolarisations> <outputSigmaBand>boolean</outputSigmaBand> <outputGammaBand>boolean</outputGammaBand> <outputBetaBand>boolean</outputBetaBand> </parameters> </node> </graph> Calling GPT with a Graph Rather than calling each operator and specifying all its parameters, it is more convenient to pass the required settings in an XML-encoded graph file. To run gpt on a graph file type: gpt <GraphFile.xml> [options] [<source-file-1> <source-file-2> ...] Creating a Graph File The basic format of a graph XML file is: <graph id= \"someGraphId\" > <version> 1.0 </version> <node id= \"someNodeId\" > <operator> OperatorName </operator> <sources> <sourceProducts> ${sourceProducts} </sourceProducts> </sources> <parameters> .... </parameters> </node> </graph> ``` Insert variables in the form `${variableName}` in place of a parameter value. `variableName` is then replaced with a value at the command line. For example, if a parameter for a file included the variable for `${myFilename}` ```xml <parameters> <file> ${myFilename} </file> </parameters> gpt is then invoked with: gpt mygraph.xml \u2013PmyFilename=pathToMyFile Batch processing SNAP users often resort to scripts to batch process their SNAP graphs. Below two examples of such scripts: For all envisat products in folder c:\\ASAR run gpt Calibration and produce the output in the folder c:\\output for /r \"c:\\ASAR\" %%X in (*.N1) do (gpt Calibration \"%%X\" -t \"C:\\output\\%%~nX.dim\") A set of input Sentinel-2 products shall be processed with the Resample processor. #!/bin/bash # enable next line for debugging purpose # set -x ############################################ # User Configuration ############################################ # adapt this path to your needs export PATH = ~/progs/snap/bin: $PATH gptPath = \"gpt\" ############################################ # Command line handling ############################################ # first parameter is a path to the graph xml graphXmlPath = \" $1 \" # second parameter is a path to a parameter file parameterFilePath = \" $2 \" # use third parameter for path to source products sourceDirectory = \" $3 \" # use fourth parameter for path to target products targetDirectory = \" $4 \" # the fifth parameter is a file prefix for the target product name, typically indicating the type of processing targetFilePrefix = \" $5 \" ############################################ # Helper functions ############################################ removeExtension () { file = \" $1 \" echo \" $( echo \" $file \" | sed -r 's/\\.[^\\.]*$//' ) \" } ############################################ # Main processing ############################################ # Create the target directory mkdir -p \" ${ targetDirectory } \" # the d option limits the elemeents to loop over to directories. Remove it, if you want to use files. for F in $( ls -1d \" ${ sourceDirectory } \" /S2*.SAFE ) ; do sourceFile = \" $( realpath \" $F \" ) \" targetFile = \" ${ targetDirectory } / ${ targetFilePrefix } _ $( removeExtension \" $( basename ${ F } ) \" ) .dim\" ${ gptPath } ${ graphXmlPath } -e -p ${ parameterFilePath } -t ${ targetFile } ${ sourceFile } done While these are valid approaches, these scripts are not portable and hardly shareable. Jump to to learn how CWL can be used to process SNAP graphs.","title":"SNAP 101"},{"location":"101/snap/#snap-101","text":"","title":"SNAP 101"},{"location":"101/snap/#graph-processing-framework","text":"The SNAP architecture provides a flexible Graph Processing Framework (GPF) allowing the creation of processing graphs for batch processing and customized processing chains. A graph is a set of nodes connected by edges. In this case, the nodes are the processing steps called operators. The edges will show the direction in which the data is being passed between nodes; therefore it will be a directed graph. A graph can have no loops or cycles, so it will be a Directed Acyclic Graph (DAG). The sources of the graph will be the data product readers, and the sinks can be either a product writer or an image displayed. An operator can have one or more image sources and other parameters that define the operation. Two or more operators may be connected together so that the first operator becomes an image source to the next operator. By linking one operator to another, an imaging graph or processing chain can be created The graph processor will not introduce any intermediate files unless a writer is optionally added anywhere in the sequence. Graphs offer the following advantages: - no intermediate files written, no I/O overhead - reusability of processing chains - simple and comprehensive operator configuration - reusability of operator configurations SNAP EO Data Processors are implemented as GPF operators and can be invoked using the GPF Graph Processing Tool gpt which can be found in the bin directory of a SNAP installation. The following command will dump the gpt print out a short description of what the tool is for and describes the arguments and options of the tool. A list of available operators is displayed according to the toolboxes installed. docker run --rm docker.io/snap-gpt gpt -h The partial output: Usage: gpt <op>|<graph-file> [options] [<source-file-1> <source-file-2> ...] Description: This tool is used to execute SNAP raster data operators in batch-mode. The operators can be used stand-alone or combined as a directed acyclic graph (DAG). Processing graphs are represented using XML. More info about processing graphs, the operator API, and the graph XML format can be found in the SNAP documentation. Arguments: <op> Name of an operator. See below for the list of <op>s. <graph-file> Operator graph file (XML format). <source-file-i> The <i>th source product file. The actual number of source file arguments is specified by <op>. May be optional for operators which use the -S option. Options: -h Displays command usage. If <op> is given, the specific operator usage is displayed. -e Displays more detailed error messages. Displays a stack trace, if an exception occurs. -t <file> The target file. Default value is 'target.dim'. -f <format> Output file format, e.g. 'GeoTIFF', 'HDF5', 'BEAM-DIMAP'. If not specified, format will be derived from the target filename extension, if any, otherwise the default format is 'BEAM-DIMAP'. Ony used, if the graph in <graph-file> does not specify its own 'Write' operator. -p <file> A (Java Properties) file containing processing parameters in the form <name>=<value> or a XML file containing a parameter DOM for the operator. Entries in this file are overwritten by the -P<name>=<value> command-line option (see below). The following variables are substituted in the parameters file: ${system.<java-sys-property>} ${operatorName} (given by the <op> argument) ${graphFile} (given by the <graph-file> argument) ${targetFile} (pull path given by the -t option) ${targetDir} (derived from -t option) ${targetName} (derived from -t option) ${targetBaseName} (derived from -t option) ${targetFormat} (given by the -f option) -c <cache-size> Sets the tile cache size in bytes. Value can be suffixed with 'K', 'M' and 'G'. Must be less than maximum available heap space. If equal to or less than zero, tile caching will be completely disabled. The default tile cache size is '1,073,741,824M'. -q <parallelism> Sets the maximum parallelism used for the computation, i.e. the maximum number of parallel (native) threads. The default parallelism is '16'. -x Clears the internal tile cache after writing a complete row of tiles to the target product file. This option may be useful if you run into memory problems. -S<source>=<file> Defines a source product. <source> is specified by the operator or the graph. In an XML graph, all occurrences of ${<source>} will be replaced with references to a source product located at <file>. -P<name>=<value> Defines a processing parameter, <name> is specific for the used operator or graph. In an XML graph, all occurrences of ${<name>} will be replaced with <value>. Overwrites parameter values specified by the '-p' option. -D<name>=<value> Defines a system property for this invocation. -v <dir> A directory containing any number of Velocity templates. Each template generates a text output file along with the target product. This feature has been added to support a flexible generation of metadata files. See http://velocity.apache.org/ and option -m. -m <file> A (Java Properties) file containing (constant) metadata in the form <name>=<value> or any XML file. Its primary usage is to provide an additional context to be used from within the Velocity templates. See option -v. --diag Displays version and diagnostic information. Operators: Aatsr.SST Computes sea surface temperature (SST) from (A)ATSR products. AATSR.Ungrid Ungrids (A)ATSR L1B products and extracts geolocation and pixel field of view data. AdaptiveThresholding Detect ships using Constant False Alarm Rate detector. AddElevation Creates a DEM band ... Warp Create Warp Function And Get Co-registrated Images WdviOp Weighted Difference Vegetation Index retrieves the Isovegetation lines parallel to soil line. Soil line has an arbitrary slope and passes through origin Wind-Field-Estimation Estimate wind speed and direction Write Writes a data product to a file. The gpt can process individual operators or a graph of connected operators. Type: docker run --rm docker.io/snap-gpt gpt <operator-name> \u2013h to get usage information of an operator provided via <operator-name> . The usage text of an operator also displays an XML template clipping of the operators configuration when used in a graph. Example: docker run --rm docker.io/snap-gpt gpt Calibration \u2013h This outputs: Usage: gpt Calibration [options] Description: Calibration of products Source Options: -Ssource=<file> Sets source 'source' to <filepath>. This is a mandatory source. Parameter Options: -PauxFile=<string> The auxiliary file Value must be one of 'Latest Auxiliary File', 'Product Auxiliary File', 'External Auxiliary File'. Default value is 'Latest Auxiliary File'. -PcreateBetaBand=<boolean> Create beta0 virtual band Default value is 'false'. -PcreateGammaBand=<boolean> Create gamma0 virtual band Default value is 'false'. -PexternalAuxFile=<file> The antenna elevation pattern gain auxiliary data file. -PoutputBetaBand=<boolean> Output beta0 band Default value is 'false'. -PoutputGammaBand=<boolean> Output gamma0 band Default value is 'false'. -PoutputImageInComplex=<boolean> Output image in complex Default value is 'false'. -PoutputImageScaleInDb=<boolean> Output image scale Default value is 'false'. -PoutputSigmaBand=<boolean> Output sigma0 band Default value is 'true'. -PselectedPolarisations=<string,string,string,...> The list of polarisations -PsourceBands=<string,string,string,...> The list of source bands. Graph XML Format: <graph id=\"someGraphId\"> <version>1.0</version> <node id=\"someNodeId\"> <operator>Calibration</operator> <sources> <source>${source}</source> </sources> <parameters> <sourceBands>string,string,string,...</sourceBands> <auxFile>string</auxFile> <externalAuxFile>file</externalAuxFile> <outputImageInComplex>boolean</outputImageInComplex> <outputImageScaleInDb>boolean</outputImageScaleInDb> <createGammaBand>boolean</createGammaBand> <createBetaBand>boolean</createBetaBand> <selectedPolarisations>string,string,string,...</selectedPolarisations> <outputSigmaBand>boolean</outputSigmaBand> <outputGammaBand>boolean</outputGammaBand> <outputBetaBand>boolean</outputBetaBand> </parameters> </node> </graph>","title":"Graph Processing Framework"},{"location":"101/snap/#calling-gpt-with-a-graph","text":"Rather than calling each operator and specifying all its parameters, it is more convenient to pass the required settings in an XML-encoded graph file. To run gpt on a graph file type: gpt <GraphFile.xml> [options] [<source-file-1> <source-file-2> ...]","title":"Calling GPT with a Graph"},{"location":"101/snap/#creating-a-graph-file","text":"The basic format of a graph XML file is: <graph id= \"someGraphId\" > <version> 1.0 </version> <node id= \"someNodeId\" > <operator> OperatorName </operator> <sources> <sourceProducts> ${sourceProducts} </sourceProducts> </sources> <parameters> .... </parameters> </node> </graph> ``` Insert variables in the form `${variableName}` in place of a parameter value. `variableName` is then replaced with a value at the command line. For example, if a parameter for a file included the variable for `${myFilename}` ```xml <parameters> <file> ${myFilename} </file> </parameters> gpt is then invoked with: gpt mygraph.xml \u2013PmyFilename=pathToMyFile","title":"Creating a Graph File"},{"location":"101/snap/#batch-processing","text":"SNAP users often resort to scripts to batch process their SNAP graphs. Below two examples of such scripts: For all envisat products in folder c:\\ASAR run gpt Calibration and produce the output in the folder c:\\output for /r \"c:\\ASAR\" %%X in (*.N1) do (gpt Calibration \"%%X\" -t \"C:\\output\\%%~nX.dim\") A set of input Sentinel-2 products shall be processed with the Resample processor. #!/bin/bash # enable next line for debugging purpose # set -x ############################################ # User Configuration ############################################ # adapt this path to your needs export PATH = ~/progs/snap/bin: $PATH gptPath = \"gpt\" ############################################ # Command line handling ############################################ # first parameter is a path to the graph xml graphXmlPath = \" $1 \" # second parameter is a path to a parameter file parameterFilePath = \" $2 \" # use third parameter for path to source products sourceDirectory = \" $3 \" # use fourth parameter for path to target products targetDirectory = \" $4 \" # the fifth parameter is a file prefix for the target product name, typically indicating the type of processing targetFilePrefix = \" $5 \" ############################################ # Helper functions ############################################ removeExtension () { file = \" $1 \" echo \" $( echo \" $file \" | sed -r 's/\\.[^\\.]*$//' ) \" } ############################################ # Main processing ############################################ # Create the target directory mkdir -p \" ${ targetDirectory } \" # the d option limits the elemeents to loop over to directories. Remove it, if you want to use files. for F in $( ls -1d \" ${ sourceDirectory } \" /S2*.SAFE ) ; do sourceFile = \" $( realpath \" $F \" ) \" targetFile = \" ${ targetDirectory } / ${ targetFilePrefix } _ $( removeExtension \" $( basename ${ F } ) \" ) .dim\" ${ gptPath } ${ graphXmlPath } -e -p ${ parameterFilePath } -t ${ targetFile } ${ sourceFile } done While these are valid approaches, these scripts are not portable and hardly shareable. Jump to to learn how CWL can be used to process SNAP graphs.","title":"Batch processing"},{"location":"101/yaml/","text":"YAML 101 Key-Value Pairs Fundamentally, a file written in YAML consists of a set of key-value pairs . Each pair is written as key: value , where whitespace after the : is optional. Key names in CWL files should not contain whitespace - We use [ camelCase ][camelCase] for multi-word key names that have special meaning in the CWL specification and underscored key names otherwise. For example: first_name : Bilbo last_name : Baggins age_years : 111 home : Bag End, Hobbiton The YAML above defines four keys - first_name , last_name , age_years , and home - with their four respective values. Values can be character strings, numeric (integer, floating point, or scientfic representation), Boolean ( true or false ), or more complex nested types (see below). Values may be wrapped in quotation marks but be aware that this may change the way that they are interpreted i.e. \"1234\" will be treated as a character string , while 1234 will be treated as an integer. This distinction can be important, for example when describing parameters to a command: in CWL all parts of baseCommand must be strings so, if you want to specify a fixed numeric value to a command, make sure that you wrap that numeric value in quotes: baseCommand: [echo, \"42\"] . Comments You may use # to add comments to your CWL and parameter files. Any characters to the right of # will be ignored by the program interpreting the YAML. For example: first_name : Bilbo last_name : Baggins age_years : 111 # this line will be ignored by the interpreter home : Bag End, Hobbiton # this is ignored too If there is anything on the line before the comment, be sure to add at least one space before the # ! Maps When describing a tool or workflow with CWL, it is usually necessary to construct more complex, nested representations. Called maps , these hierarchical structures are described in YAML by providing additional key-value pairs as the value of any key. These pairs (sometimes referred to as \"children\") are written on new lines under the key to which they belong (the \"parent\"), and should be indented with two spaces (\u21e5tab characters are not allowed). For example: cwlVersion : v1.0 class : CommandLineTool baseCommand : echo inputs : # this key has an object value example_flag : # so does this one type : boolean inputBinding : # and this one too position : 1 prefix : -f The YAML above illustrates how you can build up complex nested object descriptions relatively quickly. The inputs map contains a single key, example_flag , which itself contains two keys, type and inputBinding , while one of these children, inputBinding , contains a further two key-value pairs ( position and prefix ). See the Arrays section below for more information about providing multiple values/key-value pairs for a single key. For comparison with the example YAML above, here is a graphical representation of the inputs object it describes. graph TD inputs --> example_flag example_flag --> type type --- bool((boolean)) example_flag --> inputBinding inputBinding --> position inputBinding --> prefix position --- posval((1)) prefix --- prefval(('-f')) Arrays In certain circumstances it is necessary to provide multiple values or objects for a single key. As we've already seen in the Maps section above, more than one key-value pair can be mapped to a single key. However, it is also possible to define multiple values for a key without having to provide a unique key for each value. We can achieve this with an array , where each value is defined on its own line and preceded by - . For example: touchfiles : - foo.txt - bar.dat - baz.txt and a more complex example combining maps and arrays: exclusive_parameters : type : - type : record name : itemC fields : itemC : type : string inputBinding : prefix : -C - type : record name : itemD fields : itemD : type : string inputBinding : prefix : -D JSON Style YAML is based on [JavaScript Object Notation (JSON)][json] and maps and arrays can also be defined in YAML using the native JSON syntax. For example: touchfiles : [ foo.txt , bar.dat , baz.txt ] # equivalent to first Arrays example and: # equivalent to the `inputs` example in \"Maps\" above inputs : { example_flag : { type : boolean , inputBinding : { position : 1 , prefix : -f }}} Native JSON can be useful to indicate where a field is being left intentionally empty (such as [] for an empty array), and where it makes more sense for the values to be located on the same line (such as when providing option flags and their values in a shell command). However, as the second example above shows, it can severely affect the readability of a YAML file and should be used sparingly. Reference This page is the same as http://www.commonwl.org/user_guide/yaml/","title":"YAML 101"},{"location":"101/yaml/#yaml-101","text":"","title":"YAML 101"},{"location":"101/yaml/#key-value-pairs","text":"Fundamentally, a file written in YAML consists of a set of key-value pairs . Each pair is written as key: value , where whitespace after the : is optional. Key names in CWL files should not contain whitespace - We use [ camelCase ][camelCase] for multi-word key names that have special meaning in the CWL specification and underscored key names otherwise. For example: first_name : Bilbo last_name : Baggins age_years : 111 home : Bag End, Hobbiton The YAML above defines four keys - first_name , last_name , age_years , and home - with their four respective values. Values can be character strings, numeric (integer, floating point, or scientfic representation), Boolean ( true or false ), or more complex nested types (see below). Values may be wrapped in quotation marks but be aware that this may change the way that they are interpreted i.e. \"1234\" will be treated as a character string , while 1234 will be treated as an integer. This distinction can be important, for example when describing parameters to a command: in CWL all parts of baseCommand must be strings so, if you want to specify a fixed numeric value to a command, make sure that you wrap that numeric value in quotes: baseCommand: [echo, \"42\"] .","title":"Key-Value Pairs"},{"location":"101/yaml/#comments","text":"You may use # to add comments to your CWL and parameter files. Any characters to the right of # will be ignored by the program interpreting the YAML. For example: first_name : Bilbo last_name : Baggins age_years : 111 # this line will be ignored by the interpreter home : Bag End, Hobbiton # this is ignored too If there is anything on the line before the comment, be sure to add at least one space before the # !","title":"Comments"},{"location":"101/yaml/#maps","text":"When describing a tool or workflow with CWL, it is usually necessary to construct more complex, nested representations. Called maps , these hierarchical structures are described in YAML by providing additional key-value pairs as the value of any key. These pairs (sometimes referred to as \"children\") are written on new lines under the key to which they belong (the \"parent\"), and should be indented with two spaces (\u21e5tab characters are not allowed). For example: cwlVersion : v1.0 class : CommandLineTool baseCommand : echo inputs : # this key has an object value example_flag : # so does this one type : boolean inputBinding : # and this one too position : 1 prefix : -f The YAML above illustrates how you can build up complex nested object descriptions relatively quickly. The inputs map contains a single key, example_flag , which itself contains two keys, type and inputBinding , while one of these children, inputBinding , contains a further two key-value pairs ( position and prefix ). See the Arrays section below for more information about providing multiple values/key-value pairs for a single key. For comparison with the example YAML above, here is a graphical representation of the inputs object it describes. graph TD inputs --> example_flag example_flag --> type type --- bool((boolean)) example_flag --> inputBinding inputBinding --> position inputBinding --> prefix position --- posval((1)) prefix --- prefval(('-f'))","title":"Maps"},{"location":"101/yaml/#arrays","text":"In certain circumstances it is necessary to provide multiple values or objects for a single key. As we've already seen in the Maps section above, more than one key-value pair can be mapped to a single key. However, it is also possible to define multiple values for a key without having to provide a unique key for each value. We can achieve this with an array , where each value is defined on its own line and preceded by - . For example: touchfiles : - foo.txt - bar.dat - baz.txt and a more complex example combining maps and arrays: exclusive_parameters : type : - type : record name : itemC fields : itemC : type : string inputBinding : prefix : -C - type : record name : itemD fields : itemD : type : string inputBinding : prefix : -D","title":"Arrays"},{"location":"101/yaml/#json-style","text":"YAML is based on [JavaScript Object Notation (JSON)][json] and maps and arrays can also be defined in YAML using the native JSON syntax. For example: touchfiles : [ foo.txt , bar.dat , baz.txt ] # equivalent to first Arrays example and: # equivalent to the `inputs` example in \"Maps\" above inputs : { example_flag : { type : boolean , inputBinding : { position : 1 , prefix : -f }}} Native JSON can be useful to indicate where a field is being left intentionally empty (such as [] for an empty array), and where it makes more sense for the values to be located on the same line (such as when providing option flags and their values in a shell command). However, as the second example above shows, it can severely affect the readability of a YAML file and should be used sparingly.","title":"JSON Style"},{"location":"101/yaml/#reference","text":"This page is the same as http://www.commonwl.org/user_guide/yaml/","title":"Reference"},{"location":"101/cwl-101/","text":"cwl-101","title":"cwl-101"},{"location":"101/cwl-101/#cwl-101","text":"","title":"cwl-101"},{"location":"101/cwl-101/cwl/","text":"CWL 101 The paper Methods Included: Standardizing Computational Reuse and Portability with the Common Workflow Language provides an excellent description of the Common Workflow Language project producing free and open standards for describing command-line tool based workflows. TL;DR Although the paper provides a clear and concise description of the CWL standards, here's a light summary wrapping up the main points to provide the required concepts behind this guide. CWL Key Insights CWL is a set of standards for describing and sharing computational workflows. The CWL standards are used daily in many science and engineering domains, including by multi-stakeholder teams. The CWL standards use a declarative syntax, facilitating polylingual workflow tasks. By being explicit about the run-time environment and any use of software containers, the CWL standards enable portability and reuse. The CWL standards provide a separation of concerns between workflow authors and workflow platforms. The CWL standards support critical workflow concepts like automation, scalability, abstraction, provenance, portability, and reusability. The CWL standards are developed around core principles of community and shared decision-making, re-use, and zero cost for participants. The CWL standards are provided as freely available open standards, supported by a diverse community in collaboration with industry, and is a Free/Open Source Software ecosystem CWL Features The CWL standard support polylingual and multi-party workflows and includes two main components: A standard for describing command line tools A standard for describing workflows that compose such tool descriptions The CWL standards define an explicit language with a textual syntax derived from YAML CWL Command Line Tool Description Standard The CWL Command Line Tool Description Standard describes: how a particular command line tool works: what are the inputs and parameters and their types how to add the correct flags and switches to the command line invocation where to find the output files CWL Workflow Description Standard The CWL Workflow Description Standard is based on the same textual syntax derived from YAML to explicit workflow level inputs, outputs and steps. Steps are comprised of CWL CommandLineTools or CWL sub-workflows, each re-exposing their tool\u2019s required inputs. Inputs for each step are connected by referencing the name of either the common workflow inputs or particular outputs of other steps. The workflow outputs expose selected outputs from workflow steps. Being CWL a set of standards, the workflows are executed using a CWL runner and there are several implementations of such runners. This guide uses the CWL runner cwltool . Recomendations Include documentation and labels for all components to enable the automatic generation of helpful visual depictions for any given CWL description Include metadata about the tool Include a Workflow class for all CommandLineTools (a single step Workflow) Organize your CWL files is several individual files to ease their readability and maintenance. Pack your multi-file CWL Workflows ( cwltool --pack ) when needed References Crusoe, M. R. et al. Methods Included: Standardizing Computational Reuse and Portability with the Common Workflow Language , retrieved from https://arxiv.org/abs/2105.07028","title":"CWL 101"},{"location":"101/cwl-101/cwl/#cwl-101","text":"The paper Methods Included: Standardizing Computational Reuse and Portability with the Common Workflow Language provides an excellent description of the Common Workflow Language project producing free and open standards for describing command-line tool based workflows.","title":"CWL 101"},{"location":"101/cwl-101/cwl/#tldr","text":"Although the paper provides a clear and concise description of the CWL standards, here's a light summary wrapping up the main points to provide the required concepts behind this guide.","title":"TL;DR"},{"location":"101/cwl-101/cwl/#cwl-key-insights","text":"CWL is a set of standards for describing and sharing computational workflows. The CWL standards are used daily in many science and engineering domains, including by multi-stakeholder teams. The CWL standards use a declarative syntax, facilitating polylingual workflow tasks. By being explicit about the run-time environment and any use of software containers, the CWL standards enable portability and reuse. The CWL standards provide a separation of concerns between workflow authors and workflow platforms. The CWL standards support critical workflow concepts like automation, scalability, abstraction, provenance, portability, and reusability. The CWL standards are developed around core principles of community and shared decision-making, re-use, and zero cost for participants. The CWL standards are provided as freely available open standards, supported by a diverse community in collaboration with industry, and is a Free/Open Source Software ecosystem","title":"CWL Key Insights"},{"location":"101/cwl-101/cwl/#cwl-features","text":"The CWL standard support polylingual and multi-party workflows and includes two main components: A standard for describing command line tools A standard for describing workflows that compose such tool descriptions The CWL standards define an explicit language with a textual syntax derived from YAML","title":"CWL Features"},{"location":"101/cwl-101/cwl/#cwl-command-line-tool-description-standard","text":"The CWL Command Line Tool Description Standard describes: how a particular command line tool works: what are the inputs and parameters and their types how to add the correct flags and switches to the command line invocation where to find the output files","title":"CWL Command Line Tool Description Standard"},{"location":"101/cwl-101/cwl/#cwl-workflow-description-standard","text":"The CWL Workflow Description Standard is based on the same textual syntax derived from YAML to explicit workflow level inputs, outputs and steps. Steps are comprised of CWL CommandLineTools or CWL sub-workflows, each re-exposing their tool\u2019s required inputs. Inputs for each step are connected by referencing the name of either the common workflow inputs or particular outputs of other steps. The workflow outputs expose selected outputs from workflow steps. Being CWL a set of standards, the workflows are executed using a CWL runner and there are several implementations of such runners. This guide uses the CWL runner cwltool .","title":"CWL Workflow Description Standard"},{"location":"101/cwl-101/cwl/#recomendations","text":"Include documentation and labels for all components to enable the automatic generation of helpful visual depictions for any given CWL description Include metadata about the tool Include a Workflow class for all CommandLineTools (a single step Workflow) Organize your CWL files is several individual files to ease their readability and maintenance. Pack your multi-file CWL Workflows ( cwltool --pack ) when needed","title":"Recomendations"},{"location":"101/cwl-101/cwl/#references","text":"Crusoe, M. R. et al. Methods Included: Standardizing Computational Reuse and Portability with the Common Workflow Language , retrieved from https://arxiv.org/abs/2105.07028","title":"References"},{"location":"101/cwl-101/tutorial-1/quickwin/","text":"QuickWin tutorial Who is this tutorial for This QuickWin tutorial is for an audience that wants to get a straight to the point tutorial on how to write a tool definition and a workflow in Common Workflow Language (CWL) without knowing details of the specifications. What is converted into CWL in this tutorial The bash script to be converted to a CWL script is displayed below. It takes three URLs to Landsat-8 red, green and blue COGs and uses gdal_translate to crop them over an area of interest expressed as a bbox in a given EPSG code. red_channel=$1 green_channel=$2 blue_channel=$3 boox=\"$4\" epsg=\"$5\" # epsg default value [ -z \"${epsg}\" ] && epsg=\"EPSG:4326\" cropped=() for asset_href in \"${red_channel}\" \"${green_channel}\" \"${blue_channel}\" do in_tif=$( echo \"/vsicurl/${asset_href}\" || echo ${asset_href} | sed 's/TIF/tif/' ) out_tif=$( echo $asset_href | rev | cut -d \"/\" -f 1 | rev | sed 's/TIF/tif/' ) gdal_translate \\ -projwin \\ $ ( echo ${ bbox } | cut -d \",\" -f 1 ) \\ $ ( echo ${ bbox } | cut -d \",\" -f 4 ) \\ $ ( echo ${ bbox } | cut -d \",\" -f 3 ) \\ $ ( echo ${ bbox } | cut -d \",\" -f 2 ) \\ -projwin_srs ${ epsg } \\ $ { in_tif } \\ $ { out_tif } cropped+=($out_tif) done If you have gdal_translate on your computer (running Linux or MacOS), this script can be run by saving it in a file called pan-sharpen.sh and invoked with: sh pan-sharpen.sh \\ \"/vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B4.TIF\" \\ \"/vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B3.TIF\" \\ \"/vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B2.TIF\" \\ \"13.024,36.69,14.7,38.247\" \\ \"EPSG:4326\" Recipe Using a text editor, put the CWL document skeleton below in a file called translate.cwl . cwlVersion : v1.0 $graph : - class : CommandLineTool id : requirements : [] baseCommand : [] arguments : [] inputs : {} outputs : {} Now set: the tool id to translate since the CWL document has $graph and thus may include several tools the baseCommand to gdal_translate , which is the command we want CWL to invoke: cwlVersion : v1.0 $graph : - class : CommandLineTool id : translate requirements : [] baseCommand : - gdal_translate arguments : [] inputs : {} outputs : {} Add the inputs as type string : asset_href : the reference to the Landsat-8 COG file bbox : the area of interest expressed as a bounding box epsg : the EPSG code used to express the bounding box coordinates cwlVersion : v1.0 $graph : - class : CommandLineTool id : translate requirements : [] baseCommand : - gdal_translate arguments : [] inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : {} Add the arguments to complete the gdal_translate invocation cwlVersion : v1.0 $graph : - class : CommandLineTool id : translate requirements : [] baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : {} Notice that CWL expressions are used, e.g.: - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) And Javascript expressions, e.g.: - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } Since this CWL document uses javascript expressions to split the bbox parameter and set the cropped tif filename, it needs to declare the CWL InlineJavascriptRequirement requirement: cwlVersion : v1.0 $graph : - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : {} Add an output of type File (the cropped tif) to the outputs section: cwlVersion : v1.0 $graph : - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File gdal_translate will run in a container so set the CWL DockerRequirement and the container image URL by using the dockerPull field: cwlVersion : v1.0 $graph : - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File At this stage, the CWL document is complete ready to run the gdal_translate part of the initial shell script. To do so, prepare the parameters file named params.yml with: asset_href : \"/vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B4.TIF\" bbox : \"13.024,36.69,14.7,38.247\" epsg : \"EPSG:4326\" Run the tool with: cwltool translate.cwl#translate params.yml The CWL runner takes care of mounting the volumes required for the execution. The next steps includes adding the Workflow section to address the loop on the red, green and blue assets. Start by adding the Workflow structure: cwlVersion : v1.0 $graph : - class : Workflow id : label : doc : requirements : {} inputs : {} outputs : {} steps : {} - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File Add the CWL Workflow inputs : cwlVersion : v1.0 $graph : - class : Workflow id : label : doc : requirements : {} inputs : red_channel : type : string green_channel : type : string blue_channel : type : string bbox : type : string epsg : type : string outputs : {} steps : {} - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File Now define the CWL Workflow step that will run the translate CommandLineTool. For that use the CommandLineTool id as the step run value between double quotes and starting with the hash sign: $graph : - class : Workflow id : label : doc : requirements : {} inputs : red_channel : type : string green_channel : type : string blue_channel : type : string bbox : type : string epsg : type : string outputs : {} steps : node_translate : in : out : run : \"#translate\" - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File Map the node_translate inputs to the Workflow inputs. The asset_href input will loop over the red_channel , green_channel and blue_channel . To do so, CWL's MultipleInputFeatureRequirement requirement is used and thus added to the Workflow requirements: $graph : - class : Workflow id : label : doc : requirements : - class : MultipleInputFeatureRequirement inputs : red_channel : type : string green_channel : type : string blue_channel : type : string bbox : type : string epsg : type : string outputs : {} steps : node_translate : in : asset_href : [ red_channel , green_channel , blue_channel ] bbox : bbox epsg : epsg out : run : \"#translate\" - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File The loop over the red_channel , green_channel and blue_channel for asset_href uses the CWL requirement ScatterFeatureRequirement and it defines the scatter parameter and method: $graph : - class : Workflow id : label : doc : requirements : - class : MultipleInputFeatureRequirement - class : ScatterFeatureRequirement inputs : red_channel : type : string green_channel : type : string blue_channel : type : string bbox : type : string epsg : type : string outputs : {} steps : node_translate : in : asset_href : [ red_channel , green_channel , blue_channel ] bbox : bbox epsg : epsg out : run : \"#translate\" scatter : asset_href scatterMethod : dotproduct - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File Set the node_translate step output: $graph : - class : Workflow id : label : doc : requirements : - class : MultipleInputFeatureRequirement - class : ScatterFeatureRequirement inputs : red_channel : type : string green_channel : type : string blue_channel : type : string bbox : type : string epsg : type : string outputs : {} steps : node_translate : in : asset_href : [ red , _channel green_channel , blue_channel ] bbox : bbox epsg : epsg out : - tif run : \"#translate\" scatter : asset_href scatterMethod : dotproduct - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File And finally the Workflow outputs : $graph : - class : Workflow id : label : doc : requirements : - class : MultipleInputFeatureRequirement - class : ScatterFeatureRequirement inputs : red_channel : type : string green_channel : type : string blue_channel : type : string bbox : type : string epsg : type : string outputs : tifs : outputSource : - node_translate/tif type : File[] steps : node_translate : in : asset_href : [ red , green , blue ] bbox : bbox epsg : epsg out : - tif run : \"#translate\" scatter : asset_href scatterMethod : dotproduct - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File Set the Workflow id , label and doc : cwlVersion : v1.0 $graph : - class : Workflow id : cropper label : this is a label doc : this is a description requirements : - class : ScatterFeatureRequirement - class : MultipleInputFeatureRequirement inputs : red_channel : type : string green_channel : type : string blue_channel : type : string bbox : type : string epsg : type : string outputs : tifs : outputSource : - node_translate/tif type : File[] steps : node_translate : in : asset_href : [ red_channel , green_channel , blue_channel ] bbox : bbox epsg : epsg out : - tif run : \"#translate\" scatter : asset_href scatterMethod : dotproduct - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File Create a YAML file called workflow-params.yml with: red_channel : \"/vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B4.TIF\" green_channel : \"/vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B3.TIF\" blue_channel : \"/vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B2.TIF\" bbox : \"13.024,36.69,14.7,38.247\" epsg : \"EPSG:4326\" Run the tool with: cwltool workflow.cwl#cropper workflow-params.yml","title":"QuickWin"},{"location":"101/cwl-101/tutorial-1/quickwin/#quickwin-tutorial","text":"","title":"QuickWin tutorial"},{"location":"101/cwl-101/tutorial-1/quickwin/#who-is-this-tutorial-for","text":"This QuickWin tutorial is for an audience that wants to get a straight to the point tutorial on how to write a tool definition and a workflow in Common Workflow Language (CWL) without knowing details of the specifications.","title":"Who is this tutorial for"},{"location":"101/cwl-101/tutorial-1/quickwin/#what-is-converted-into-cwl-in-this-tutorial","text":"The bash script to be converted to a CWL script is displayed below. It takes three URLs to Landsat-8 red, green and blue COGs and uses gdal_translate to crop them over an area of interest expressed as a bbox in a given EPSG code. red_channel=$1 green_channel=$2 blue_channel=$3 boox=\"$4\" epsg=\"$5\" # epsg default value [ -z \"${epsg}\" ] && epsg=\"EPSG:4326\" cropped=() for asset_href in \"${red_channel}\" \"${green_channel}\" \"${blue_channel}\" do in_tif=$( echo \"/vsicurl/${asset_href}\" || echo ${asset_href} | sed 's/TIF/tif/' ) out_tif=$( echo $asset_href | rev | cut -d \"/\" -f 1 | rev | sed 's/TIF/tif/' ) gdal_translate \\ -projwin \\ $ ( echo ${ bbox } | cut -d \",\" -f 1 ) \\ $ ( echo ${ bbox } | cut -d \",\" -f 4 ) \\ $ ( echo ${ bbox } | cut -d \",\" -f 3 ) \\ $ ( echo ${ bbox } | cut -d \",\" -f 2 ) \\ -projwin_srs ${ epsg } \\ $ { in_tif } \\ $ { out_tif } cropped+=($out_tif) done If you have gdal_translate on your computer (running Linux or MacOS), this script can be run by saving it in a file called pan-sharpen.sh and invoked with: sh pan-sharpen.sh \\ \"/vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B4.TIF\" \\ \"/vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B3.TIF\" \\ \"/vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B2.TIF\" \\ \"13.024,36.69,14.7,38.247\" \\ \"EPSG:4326\"","title":"What is converted into CWL in this tutorial"},{"location":"101/cwl-101/tutorial-1/quickwin/#recipe","text":"Using a text editor, put the CWL document skeleton below in a file called translate.cwl . cwlVersion : v1.0 $graph : - class : CommandLineTool id : requirements : [] baseCommand : [] arguments : [] inputs : {} outputs : {} Now set: the tool id to translate since the CWL document has $graph and thus may include several tools the baseCommand to gdal_translate , which is the command we want CWL to invoke: cwlVersion : v1.0 $graph : - class : CommandLineTool id : translate requirements : [] baseCommand : - gdal_translate arguments : [] inputs : {} outputs : {} Add the inputs as type string : asset_href : the reference to the Landsat-8 COG file bbox : the area of interest expressed as a bounding box epsg : the EPSG code used to express the bounding box coordinates cwlVersion : v1.0 $graph : - class : CommandLineTool id : translate requirements : [] baseCommand : - gdal_translate arguments : [] inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : {} Add the arguments to complete the gdal_translate invocation cwlVersion : v1.0 $graph : - class : CommandLineTool id : translate requirements : [] baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : {} Notice that CWL expressions are used, e.g.: - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) And Javascript expressions, e.g.: - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } Since this CWL document uses javascript expressions to split the bbox parameter and set the cropped tif filename, it needs to declare the CWL InlineJavascriptRequirement requirement: cwlVersion : v1.0 $graph : - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : {} Add an output of type File (the cropped tif) to the outputs section: cwlVersion : v1.0 $graph : - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File gdal_translate will run in a container so set the CWL DockerRequirement and the container image URL by using the dockerPull field: cwlVersion : v1.0 $graph : - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File At this stage, the CWL document is complete ready to run the gdal_translate part of the initial shell script. To do so, prepare the parameters file named params.yml with: asset_href : \"/vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B4.TIF\" bbox : \"13.024,36.69,14.7,38.247\" epsg : \"EPSG:4326\" Run the tool with: cwltool translate.cwl#translate params.yml The CWL runner takes care of mounting the volumes required for the execution. The next steps includes adding the Workflow section to address the loop on the red, green and blue assets. Start by adding the Workflow structure: cwlVersion : v1.0 $graph : - class : Workflow id : label : doc : requirements : {} inputs : {} outputs : {} steps : {} - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File Add the CWL Workflow inputs : cwlVersion : v1.0 $graph : - class : Workflow id : label : doc : requirements : {} inputs : red_channel : type : string green_channel : type : string blue_channel : type : string bbox : type : string epsg : type : string outputs : {} steps : {} - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File Now define the CWL Workflow step that will run the translate CommandLineTool. For that use the CommandLineTool id as the step run value between double quotes and starting with the hash sign: $graph : - class : Workflow id : label : doc : requirements : {} inputs : red_channel : type : string green_channel : type : string blue_channel : type : string bbox : type : string epsg : type : string outputs : {} steps : node_translate : in : out : run : \"#translate\" - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File Map the node_translate inputs to the Workflow inputs. The asset_href input will loop over the red_channel , green_channel and blue_channel . To do so, CWL's MultipleInputFeatureRequirement requirement is used and thus added to the Workflow requirements: $graph : - class : Workflow id : label : doc : requirements : - class : MultipleInputFeatureRequirement inputs : red_channel : type : string green_channel : type : string blue_channel : type : string bbox : type : string epsg : type : string outputs : {} steps : node_translate : in : asset_href : [ red_channel , green_channel , blue_channel ] bbox : bbox epsg : epsg out : run : \"#translate\" - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File The loop over the red_channel , green_channel and blue_channel for asset_href uses the CWL requirement ScatterFeatureRequirement and it defines the scatter parameter and method: $graph : - class : Workflow id : label : doc : requirements : - class : MultipleInputFeatureRequirement - class : ScatterFeatureRequirement inputs : red_channel : type : string green_channel : type : string blue_channel : type : string bbox : type : string epsg : type : string outputs : {} steps : node_translate : in : asset_href : [ red_channel , green_channel , blue_channel ] bbox : bbox epsg : epsg out : run : \"#translate\" scatter : asset_href scatterMethod : dotproduct - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File Set the node_translate step output: $graph : - class : Workflow id : label : doc : requirements : - class : MultipleInputFeatureRequirement - class : ScatterFeatureRequirement inputs : red_channel : type : string green_channel : type : string blue_channel : type : string bbox : type : string epsg : type : string outputs : {} steps : node_translate : in : asset_href : [ red , _channel green_channel , blue_channel ] bbox : bbox epsg : epsg out : - tif run : \"#translate\" scatter : asset_href scatterMethod : dotproduct - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File And finally the Workflow outputs : $graph : - class : Workflow id : label : doc : requirements : - class : MultipleInputFeatureRequirement - class : ScatterFeatureRequirement inputs : red_channel : type : string green_channel : type : string blue_channel : type : string bbox : type : string epsg : type : string outputs : tifs : outputSource : - node_translate/tif type : File[] steps : node_translate : in : asset_href : [ red , green , blue ] bbox : bbox epsg : epsg out : - tif run : \"#translate\" scatter : asset_href scatterMethod : dotproduct - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File Set the Workflow id , label and doc : cwlVersion : v1.0 $graph : - class : Workflow id : cropper label : this is a label doc : this is a description requirements : - class : ScatterFeatureRequirement - class : MultipleInputFeatureRequirement inputs : red_channel : type : string green_channel : type : string blue_channel : type : string bbox : type : string epsg : type : string outputs : tifs : outputSource : - node_translate/tif type : File[] steps : node_translate : in : asset_href : [ red_channel , green_channel , blue_channel ] bbox : bbox epsg : epsg out : - tif run : \"#translate\" scatter : asset_href scatterMethod : dotproduct - class : CommandLineTool id : translate requirements : - class : InlineJavascriptRequirement - class : DockerRequirement dockerPull : docker.io/osgeo/gdal:latest baseCommand : - gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - $( inputs.epsg ) - $( inputs.asset_href ) - valueFrom : ${ return inputs.asset_href.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset_href : type : string bbox : type : string epsg : type : string outputs : tif : outputBinding : glob : '*.tif' type : File Create a YAML file called workflow-params.yml with: red_channel : \"/vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B4.TIF\" green_channel : \"/vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B3.TIF\" blue_channel : \"/vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B2.TIF\" bbox : \"13.024,36.69,14.7,38.247\" epsg : \"EPSG:4326\" Run the tool with: cwltool workflow.cwl#cropper workflow-params.yml","title":"Recipe"},{"location":"101/cwl-101/tutorial-2/command-line-tool/","text":"Writing your first CWL CommandLineTool document Goal Create a CWL CommandLineTool that uses GDAL's gdal_translate to clip a GeoTIFF using a given bounding box expressed in a defined EPSG code. CWL CommandLineTool skeleton Use a text editor to create a new plain text file and: set the CWL class CommandLineTool class : CommandLineTool set the CWL version in the last line class : CommandLineTool cwlVersion : v1.0 add the CommandLineTool elements: baseCommand : the CLI utility to invoke arguments : any arguments for the CLI utility inputs : the input parameters to expose outputs : the outputs to collect after the execution of the CLI utility class : CommandLineTool baseCommand : arguments : inputs : outputs : cwlVersion : v1.0 add the requirements block to specify the CWL requirements used for running the CWL document class : CommandLineTool requirements : baseCommand : arguments : inputs : outputs : cwlVersion : v1.0 baseCommand It's now time to fill the elements with their values. add the baseCommand : class : CommandLineTool requirements : baseCommand : gdal_translate arguments : inputs : outputs : cwlVersion : v1.0 Set the container set the container where gdal_translate is available: class : CommandLineTool requirements : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : inputs : outputs : cwlVersion : v1.0 Define the inputs set the inputs: geotiff of type File which is the path to the GeoTIFF file bbox of type string which is the bounding box expressed as \"xmin,ymin,latmin,latmax\" epsg of type string which is the EPSG code of the bounding box coordinates class : CommandLineTool requirements : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : inputs : geotiff : type : File bbox : type : string epsg : type : string default : \"EPSG:4326\" outputs : cwlVersion : v1.0 Set the arguments gdal_translate uses -projwin ulx uly lrx lry to set the area of interest. Since our bounding box is expressed as xmin,ymin,xmax,ymax , we'll have to manipulate the bbox value to format it as expected by gdal_translate ( xmax,ymin,xmin,ymax ). This is easily achieved by using the InlineJavascriptRequirement CWL requirement and using Javascript to manipulate the bbox input: class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : inputs : geotiff : type : File bbox : type : string epsg : type : string default : \"EPSG:4326\" outputs : cwlVersion : v1.0 and: class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } inputs : geotiff : type : File bbox : type : string epsg : type : string default : \"EPSG:4326\" outputs : cwlVersion : v1.0 Now, we need to set gdal_translate flag -projwin_srs and use the input epsg value. This can be done by setting the inputBinding element: class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } inputs : geotiff : type : File bbox : type : string epsg : type : string default : \"EPSG:4326\" inputBinding : position : 6 prefix : -projwin_srs separate : true outputs : cwlVersion : v1.0 Link the inputs The next step is to add the input file (the geotiff input). Again we use the inputBinding and set the position. class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } inputs : geotiff : type : File inputBinding : position : 7 bbox : type : string epsg : type : string default : \"EPSG:4326\" inputBinding : position : 6 prefix : -projwin_srs separate : true outputs : cwlVersion : v1.0 Our last argument is the output file name. Since we haven't defined a parameter to set this value, we'll pass it in the arguments element and construct it based on the geotiff input parameter. We also have to tell where to put it. class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - valueFrom : ${ return inputs.geotiff.basename.replace(\".tif\", \"\") + \"_clipped.tif\"; } position : 8 inputs : geotiff : type : File inputBinding : position : 7 bbox : type : string epsg : type : string default : \"EPSG:4326\" inputBinding : position : 6 prefix : -projwin_srs separate : true outputs : cwlVersion : v1.0 Set the output The file element is the output section. We'll call the result clipped_tif and set a search pattern to collect the output. class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - valueFrom : ${ return inputs.geotiff.basename.replace(\".tif\", \"\") + \"_clipped.tif\"; } position : 8 inputs : geotiff : type : File inputBinding : position : 7 bbox : type : string epsg : type : string default : \"EPSG:4326\" inputBinding : position : 6 prefix : -projwin_srs separate : true outputs : clipped_tif : outputBinding : glob : '*_clipped.tif' type : File cwlVersion : v1.0 Save it as gdal-translate.cwl CWL document validation Validate it using cwltool : cwltool --validate gdal-translate.cwl Test the CWL document Now get the geotiff we'll use for testing our first CWL document: curl -o B04.tif https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B04.tif Create a file called params.yml with: bbox : \"136.659,-35.96,136.923,-35.791\" geotiff : { \"class\" : \"File\" , \"path\" : \"B04.tif\" } epsg : \"EPSG:4326\" Use cwltool to run the CWL document: cwltool gdal-translate.cwl params.yml This will produce: INFO /srv/conda/bin/cwltool 3.1.20210628163208 INFO Resolved 'gdal-translate.cwl' to 'file:///home/fbrito/work/guide/gdal-translate.cwl' INFO [job gdal-translate.cwl] /tmp/m68dfr9m$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/m68dfr9m,target=/iWBQko \\ --mount=type=bind,source=/tmp/ku7m_krp,target=/tmp \\ --mount=type=bind,source=/home/fbrito/work/guide/B8A.tif,target=/var/lib/cwl/stg6d53b4c1-725d-4b0d-83dc-0d8662c928e7/B8A.tif,readonly \\ --workdir=/iWBQko \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/e5jclx6k/20210810091516-035626.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/iWBQko \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 136.659 \\ -35.791 \\ 136.923 \\ -35.96 \\ -projwin_srs \\ EPSG:4326 \\ /var/lib/cwl/stg6d53b4c1-725d-4b0d-83dc-0d8662c928e7/B8A.tif \\ B8A_clipped.tif Input file size is 5490, 5490 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job gdal-translate.cwl] Max memory used: 0MiB INFO [job gdal-translate.cwl] completed success { \"clipped_tif\": { \"location\": \"file:///home/fbrito/work/guide/B8A_clipped.tif\", \"basename\": \"B8A_clipped.tif\", \"class\": \"File\", \"checksum\": \"sha1$033898bb305bb2ae53980182cd882b05cc585fa2\", \"size\": 2256036, \"path\": \"/home/fbrito/work/guide/B8A_clipped.tif\" } } INFO Final process status is success","title":"Your first CommandLineTool"},{"location":"101/cwl-101/tutorial-2/command-line-tool/#writing-your-first-cwl-commandlinetool-document","text":"","title":"Writing your first CWL CommandLineTool document"},{"location":"101/cwl-101/tutorial-2/command-line-tool/#goal","text":"Create a CWL CommandLineTool that uses GDAL's gdal_translate to clip a GeoTIFF using a given bounding box expressed in a defined EPSG code.","title":"Goal"},{"location":"101/cwl-101/tutorial-2/command-line-tool/#cwl-commandlinetool-skeleton","text":"Use a text editor to create a new plain text file and: set the CWL class CommandLineTool class : CommandLineTool set the CWL version in the last line class : CommandLineTool cwlVersion : v1.0 add the CommandLineTool elements: baseCommand : the CLI utility to invoke arguments : any arguments for the CLI utility inputs : the input parameters to expose outputs : the outputs to collect after the execution of the CLI utility class : CommandLineTool baseCommand : arguments : inputs : outputs : cwlVersion : v1.0 add the requirements block to specify the CWL requirements used for running the CWL document class : CommandLineTool requirements : baseCommand : arguments : inputs : outputs : cwlVersion : v1.0","title":"CWL CommandLineTool skeleton"},{"location":"101/cwl-101/tutorial-2/command-line-tool/#basecommand","text":"It's now time to fill the elements with their values. add the baseCommand : class : CommandLineTool requirements : baseCommand : gdal_translate arguments : inputs : outputs : cwlVersion : v1.0","title":"baseCommand"},{"location":"101/cwl-101/tutorial-2/command-line-tool/#set-the-container","text":"set the container where gdal_translate is available: class : CommandLineTool requirements : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : inputs : outputs : cwlVersion : v1.0","title":"Set the container"},{"location":"101/cwl-101/tutorial-2/command-line-tool/#define-the-inputs","text":"set the inputs: geotiff of type File which is the path to the GeoTIFF file bbox of type string which is the bounding box expressed as \"xmin,ymin,latmin,latmax\" epsg of type string which is the EPSG code of the bounding box coordinates class : CommandLineTool requirements : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : inputs : geotiff : type : File bbox : type : string epsg : type : string default : \"EPSG:4326\" outputs : cwlVersion : v1.0","title":"Define the inputs"},{"location":"101/cwl-101/tutorial-2/command-line-tool/#set-the-arguments","text":"gdal_translate uses -projwin ulx uly lrx lry to set the area of interest. Since our bounding box is expressed as xmin,ymin,xmax,ymax , we'll have to manipulate the bbox value to format it as expected by gdal_translate ( xmax,ymin,xmin,ymax ). This is easily achieved by using the InlineJavascriptRequirement CWL requirement and using Javascript to manipulate the bbox input: class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : inputs : geotiff : type : File bbox : type : string epsg : type : string default : \"EPSG:4326\" outputs : cwlVersion : v1.0 and: class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } inputs : geotiff : type : File bbox : type : string epsg : type : string default : \"EPSG:4326\" outputs : cwlVersion : v1.0 Now, we need to set gdal_translate flag -projwin_srs and use the input epsg value. This can be done by setting the inputBinding element: class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } inputs : geotiff : type : File bbox : type : string epsg : type : string default : \"EPSG:4326\" inputBinding : position : 6 prefix : -projwin_srs separate : true outputs : cwlVersion : v1.0","title":"Set the arguments"},{"location":"101/cwl-101/tutorial-2/command-line-tool/#link-the-inputs","text":"The next step is to add the input file (the geotiff input). Again we use the inputBinding and set the position. class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } inputs : geotiff : type : File inputBinding : position : 7 bbox : type : string epsg : type : string default : \"EPSG:4326\" inputBinding : position : 6 prefix : -projwin_srs separate : true outputs : cwlVersion : v1.0 Our last argument is the output file name. Since we haven't defined a parameter to set this value, we'll pass it in the arguments element and construct it based on the geotiff input parameter. We also have to tell where to put it. class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - valueFrom : ${ return inputs.geotiff.basename.replace(\".tif\", \"\") + \"_clipped.tif\"; } position : 8 inputs : geotiff : type : File inputBinding : position : 7 bbox : type : string epsg : type : string default : \"EPSG:4326\" inputBinding : position : 6 prefix : -projwin_srs separate : true outputs : cwlVersion : v1.0","title":"Link the inputs"},{"location":"101/cwl-101/tutorial-2/command-line-tool/#set-the-output","text":"The file element is the output section. We'll call the result clipped_tif and set a search pattern to collect the output. class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - valueFrom : ${ return inputs.geotiff.basename.replace(\".tif\", \"\") + \"_clipped.tif\"; } position : 8 inputs : geotiff : type : File inputBinding : position : 7 bbox : type : string epsg : type : string default : \"EPSG:4326\" inputBinding : position : 6 prefix : -projwin_srs separate : true outputs : clipped_tif : outputBinding : glob : '*_clipped.tif' type : File cwlVersion : v1.0 Save it as gdal-translate.cwl","title":"Set the output"},{"location":"101/cwl-101/tutorial-2/command-line-tool/#cwl-document-validation","text":"Validate it using cwltool : cwltool --validate gdal-translate.cwl","title":"CWL document validation"},{"location":"101/cwl-101/tutorial-2/command-line-tool/#test-the-cwl-document","text":"Now get the geotiff we'll use for testing our first CWL document: curl -o B04.tif https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B04.tif Create a file called params.yml with: bbox : \"136.659,-35.96,136.923,-35.791\" geotiff : { \"class\" : \"File\" , \"path\" : \"B04.tif\" } epsg : \"EPSG:4326\" Use cwltool to run the CWL document: cwltool gdal-translate.cwl params.yml This will produce: INFO /srv/conda/bin/cwltool 3.1.20210628163208 INFO Resolved 'gdal-translate.cwl' to 'file:///home/fbrito/work/guide/gdal-translate.cwl' INFO [job gdal-translate.cwl] /tmp/m68dfr9m$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/m68dfr9m,target=/iWBQko \\ --mount=type=bind,source=/tmp/ku7m_krp,target=/tmp \\ --mount=type=bind,source=/home/fbrito/work/guide/B8A.tif,target=/var/lib/cwl/stg6d53b4c1-725d-4b0d-83dc-0d8662c928e7/B8A.tif,readonly \\ --workdir=/iWBQko \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/e5jclx6k/20210810091516-035626.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/iWBQko \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 136.659 \\ -35.791 \\ 136.923 \\ -35.96 \\ -projwin_srs \\ EPSG:4326 \\ /var/lib/cwl/stg6d53b4c1-725d-4b0d-83dc-0d8662c928e7/B8A.tif \\ B8A_clipped.tif Input file size is 5490, 5490 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job gdal-translate.cwl] Max memory used: 0MiB INFO [job gdal-translate.cwl] completed success { \"clipped_tif\": { \"location\": \"file:///home/fbrito/work/guide/B8A_clipped.tif\", \"basename\": \"B8A_clipped.tif\", \"class\": \"File\", \"checksum\": \"sha1$033898bb305bb2ae53980182cd882b05cc585fa2\", \"size\": 2256036, \"path\": \"/home/fbrito/work/guide/B8A_clipped.tif\" } } INFO Final process status is success","title":"Test the CWL document"},{"location":"101/cwl-101/tutorial-2/workflow/","text":"Writing your first CWL Workflow document Goal Building on the CommandLineTool created on the previous step, the first Workflow will include two processing steps: a fan-out processing pattern to use gdal_translate to clip the bands B04, B03 and B02 a fan-in processing pattern using OTB's image stacking CLI to create an RGB composite At this stage, there's a translate.cwl CWL document and a file params.yml . CWL Workflow skeleton Start creating the CWL workflow document with it's initial structure: class : label : doc : id : requirements : inputs : outputs : steps : node_ : run : in : out : cwlVersion : v1.0 Set the CWL class to Workflow : class : Workflow label : doc : id : requirements : inputs : outputs : steps : node_ : run : in : out : cwlVersion : v1.0 Workflow information Set the Workflow information ( label , doc ) and id : class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : inputs : outputs : steps : node_ : run : in : out : cwlVersion : v1.0 Workflow requirements Set the Workflow requirements to support the fan-out pattern. Setting the ScatterFeatureRequirement requirement tells the CWL runner to spawn several processes (these may run in parallel). class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : outputs : steps : node_ : run : in : out : cwlVersion : v1.0 Workflow inputs Define the inputs: - the list of geotifs - the area of interest - the EPSG code used to express the area of interest coordinates The geotiffs are a list of files, this workflow parameter type is now File[] : class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : geotiffs : doc : list of geotifs type : File[] aoi : doc : area of interest as a bounding box type : string epsg : doc : EPSG code type : string default : \"EPSG:4326\" outputs : steps : node_ : run : in : out : cwlVersion : v1.0 Workflow processing step Update the first processing step to set the sub-workflow translate.cwl to be run: class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : geotiffs : doc : list of geotifs type : File[] aoi : doc : area of interest as a bounding box type : string epsg : doc : EPSG code type : string default : \"EPSG:4326\" outputs : steps : node_ : run : translate.cwl in : out : cwlVersion : v1.0 Workflow input mapping Now, set the step inputs mapping where: translate.cwl input geotiff is mapped to worklow input geotiffs translate.cwl input aoi is mapped to worklow input aoi translate.cwl input epsg is mapped to worklow input epsg class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : geotiffs : doc : list of geotifs type : File[] aoi : doc : area of interest as a bounding box type : string epsg : doc : EPSG code type : string default : \"EPSG:4326\" outputs : steps : node_ : run : translate.cwl in : geotiff : geotiffs aoi : aoi epsg : epsg out : cwlVersion : v1.0 Workflow step output Set the node_translate output, i.e. the clipped_tif generated by translate.cwl : class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : geotiffs : doc : list of geotifs type : File[] aoi : doc : area of interest as a bounding box type : string epsg : doc : EPSG code type : string default : \"EPSG:4326\" outputs : steps : node_translate : run : translate.cwl in : geotiff : geotiffs aoi : aoi epsg : epsg out : - clipped_tif cwlVersion : v1.0 Scatter (fan-out) Now set the fan-out configuration by setting the scatter method and input (the geotiffs): class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : geotiffs : doc : list of geotifs type : File[] aoi : doc : area of interest as a bounding box type : string epsg : doc : EPSG code type : string default : \"EPSG:4326\" outputs : steps : node_translate : run : translate.cwl in : geotiff : geotiffs aoi : aoi epsg : epsg out : - clipped_tif scatter : geotiffs scatterMethod : dotproduct cwlVersion : v1.0 Adding another step The next step requires an additional CWL CommandLineTool. It's a file called concatenate.cwl and it contains: class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : terradue/otb-7.2.0 baseCommand : otbcli_ConcatenateImages arguments : - -out - composite.tif inputs : tifs : type : File[] inputBinding : position : 5 prefix : -il separate : true outputs : composite : outputBinding : glob : \"composite.tif\" type : File stderr : stderr stdout : stdout cwlVersion : v1.0 Add the additional step to concatenate the clipped geotiffs. class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : geotiffs : doc : list of geotifs type : File[] aoi : doc : area of interest as a bounding box type : string epsg : doc : EPSG code type : string default : \"EPSG:4326\" outputs : steps : node_translate : run : translate.cwl in : geotiff : geotiffs aoi : aoi epsg : epsg out : - clipped_tif scatter : geotiffs scatterMethod : dotproduct node_concatenate : run : concatenate.cwl in : tifs : source : node_translate/clipped_tif out : - composite cwlVersion : v1.0 Mapping the inputs from the previous step The inputs come from the previous step using the mapping: class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : geotiffs : doc : list of geotifs type : File[] aoi : doc : area of interest as a bounding box type : string epsg : doc : EPSG code type : string default : \"EPSG:4326\" outputs : steps : node_translate : run : translate.cwl in : geotiff : geotiffs aoi : aoi epsg : epsg out : - clipped_tif scatter : geotiffs scatterMethod : dotproduct node_concatenate : run : concatenate.cwl in : tifs : source : node_translate/clipped_tif out : - composite cwlVersion : v1.0 The workflow only misses the Workflow output block, a mapping to the node_concatenate outputs: class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : geotiffs : doc : list of geotifs type : File[] aoi : doc : area of interest as a bounding box type : string epsg : doc : EPSG code type : string default : \"EPSG:4326\" outputs : rgb : outputSource : - node_concatenate/composite type : File steps : node_translate : run : translate.cwl in : geotiff : geotiffs aoi : aoi epsg : epsg out : - clipped_tif scatter : geotiffs scatterMethod : dotproduct node_concatenate : run : concatenate.cwl in : tifs : source : node_translate/clipped_tif out : - composite cwlVersion : v1.0 Test the CWL workflow Download the three geotiff with: curl -o B04.tif https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B04.tif curl -o B03.tif https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B03.tif curl -o B02.tif https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B02.tif Create a file called composite-params.yml with: bbox : \"136.659,-35.96,136.923,-35.791\" geotiffs : - { \"class\" : \"File\" , \"path\" : \"B04.tif\" } - { \"class\" : \"File\" , \"path\" : \"B03.tif\" } - { \"class\" : \"File\" , \"path\" : \"B02.tif\" } epsg : \"EPSG:4326\" Run the workflow with: cwltool --parallel composite.cwl composite-params.yml This creates a file called composite.tif .","title":"Your first Workflow"},{"location":"101/cwl-101/tutorial-2/workflow/#writing-your-first-cwl-workflow-document","text":"","title":"Writing your first CWL Workflow document"},{"location":"101/cwl-101/tutorial-2/workflow/#goal","text":"Building on the CommandLineTool created on the previous step, the first Workflow will include two processing steps: a fan-out processing pattern to use gdal_translate to clip the bands B04, B03 and B02 a fan-in processing pattern using OTB's image stacking CLI to create an RGB composite At this stage, there's a translate.cwl CWL document and a file params.yml .","title":"Goal"},{"location":"101/cwl-101/tutorial-2/workflow/#cwl-workflow-skeleton","text":"Start creating the CWL workflow document with it's initial structure: class : label : doc : id : requirements : inputs : outputs : steps : node_ : run : in : out : cwlVersion : v1.0 Set the CWL class to Workflow : class : Workflow label : doc : id : requirements : inputs : outputs : steps : node_ : run : in : out : cwlVersion : v1.0","title":"CWL Workflow skeleton"},{"location":"101/cwl-101/tutorial-2/workflow/#workflow-information","text":"Set the Workflow information ( label , doc ) and id : class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : inputs : outputs : steps : node_ : run : in : out : cwlVersion : v1.0","title":"Workflow information"},{"location":"101/cwl-101/tutorial-2/workflow/#workflow-requirements","text":"Set the Workflow requirements to support the fan-out pattern. Setting the ScatterFeatureRequirement requirement tells the CWL runner to spawn several processes (these may run in parallel). class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : outputs : steps : node_ : run : in : out : cwlVersion : v1.0","title":"Workflow requirements"},{"location":"101/cwl-101/tutorial-2/workflow/#workflow-inputs","text":"Define the inputs: - the list of geotifs - the area of interest - the EPSG code used to express the area of interest coordinates The geotiffs are a list of files, this workflow parameter type is now File[] : class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : geotiffs : doc : list of geotifs type : File[] aoi : doc : area of interest as a bounding box type : string epsg : doc : EPSG code type : string default : \"EPSG:4326\" outputs : steps : node_ : run : in : out : cwlVersion : v1.0","title":"Workflow inputs"},{"location":"101/cwl-101/tutorial-2/workflow/#workflow-processing-step","text":"Update the first processing step to set the sub-workflow translate.cwl to be run: class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : geotiffs : doc : list of geotifs type : File[] aoi : doc : area of interest as a bounding box type : string epsg : doc : EPSG code type : string default : \"EPSG:4326\" outputs : steps : node_ : run : translate.cwl in : out : cwlVersion : v1.0","title":"Workflow processing step"},{"location":"101/cwl-101/tutorial-2/workflow/#workflow-input-mapping","text":"Now, set the step inputs mapping where: translate.cwl input geotiff is mapped to worklow input geotiffs translate.cwl input aoi is mapped to worklow input aoi translate.cwl input epsg is mapped to worklow input epsg class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : geotiffs : doc : list of geotifs type : File[] aoi : doc : area of interest as a bounding box type : string epsg : doc : EPSG code type : string default : \"EPSG:4326\" outputs : steps : node_ : run : translate.cwl in : geotiff : geotiffs aoi : aoi epsg : epsg out : cwlVersion : v1.0","title":"Workflow input mapping"},{"location":"101/cwl-101/tutorial-2/workflow/#workflow-step-output","text":"Set the node_translate output, i.e. the clipped_tif generated by translate.cwl : class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : geotiffs : doc : list of geotifs type : File[] aoi : doc : area of interest as a bounding box type : string epsg : doc : EPSG code type : string default : \"EPSG:4326\" outputs : steps : node_translate : run : translate.cwl in : geotiff : geotiffs aoi : aoi epsg : epsg out : - clipped_tif cwlVersion : v1.0","title":"Workflow step output"},{"location":"101/cwl-101/tutorial-2/workflow/#scatter-fan-out","text":"Now set the fan-out configuration by setting the scatter method and input (the geotiffs): class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : geotiffs : doc : list of geotifs type : File[] aoi : doc : area of interest as a bounding box type : string epsg : doc : EPSG code type : string default : \"EPSG:4326\" outputs : steps : node_translate : run : translate.cwl in : geotiff : geotiffs aoi : aoi epsg : epsg out : - clipped_tif scatter : geotiffs scatterMethod : dotproduct cwlVersion : v1.0","title":"Scatter (fan-out)"},{"location":"101/cwl-101/tutorial-2/workflow/#adding-another-step","text":"The next step requires an additional CWL CommandLineTool. It's a file called concatenate.cwl and it contains: class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : terradue/otb-7.2.0 baseCommand : otbcli_ConcatenateImages arguments : - -out - composite.tif inputs : tifs : type : File[] inputBinding : position : 5 prefix : -il separate : true outputs : composite : outputBinding : glob : \"composite.tif\" type : File stderr : stderr stdout : stdout cwlVersion : v1.0 Add the additional step to concatenate the clipped geotiffs. class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : geotiffs : doc : list of geotifs type : File[] aoi : doc : area of interest as a bounding box type : string epsg : doc : EPSG code type : string default : \"EPSG:4326\" outputs : steps : node_translate : run : translate.cwl in : geotiff : geotiffs aoi : aoi epsg : epsg out : - clipped_tif scatter : geotiffs scatterMethod : dotproduct node_concatenate : run : concatenate.cwl in : tifs : source : node_translate/clipped_tif out : - composite cwlVersion : v1.0","title":"Adding another step"},{"location":"101/cwl-101/tutorial-2/workflow/#mapping-the-inputs-from-the-previous-step","text":"The inputs come from the previous step using the mapping: class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : geotiffs : doc : list of geotifs type : File[] aoi : doc : area of interest as a bounding box type : string epsg : doc : EPSG code type : string default : \"EPSG:4326\" outputs : steps : node_translate : run : translate.cwl in : geotiff : geotiffs aoi : aoi epsg : epsg out : - clipped_tif scatter : geotiffs scatterMethod : dotproduct node_concatenate : run : concatenate.cwl in : tifs : source : node_translate/clipped_tif out : - composite cwlVersion : v1.0 The workflow only misses the Workflow output block, a mapping to the node_concatenate outputs: class : Workflow label : Sentinel-2 RGB creation doc : This workflow creates an RGB composite id : main requirements : - class : ScatterFeatureRequirement inputs : geotiffs : doc : list of geotifs type : File[] aoi : doc : area of interest as a bounding box type : string epsg : doc : EPSG code type : string default : \"EPSG:4326\" outputs : rgb : outputSource : - node_concatenate/composite type : File steps : node_translate : run : translate.cwl in : geotiff : geotiffs aoi : aoi epsg : epsg out : - clipped_tif scatter : geotiffs scatterMethod : dotproduct node_concatenate : run : concatenate.cwl in : tifs : source : node_translate/clipped_tif out : - composite cwlVersion : v1.0","title":"Mapping the inputs from the previous step"},{"location":"101/cwl-101/tutorial-2/workflow/#test-the-cwl-workflow","text":"Download the three geotiff with: curl -o B04.tif https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B04.tif curl -o B03.tif https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B03.tif curl -o B02.tif https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B02.tif Create a file called composite-params.yml with: bbox : \"136.659,-35.96,136.923,-35.791\" geotiffs : - { \"class\" : \"File\" , \"path\" : \"B04.tif\" } - { \"class\" : \"File\" , \"path\" : \"B03.tif\" } - { \"class\" : \"File\" , \"path\" : \"B02.tif\" } epsg : \"EPSG:4326\" Run the workflow with: cwltool --parallel composite.cwl composite-params.yml This creates a file called composite.tif .","title":"Test the CWL workflow"},{"location":"101/cwl-101/tutorial-3/bash-script/","text":"Shell script to be converted to CWL The shell script below takes as input: stac_item : an URL to a STAC Item describing a Landsat-8 acquisition bbox : the area of interest expressed as a bounding box as \"x_min,y_min,x_max,y_max\" epsg : the EPSG code used for the bounding box coordinates to apply the pan-sharpening technique and thus create an RGB composite at 15 metres. This shell script invokes the executables: curl and yq to get and parse the STAC Item to resolve the red (B04), green (B03) and blue (B02) assets gdal_translate to extract the area of interest of each of the red, green, blue assets on the one hand and on the other for the panchromatic band (B06) otbcli_ConcatenateImages to create a multi-band GeoTIFF file with the red, green, blue cropped bands otbcli_BundleToPerfectSensor to apply the pan-sharpening technique and generate the higher resolution RGB composite #!/bin/bash if [ \" $# \" -lt 2 ] then echo \"Usage: ...\" exit 1 fi # three parameters stac_item = \" $1 \" bbox = \" $2 \" epsg = \" $3 \" # epsg default value [ -z \" ${ epsg } \" ] && epsg = \"EPSG:4326\" # crop pan band asset = \"B8\" # resolve pan asset href using curl to get the content of the STAC item and jq to parse it asset_href = $( curl -s ${ stac_item } | jq .assets. ${ asset } .href | tr -d '\"' ) # check if it's a VSI in_tif = $( [ ${ asset_href } == http* ] && echo \"/vsicurl/ ${ asset_href } \" || echo ${ asset_href } ) # cropped tif reuses input name pan = $( echo $asset_href | rev | cut -d \"/\" -f 1 | rev | sed 's/TIF/tif/' ) # use gdal_translate to crop the tif gdal_translate \\ -projwin \\ $( echo ${ bbox } | cut -d \",\" -f 1 ) \\ $( echo ${ bbox } | cut -d \",\" -f 4 ) \\ $( echo ${ bbox } | cut -d \",\" -f 3 ) \\ $( echo ${ bbox } | cut -d \",\" -f 2 ) \\ -projwin_srs ${ epsg } \\ ${ in_tif } \\ ${ pan } # same approach for cropping the red, green and blue bands cropped =() for asset in \"B4\" \"B3\" \"B2\" do asset_href = $( curl -s ${ stac_item } | jq .assets. ${ asset } .href | tr -d '\"' ) in_tif = $( [[ ${ asset_href } == http* ]] && echo \"/vsicurl/ ${ asset_href } \" || echo ${ asset_href } ) out_tif = $( echo $asset_href | rev | cut -d \"/\" -f 1 | rev | sed 's/TIF/tif/' ) gdal_translate \\ -projwin \\ $( echo ${ bbox } | cut -d \",\" -f 1 ) \\ $( echo ${ bbox } | cut -d \",\" -f 4 ) \\ $( echo ${ bbox } | cut -d \",\" -f 3 ) \\ $( echo ${ bbox } | cut -d \",\" -f 2 ) \\ -projwin_srs ${ epsg } \\ ${ in_tif } \\ ${ out_tif } cropped +=( $out_tif ) done xs = xs_stack.tif # create a single tif with the red, green and blue cropped tifs otbcli_ConcatenateImages \\ -out \\ ${ xs } \\ -il $( for el in ${ cropped [@] } ; do echo $el ; done ) # pansharpening otbcli_BundleToPerfectSensor \\ -out pan-sharpen.tif \\ int \\ -inxs ${ xs } \\ -inp ${ pan } Identifying the tools The shell script invokes four executables: curl and yq gdal_translate otbcli_ConcatenateImages otbcli_BundleToPerfectSensor curl and yq curl and yq are invoked to resolve the STAC Item assets B04 , B03 and B02 : for asset in \"B4\" \"B3\" \"B2\" do asset_href = $( curl -s ${ stac_item } | jq .assets. ${ asset } .href | tr -d '\"' ) in_tif = $( [[ ${ asset_href } == http* ]] && echo \"/vsicurl/ ${ asset_href } \" || echo ${ asset_href } | sed 's/TIF/tif/' ) out_tif = $( echo $asset_href | rev | cut -d \"/\" -f 1 | rev | sed 's/TIF/tif/' ) It takes two command line arguments: stac_item , the URL to the Landsat-8 STAC item asset , the asset id And returns the asset href with the prefix /vsicurl/ so it can be read by gdal_translate . gdal_translate gdal_translate is used to read the remote GeoTIFF and save a cropped GeoTIFF. in_tif = $( [[ ${ asset_href } == http* ]] && echo \"/vsicurl/ ${ asset_href } \" || echo ${ asset_href } | sed 's/TIF/tif/' ) out_tif = $( echo $asset_href | rev | cut -d \"/\" -f 1 | rev | sed 's/TIF/tif/' ) gdal_translate \\ -projwin \\ $( echo ${ bbox } | cut -d \",\" -f 1 ) \\ $( echo ${ bbox } | cut -d \",\" -f 4 ) \\ $( echo ${ bbox } | cut -d \",\" -f 3 ) \\ $( echo ${ bbox } | cut -d \",\" -f 2 ) \\ -projwin_srs ${ epsg } \\ ${ in_tif } \\ ${ out_tif } cropped +=( $out_tif ) It takes as command line arguments: bbox whose value is split since gdal_translate expects the area of interest expresses as x_min,y_max,x_max,y_min while the script gets it as x_min,y_min,x_max,y_max . epsg , the EPSG code used for the bbox coordinates in_tif , the asset href value prefixed with /vsicurl out_tif , the output name for the cropped GeoTIFF To produce the cropped GeoTIFF. otbcli_ConcatenateImages Orfeo's Toolbox otbcli_ConcatenateImages is used to concatenate the three cropped GeoTIFFs for the red, green and blue channels: otbcli_ConcatenateImages \\ -out \\ ${ xs } \\ -il $( for el in ${ cropped [@] } ; do echo $el ; done ) It takes as command line arguments: ${xs} , the stacked output GeoTIFF the list of GeoTIFF to concatenate To produce the stacked GeoTIFF. otbcli_BundleToPerfectSensor Orfeo's Toolbox otbcli_BundleToPerfectSensor is used to apply the pan-sharpening technique using the stacked GeoTIFF produced by otbcli_ConcatenateImages and the panchromatic band cropped by gdal_translate otbcli_BundleToPerfectSensor \\ -out pan-sharpen.tif \\ int \\ -inxs ${ xs } \\ -inp ${ pan } It takes as command line arguments: ${xs} , the stacked GeoTIFF ${pan} , the cropped pan-chromatic band To produce the pan-sharpened GeoTIFF.","title":"Bash script"},{"location":"101/cwl-101/tutorial-3/bash-script/#shell-script-to-be-converted-to-cwl","text":"The shell script below takes as input: stac_item : an URL to a STAC Item describing a Landsat-8 acquisition bbox : the area of interest expressed as a bounding box as \"x_min,y_min,x_max,y_max\" epsg : the EPSG code used for the bounding box coordinates to apply the pan-sharpening technique and thus create an RGB composite at 15 metres. This shell script invokes the executables: curl and yq to get and parse the STAC Item to resolve the red (B04), green (B03) and blue (B02) assets gdal_translate to extract the area of interest of each of the red, green, blue assets on the one hand and on the other for the panchromatic band (B06) otbcli_ConcatenateImages to create a multi-band GeoTIFF file with the red, green, blue cropped bands otbcli_BundleToPerfectSensor to apply the pan-sharpening technique and generate the higher resolution RGB composite #!/bin/bash if [ \" $# \" -lt 2 ] then echo \"Usage: ...\" exit 1 fi # three parameters stac_item = \" $1 \" bbox = \" $2 \" epsg = \" $3 \" # epsg default value [ -z \" ${ epsg } \" ] && epsg = \"EPSG:4326\" # crop pan band asset = \"B8\" # resolve pan asset href using curl to get the content of the STAC item and jq to parse it asset_href = $( curl -s ${ stac_item } | jq .assets. ${ asset } .href | tr -d '\"' ) # check if it's a VSI in_tif = $( [ ${ asset_href } == http* ] && echo \"/vsicurl/ ${ asset_href } \" || echo ${ asset_href } ) # cropped tif reuses input name pan = $( echo $asset_href | rev | cut -d \"/\" -f 1 | rev | sed 's/TIF/tif/' ) # use gdal_translate to crop the tif gdal_translate \\ -projwin \\ $( echo ${ bbox } | cut -d \",\" -f 1 ) \\ $( echo ${ bbox } | cut -d \",\" -f 4 ) \\ $( echo ${ bbox } | cut -d \",\" -f 3 ) \\ $( echo ${ bbox } | cut -d \",\" -f 2 ) \\ -projwin_srs ${ epsg } \\ ${ in_tif } \\ ${ pan } # same approach for cropping the red, green and blue bands cropped =() for asset in \"B4\" \"B3\" \"B2\" do asset_href = $( curl -s ${ stac_item } | jq .assets. ${ asset } .href | tr -d '\"' ) in_tif = $( [[ ${ asset_href } == http* ]] && echo \"/vsicurl/ ${ asset_href } \" || echo ${ asset_href } ) out_tif = $( echo $asset_href | rev | cut -d \"/\" -f 1 | rev | sed 's/TIF/tif/' ) gdal_translate \\ -projwin \\ $( echo ${ bbox } | cut -d \",\" -f 1 ) \\ $( echo ${ bbox } | cut -d \",\" -f 4 ) \\ $( echo ${ bbox } | cut -d \",\" -f 3 ) \\ $( echo ${ bbox } | cut -d \",\" -f 2 ) \\ -projwin_srs ${ epsg } \\ ${ in_tif } \\ ${ out_tif } cropped +=( $out_tif ) done xs = xs_stack.tif # create a single tif with the red, green and blue cropped tifs otbcli_ConcatenateImages \\ -out \\ ${ xs } \\ -il $( for el in ${ cropped [@] } ; do echo $el ; done ) # pansharpening otbcli_BundleToPerfectSensor \\ -out pan-sharpen.tif \\ int \\ -inxs ${ xs } \\ -inp ${ pan }","title":"Shell script to be converted to CWL"},{"location":"101/cwl-101/tutorial-3/bash-script/#identifying-the-tools","text":"The shell script invokes four executables: curl and yq gdal_translate otbcli_ConcatenateImages otbcli_BundleToPerfectSensor","title":"Identifying the tools"},{"location":"101/cwl-101/tutorial-3/bash-script/#curl-and-yq","text":"curl and yq are invoked to resolve the STAC Item assets B04 , B03 and B02 : for asset in \"B4\" \"B3\" \"B2\" do asset_href = $( curl -s ${ stac_item } | jq .assets. ${ asset } .href | tr -d '\"' ) in_tif = $( [[ ${ asset_href } == http* ]] && echo \"/vsicurl/ ${ asset_href } \" || echo ${ asset_href } | sed 's/TIF/tif/' ) out_tif = $( echo $asset_href | rev | cut -d \"/\" -f 1 | rev | sed 's/TIF/tif/' ) It takes two command line arguments: stac_item , the URL to the Landsat-8 STAC item asset , the asset id And returns the asset href with the prefix /vsicurl/ so it can be read by gdal_translate .","title":"curl and yq"},{"location":"101/cwl-101/tutorial-3/bash-script/#gdal_translate","text":"gdal_translate is used to read the remote GeoTIFF and save a cropped GeoTIFF. in_tif = $( [[ ${ asset_href } == http* ]] && echo \"/vsicurl/ ${ asset_href } \" || echo ${ asset_href } | sed 's/TIF/tif/' ) out_tif = $( echo $asset_href | rev | cut -d \"/\" -f 1 | rev | sed 's/TIF/tif/' ) gdal_translate \\ -projwin \\ $( echo ${ bbox } | cut -d \",\" -f 1 ) \\ $( echo ${ bbox } | cut -d \",\" -f 4 ) \\ $( echo ${ bbox } | cut -d \",\" -f 3 ) \\ $( echo ${ bbox } | cut -d \",\" -f 2 ) \\ -projwin_srs ${ epsg } \\ ${ in_tif } \\ ${ out_tif } cropped +=( $out_tif ) It takes as command line arguments: bbox whose value is split since gdal_translate expects the area of interest expresses as x_min,y_max,x_max,y_min while the script gets it as x_min,y_min,x_max,y_max . epsg , the EPSG code used for the bbox coordinates in_tif , the asset href value prefixed with /vsicurl out_tif , the output name for the cropped GeoTIFF To produce the cropped GeoTIFF.","title":"gdal_translate"},{"location":"101/cwl-101/tutorial-3/bash-script/#otbcli_concatenateimages","text":"Orfeo's Toolbox otbcli_ConcatenateImages is used to concatenate the three cropped GeoTIFFs for the red, green and blue channels: otbcli_ConcatenateImages \\ -out \\ ${ xs } \\ -il $( for el in ${ cropped [@] } ; do echo $el ; done ) It takes as command line arguments: ${xs} , the stacked output GeoTIFF the list of GeoTIFF to concatenate To produce the stacked GeoTIFF.","title":"otbcli_ConcatenateImages"},{"location":"101/cwl-101/tutorial-3/bash-script/#otbcli_bundletoperfectsensor","text":"Orfeo's Toolbox otbcli_BundleToPerfectSensor is used to apply the pan-sharpening technique using the stacked GeoTIFF produced by otbcli_ConcatenateImages and the panchromatic band cropped by gdal_translate otbcli_BundleToPerfectSensor \\ -out pan-sharpen.tif \\ int \\ -inxs ${ xs } \\ -inp ${ pan } It takes as command line arguments: ${xs} , the stacked GeoTIFF ${pan} , the cropped pan-chromatic band To produce the pan-sharpened GeoTIFF.","title":"otbcli_BundleToPerfectSensor"},{"location":"101/cwl-101/tutorial-3/sub-workflow/","text":"","title":"Processing multiple inputs"},{"location":"101/cwl-101/tutorial-3/tool-wrappers/","text":"Each identified tool is converted to a CWL CommandLineTool. curl and yq class : CommandLineTool requirements : DockerRequirement : dockerPull : terradue/jq ShellCommandRequirement : {} InlineJavascriptRequirement : {} baseCommand : curl arguments : - -s - $(inputs.stac_item) - \"|\" - jq - .assets.$(inputs.asset).href - \"|\" - tr - -d - '\\\"' #\\\"\" stdout : message inputs : stac_item : type : string asset : type : string outputs : asset_href : type : string outputBinding : glob : message loadContents : true outputEval : $( self[0].contents.split(\"\\n\").join(\"\") ) cwlVersion : v1.0 gdal_translate class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - valueFrom : ${ return inputs.epsg; } - valueFrom : | ${ if (inputs.asset.startsWith(\"http\")) { return \"/vsicurl/\" + inputs.asset; } else { return inputs.asset; } } - valueFrom : ${ return inputs.asset.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset : type : string bbox : type : string epsg : type : string default : \"EPSG:4326\" outputs : tifs : outputBinding : glob : '*.tif' type : File stderr : stderr stdout : stdout cwlVersion : v1.0 otbcli_ConcatenateImages class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : terradue/otb-7.2.0 baseCommand : otbcli_ConcatenateImages arguments : - -out - xs_stack.tif inputs : tifs : type : File[] inputBinding : position : 5 prefix : -il separate : true outputs : xs_stack : outputBinding : glob : \"xs_stack.tif\" type : File stderr : stderr stdout : stdout cwlVersion : v1.0 otbcli_BundleToPerfectSensor class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : terradue/otb-7.2.0 baseCommand : otbcli_BundleToPerfectSensor arguments : - -out - pan-sharpen.tif inputs : xs : type : File inputBinding : position : 2 prefix : -inxs separate : true pan : type : File inputBinding : position : 3 prefix : -inp separate : true outputs : pan-sharpened : outputBinding : glob : \"*.tif\" type : File stderr : stderr stdout : stdout cwlVersion : v1.0","title":"Writing the Tool Wrappers"},{"location":"101/cwl-101/tutorial-3/tool-wrappers/#curl-and-yq","text":"class : CommandLineTool requirements : DockerRequirement : dockerPull : terradue/jq ShellCommandRequirement : {} InlineJavascriptRequirement : {} baseCommand : curl arguments : - -s - $(inputs.stac_item) - \"|\" - jq - .assets.$(inputs.asset).href - \"|\" - tr - -d - '\\\"' #\\\"\" stdout : message inputs : stac_item : type : string asset : type : string outputs : asset_href : type : string outputBinding : glob : message loadContents : true outputEval : $( self[0].contents.split(\"\\n\").join(\"\") ) cwlVersion : v1.0","title":"curl and yq"},{"location":"101/cwl-101/tutorial-3/tool-wrappers/#gdal_translate","text":"class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - valueFrom : ${ return inputs.epsg; } - valueFrom : | ${ if (inputs.asset.startsWith(\"http\")) { return \"/vsicurl/\" + inputs.asset; } else { return inputs.asset; } } - valueFrom : ${ return inputs.asset.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset : type : string bbox : type : string epsg : type : string default : \"EPSG:4326\" outputs : tifs : outputBinding : glob : '*.tif' type : File stderr : stderr stdout : stdout cwlVersion : v1.0","title":"gdal_translate"},{"location":"101/cwl-101/tutorial-3/tool-wrappers/#otbcli_concatenateimages","text":"class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : terradue/otb-7.2.0 baseCommand : otbcli_ConcatenateImages arguments : - -out - xs_stack.tif inputs : tifs : type : File[] inputBinding : position : 5 prefix : -il separate : true outputs : xs_stack : outputBinding : glob : \"xs_stack.tif\" type : File stderr : stderr stdout : stdout cwlVersion : v1.0","title":"otbcli_ConcatenateImages"},{"location":"101/cwl-101/tutorial-3/tool-wrappers/#otbcli_bundletoperfectsensor","text":"class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : terradue/otb-7.2.0 baseCommand : otbcli_BundleToPerfectSensor arguments : - -out - pan-sharpen.tif inputs : xs : type : File inputBinding : position : 2 prefix : -inxs separate : true pan : type : File inputBinding : position : 3 prefix : -inp separate : true outputs : pan-sharpened : outputBinding : glob : \"*.tif\" type : File stderr : stderr stdout : stdout cwlVersion : v1.0","title":"otbcli_BundleToPerfectSensor"},{"location":"101/cwl-101/tutorial-3/workflow-composition/","text":"","title":"Workflow composition"},{"location":"101/cwl-101/tutorial-3/workflow-run/","text":"","title":"Running and debugging"},{"location":"cwl-snap-graph-runner/","text":"Process SNAP GPT graphs using docker and the Common Workflow Language (CWL) This repo provides a method to process Earth Observation data with the SNAP Graph Processing Tool (GPT) using docker and CWL. With this method, the host machine does not have to have SNAP installed. CWL is used to invoke the SNAP gpt command line tool and deals with all the docker volume mounts required to process a Graph and EO data available on the host. This repo contains a SNAP Graph for the SAR calibration of Copernicus Sentinel-1 GRD product. You're expected to have the product on your local computer Requirements CWL runner The CWL runner executes CWL documents. Follow the installation procedure provided here Docker The SNAP processing runs in a docker container so docker is required. Follow the installation steps for your computer provided here If needed follow the additional steps described here to allow the CWL runner to manage docker as a non-root user. Getting started Setting-up the container Clone this repository and build the docker image with: git clone https://github.com/snap-contrib/cwl-snap-graph-runner.git cd cwl-snap-graph-runner docker build -t snap:latest -f .docker/Dockerfile . Check the docker image exists with: docker images | grep snap:latest This returns one line with the docker image just built. Check if SNAP gpt utility is available in the container: docker run --rm -it snap:latest gpt -h This dumps the SNAP gpt utiliy help message. Getting a few Sentinel-1 GRD acquistions Download a couple of Sentinel-1 GRD acquisitions and unzip them. Preparing the input parameters for the CWL step The CWL parameters file is a YAML file with an array of input directories pointing to the SAFE folders: polarization : 'VV' snap_graph : { class : File , path : ./sar-calibration.xml } safe : - { 'class' : 'Directory' , 'path' : '/home/fbrito/Downloads/S1A_IW_GRDH_1SDV_20210615T050457_20210615T050522_038346_048680_F42E.SAFE' } Save this content in a file called params.yml . The SNAP Graph The file sar-calibration.xml contains a SNAP Graph that is parametrized with variables: <node id= \"Read\" > <operator> Read </operator> <sources/> <parameters class= \"com.bc.ceres.binding.dom.XppDomElement\" > <file> ${inFile} </file> <formatName> SENTINEL-1 </formatName> </parameters> </node> The CWL file will instruct gpt to use the value passed as a command line argument: inp3 : inputBinding : position : 2 prefix : -PinFile= separate : false type : Directory Run the SNAP graph with CWL in the container cwltool gpt-sar-calibration.cwl gpt-sar-calibration-params.yml This will process the Sentinel-1 GRD acquisitions with an output as: INFO /srv/conda/bin/cwltool 3.0.20210319143721 INFO Resolved 'gpt-sar-calibration.cwl' to 'file:///home/fbrito/work/cwl-snap-graph-runner/gpt-sar-calibration.cwl' INFO [workflow ] start INFO [workflow ] starting step node_1 INFO [step node_1] start INFO [job node_1] /tmp/9ti8kfl0$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/9ti8kfl0,target=/zefIeZ \\ --mount=type=bind,source=/tmp/f2jfo_i7,target=/tmp \\ --mount=type=bind,source=/home/fbrito/work/cwl-snap-graph-runner/sar-calibration.xml,target=/var/lib/cwl/stg52f9db5f-3988-4923-97d6-8f02f538b99c/sar-calibration.xml,readonly \\ --mount=type=bind,source=/home/fbrito/Downloads/S1A_IW_GRDH_1SDV_20210615T050457_20210615T050522_038346_048680_F42E.SAFE,target=/var/lib/cwl/stg83984c21-caf6-4b14-b2b0-893583bcd1b9/S1A_IW_GRDH_1SDV_20210615T050457_20210615T050522_038346_048680_F42E.SAFE,readonly \\ --workdir=/zefIeZ \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/zefIeZ \\ --cidfile=/tmp/sub7uryv/20210616102403-516906.cid \\ --env=PATH=/srv/conda/envs/env_snap/snap/bin:/usr/share/java/maven/bin:/usr/share/java/maven/bin:/opt/anaconda/bin:/opt/anaconda/condabin:/opt/anaconda/bin:/usr/lib64/qt-3.3/bin:/usr/share/java/maven/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin \\ --env=PREFIX=/opt/anaconda/envs/env_snap \\ snap:latest \\ gpt \\ /var/lib/cwl/stg52f9db5f-3988-4923-97d6-8f02f538b99c/sar-calibration.xml \\ -PselPol=VV \\ -PinFile=/var/lib/cwl/stg83984c21-caf6-4b14-b2b0-893583bcd1b9/S1A_IW_GRDH_1SDV_20210615T050457_20210615T050522_038346_048680_F42E.SAFE > /tmp/9ti8kfl0/std.out 2> /tmp/9ti8kfl0/std.err INFO [job node_1] Max memory used: 7174MiB INFO [job node_1] completed success INFO [step node_1] completed success INFO [workflow ] completed success Run your own SNAP graphs Use the approach provided to run your own SNAP graphs Create your own repo with this one as a template using the URL https://github.com/snap-contrib/cwl-snap-graph-runner/generate Create the SNAP graphs including the variable to be used in the CWL as parameters Write the CWL document to expose the SNAP Graph parameters you want to provide at execution time Write the YAML parameters file Run the CWL document","title":"Process SNAP GPT graphs using docker and the Common Workflow Language (CWL)"},{"location":"cwl-snap-graph-runner/#process-snap-gpt-graphs-using-docker-and-the-common-workflow-language-cwl","text":"This repo provides a method to process Earth Observation data with the SNAP Graph Processing Tool (GPT) using docker and CWL. With this method, the host machine does not have to have SNAP installed. CWL is used to invoke the SNAP gpt command line tool and deals with all the docker volume mounts required to process a Graph and EO data available on the host. This repo contains a SNAP Graph for the SAR calibration of Copernicus Sentinel-1 GRD product. You're expected to have the product on your local computer","title":"Process SNAP GPT graphs using docker and the Common Workflow Language (CWL)"},{"location":"cwl-snap-graph-runner/#requirements","text":"","title":"Requirements"},{"location":"cwl-snap-graph-runner/#cwl-runner","text":"The CWL runner executes CWL documents. Follow the installation procedure provided here","title":"CWL runner"},{"location":"cwl-snap-graph-runner/#docker","text":"The SNAP processing runs in a docker container so docker is required. Follow the installation steps for your computer provided here If needed follow the additional steps described here to allow the CWL runner to manage docker as a non-root user.","title":"Docker"},{"location":"cwl-snap-graph-runner/#getting-started","text":"","title":"Getting started"},{"location":"cwl-snap-graph-runner/#setting-up-the-container","text":"Clone this repository and build the docker image with: git clone https://github.com/snap-contrib/cwl-snap-graph-runner.git cd cwl-snap-graph-runner docker build -t snap:latest -f .docker/Dockerfile . Check the docker image exists with: docker images | grep snap:latest This returns one line with the docker image just built. Check if SNAP gpt utility is available in the container: docker run --rm -it snap:latest gpt -h This dumps the SNAP gpt utiliy help message.","title":"Setting-up the container"},{"location":"cwl-snap-graph-runner/#getting-a-few-sentinel-1-grd-acquistions","text":"Download a couple of Sentinel-1 GRD acquisitions and unzip them.","title":"Getting a few Sentinel-1 GRD acquistions"},{"location":"cwl-snap-graph-runner/#preparing-the-input-parameters-for-the-cwl-step","text":"The CWL parameters file is a YAML file with an array of input directories pointing to the SAFE folders: polarization : 'VV' snap_graph : { class : File , path : ./sar-calibration.xml } safe : - { 'class' : 'Directory' , 'path' : '/home/fbrito/Downloads/S1A_IW_GRDH_1SDV_20210615T050457_20210615T050522_038346_048680_F42E.SAFE' } Save this content in a file called params.yml .","title":"Preparing the input parameters for the CWL step"},{"location":"cwl-snap-graph-runner/#the-snap-graph","text":"The file sar-calibration.xml contains a SNAP Graph that is parametrized with variables: <node id= \"Read\" > <operator> Read </operator> <sources/> <parameters class= \"com.bc.ceres.binding.dom.XppDomElement\" > <file> ${inFile} </file> <formatName> SENTINEL-1 </formatName> </parameters> </node> The CWL file will instruct gpt to use the value passed as a command line argument: inp3 : inputBinding : position : 2 prefix : -PinFile= separate : false type : Directory","title":"The SNAP Graph"},{"location":"cwl-snap-graph-runner/#run-the-snap-graph-with-cwl-in-the-container","text":"cwltool gpt-sar-calibration.cwl gpt-sar-calibration-params.yml This will process the Sentinel-1 GRD acquisitions with an output as: INFO /srv/conda/bin/cwltool 3.0.20210319143721 INFO Resolved 'gpt-sar-calibration.cwl' to 'file:///home/fbrito/work/cwl-snap-graph-runner/gpt-sar-calibration.cwl' INFO [workflow ] start INFO [workflow ] starting step node_1 INFO [step node_1] start INFO [job node_1] /tmp/9ti8kfl0$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/9ti8kfl0,target=/zefIeZ \\ --mount=type=bind,source=/tmp/f2jfo_i7,target=/tmp \\ --mount=type=bind,source=/home/fbrito/work/cwl-snap-graph-runner/sar-calibration.xml,target=/var/lib/cwl/stg52f9db5f-3988-4923-97d6-8f02f538b99c/sar-calibration.xml,readonly \\ --mount=type=bind,source=/home/fbrito/Downloads/S1A_IW_GRDH_1SDV_20210615T050457_20210615T050522_038346_048680_F42E.SAFE,target=/var/lib/cwl/stg83984c21-caf6-4b14-b2b0-893583bcd1b9/S1A_IW_GRDH_1SDV_20210615T050457_20210615T050522_038346_048680_F42E.SAFE,readonly \\ --workdir=/zefIeZ \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/zefIeZ \\ --cidfile=/tmp/sub7uryv/20210616102403-516906.cid \\ --env=PATH=/srv/conda/envs/env_snap/snap/bin:/usr/share/java/maven/bin:/usr/share/java/maven/bin:/opt/anaconda/bin:/opt/anaconda/condabin:/opt/anaconda/bin:/usr/lib64/qt-3.3/bin:/usr/share/java/maven/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin \\ --env=PREFIX=/opt/anaconda/envs/env_snap \\ snap:latest \\ gpt \\ /var/lib/cwl/stg52f9db5f-3988-4923-97d6-8f02f538b99c/sar-calibration.xml \\ -PselPol=VV \\ -PinFile=/var/lib/cwl/stg83984c21-caf6-4b14-b2b0-893583bcd1b9/S1A_IW_GRDH_1SDV_20210615T050457_20210615T050522_038346_048680_F42E.SAFE > /tmp/9ti8kfl0/std.out 2> /tmp/9ti8kfl0/std.err INFO [job node_1] Max memory used: 7174MiB INFO [job node_1] completed success INFO [step node_1] completed success INFO [workflow ] completed success","title":"Run the SNAP graph with CWL in the container"},{"location":"cwl-snap-graph-runner/#run-your-own-snap-graphs","text":"Use the approach provided to run your own SNAP graphs Create your own repo with this one as a template using the URL https://github.com/snap-contrib/cwl-snap-graph-runner/generate Create the SNAP graphs including the variable to be used in the CWL as parameters Write the CWL document to expose the SNAP Graph parameters you want to provide at execution time Write the YAML parameters file Run the CWL document","title":"Run your own SNAP graphs"},{"location":"gdal/","text":"Geospatial Data Abstraction Library (GDAL) GDAL is a translator library for raster and vector geospatial data formats that is released under an X/MIT style Open Source License by the Open Source Geospatial Foundation. As a library, it presents a single raster abstract data model and single vector abstract data model to the calling application for all supported formats. It also comes with a variety of useful command line utilities for data translation and processing.","title":"Geospatial Data Abstraction Library (GDAL)"},{"location":"gdal/#geospatial-data-abstraction-library-gdal","text":"GDAL is a translator library for raster and vector geospatial data formats that is released under an X/MIT style Open Source License by the Open Source Geospatial Foundation. As a library, it presents a single raster abstract data model and single vector abstract data model to the calling application for all supported formats. It also comes with a variety of useful command line utilities for data translation and processing.","title":"Geospatial Data Abstraction Library (GDAL)"},{"location":"gdal/gdal_translate/","text":"gdal_translate This is a simple example of gdal_translate that reads a COG URL and does a geographic subset according to a provided boundinx box and associated EPSG code. This CWL document takes an URL to a Sentinel-2 STAC asset href pointing to a COG file and uses gdal_translate to access the desired portion of the file. The command wrapped by the CWL CommandLineTool is: gdal_translate \\ -projwin \\ 136.659 \\ -35.791 \\ 136.923 \\ -35.96 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif \\ B8A.tif The CWL document content is: class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - valueFrom : ${ return inputs.epsg; } - valueFrom : | ${ if (inputs.asset.startsWith(\"http\")) { return \"/vsicurl/\" + inputs.asset; } else { return inputs.asset; } } - valueFrom : ${ return inputs.asset.split(\"/\").slice(-1)[0]; } inputs : asset : type : string bbox : type : string epsg : type : string default : \"EPSG:4326\" outputs : tifs : outputBinding : glob : '*.tif' type : File cwlVersion : v1.0 It may be run with the parameters: bbox : \"136.659,-35.96,136.923,-35.791\" asset : https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif epsg : \"EPSG:4326\" The execution will generate: INFO /srv/conda/bin/cwltool 3.0.20210319143721 INFO Resolved 'translate.cwl' to 'file:///home/fbrito/work/sentinel-2-dnbr-multitemporal-cog/translate.cwl' INFO [job translate.cwl] /tmp/k8idc3ml$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/k8idc3ml,target=/MRizBi \\ --mount=type=bind,source=/tmp/zb8r6gau,target=/tmp \\ --workdir=/MRizBi \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/MRizBi \\ --cidfile=/tmp/57e_gmg_/20210803114536-240117.cid \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 136.659 \\ -35.791 \\ 136.923 \\ -35.96 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif \\ B8A.tif Input file size is 5490, 5490 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job translate.cwl] Max memory used: 25MiB INFO [job translate.cwl] completed success { \"tifs\": { \"location\": \"file:///home/fbrito/work/sentinel-2-dnbr-multitemporal-cog/B8A.tif\", \"basename\": \"B8A.tif\", \"class\": \"File\", \"checksum\": \"sha1$033898bb305bb2ae53980182cd882b05cc585fa2\", \"size\": 2256036, \"path\": \"/home/fbrito/work/sentinel-2-dnbr-multitemporal-cog/B8A.tif\" } } INFO Final process status is success","title":"gdal_translate"},{"location":"gdal/gdal_translate/#gdal_translate","text":"This is a simple example of gdal_translate that reads a COG URL and does a geographic subset according to a provided boundinx box and associated EPSG code. This CWL document takes an URL to a Sentinel-2 STAC asset href pointing to a COG file and uses gdal_translate to access the desired portion of the file. The command wrapped by the CWL CommandLineTool is: gdal_translate \\ -projwin \\ 136.659 \\ -35.791 \\ 136.923 \\ -35.96 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif \\ B8A.tif The CWL document content is: class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - valueFrom : ${ return inputs.epsg; } - valueFrom : | ${ if (inputs.asset.startsWith(\"http\")) { return \"/vsicurl/\" + inputs.asset; } else { return inputs.asset; } } - valueFrom : ${ return inputs.asset.split(\"/\").slice(-1)[0]; } inputs : asset : type : string bbox : type : string epsg : type : string default : \"EPSG:4326\" outputs : tifs : outputBinding : glob : '*.tif' type : File cwlVersion : v1.0 It may be run with the parameters: bbox : \"136.659,-35.96,136.923,-35.791\" asset : https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif epsg : \"EPSG:4326\" The execution will generate: INFO /srv/conda/bin/cwltool 3.0.20210319143721 INFO Resolved 'translate.cwl' to 'file:///home/fbrito/work/sentinel-2-dnbr-multitemporal-cog/translate.cwl' INFO [job translate.cwl] /tmp/k8idc3ml$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/k8idc3ml,target=/MRizBi \\ --mount=type=bind,source=/tmp/zb8r6gau,target=/tmp \\ --workdir=/MRizBi \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/MRizBi \\ --cidfile=/tmp/57e_gmg_/20210803114536-240117.cid \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 136.659 \\ -35.791 \\ 136.923 \\ -35.96 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif \\ B8A.tif Input file size is 5490, 5490 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job translate.cwl] Max memory used: 25MiB INFO [job translate.cwl] completed success { \"tifs\": { \"location\": \"file:///home/fbrito/work/sentinel-2-dnbr-multitemporal-cog/B8A.tif\", \"basename\": \"B8A.tif\", \"class\": \"File\", \"checksum\": \"sha1$033898bb305bb2ae53980182cd882b05cc585fa2\", \"size\": 2256036, \"path\": \"/home/fbrito/work/sentinel-2-dnbr-multitemporal-cog/B8A.tif\" } } INFO Final process status is success","title":"gdal_translate"},{"location":"how-to/cwl-how-to/","text":"CWL how-to in the EO context","title":"CWL how-to in the EO context"},{"location":"how-to/cwl-how-to/#cwl-how-to-in-the-eo-context","text":"","title":"CWL how-to in the EO context"},{"location":"how-to/cwl-how-to/01-output/","text":"Run this example with: cwltool --no-container return-output-file.cwl return-output-file.yml","title":"Index"},{"location":"how-to/cwl-how-to/01-output/return-output-file/","text":"How to return an output file Questions Where does the output of a command go? How can I save the output of a command? Objectives Learn how to describe and handle outputs from a tool. Explanation The outputs of a tool is a list of output parameters that should be returned after running the tool. Each parameter has an id for the name of parameter, and type describing what types of values are valid for that parameter. When a tool runs under CWL, the starting working directory is the designated output directory. The underlying tool or script must record its results in the form of files created in the output directory. The output parameters returned by the CWL tool are either the output files themselves, or come from examining the content of those files. The following example demonstrates how to return a file generated by gdal_translate . Example 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 cwlVersion : v1.0 $graph : - class : Workflow id : main inputs : tif : type : string outputs : preview : outputSource : node_gdal/preview type : File steps : node_gdal : in : tif : tif out : - preview run : \"#gdal\" - class : CommandLineTool id : gdal requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -of - PNG - -ot - Byte - valueFrom : | ${ if (inputs.tif.startsWith(\"http\")) { return \"/vsicurl/\" + inputs.tif; } else { return inputs.tif; } } - preview.png inputs : tif : type : string outputs : preview : type : File outputBinding : glob : preview.png Parameters The parameters file return-output-file.yml contains: tif : https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif Run this how-to on Code Server Open a new terminal Execute cwltool --no-container return-output-file.cwl return-output-file.yml This will return: INFO /srv/conda/envs/notebook/bin/cwltool 3.1.20220607081835 INFO Resolved 'return-output-file.cwl' to 'file:///home/jovyan/cwl-how-to.git/01-output/return-output-file.cwl' INFO [workflow ] start INFO [workflow ] starting step node_gdal INFO [step node_gdal] start INFO [job node_gdal] /tmp/dm_vv1x5$ gdal_translate \\ -of \\ PNG \\ -ot \\ Byte \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif \\ preview.png Input file size is 5490, 5490 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_gdal] Max memory used: 53MiB INFO [job node_gdal] completed success INFO [step node_gdal] completed success INFO [workflow ] completed success { \"preview\": { \"location\": \"file:///home/jovyan/cwl-how-to.git/01-output/preview.png\", \"basename\": \"preview.png\", \"class\": \"File\", \"checksum\": \"sha1$042f63c30a8a0ddb0d83fd8f3e84301c18957daf\", \"size\": 9217085, \"path\": \"/home/jovyan/cwl-how-to.git/01-output/preview.png\" } } INFO Final process status is success Key points Outputs are described in the outputs section of a CWL description. The field outputBinding describes how to to set the value of each output parameter. Wildcards are allowed in the glob field.","title":"How to return an output file"},{"location":"how-to/cwl-how-to/01-output/return-output-file/#how-to-return-an-output-file","text":"","title":"How to return an output file"},{"location":"how-to/cwl-how-to/01-output/return-output-file/#questions","text":"Where does the output of a command go? How can I save the output of a command?","title":"Questions"},{"location":"how-to/cwl-how-to/01-output/return-output-file/#objectives","text":"Learn how to describe and handle outputs from a tool.","title":"Objectives"},{"location":"how-to/cwl-how-to/01-output/return-output-file/#explanation","text":"The outputs of a tool is a list of output parameters that should be returned after running the tool. Each parameter has an id for the name of parameter, and type describing what types of values are valid for that parameter. When a tool runs under CWL, the starting working directory is the designated output directory. The underlying tool or script must record its results in the form of files created in the output directory. The output parameters returned by the CWL tool are either the output files themselves, or come from examining the content of those files. The following example demonstrates how to return a file generated by gdal_translate .","title":"Explanation"},{"location":"how-to/cwl-how-to/01-output/return-output-file/#example","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 cwlVersion : v1.0 $graph : - class : Workflow id : main inputs : tif : type : string outputs : preview : outputSource : node_gdal/preview type : File steps : node_gdal : in : tif : tif out : - preview run : \"#gdal\" - class : CommandLineTool id : gdal requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -of - PNG - -ot - Byte - valueFrom : | ${ if (inputs.tif.startsWith(\"http\")) { return \"/vsicurl/\" + inputs.tif; } else { return inputs.tif; } } - preview.png inputs : tif : type : string outputs : preview : type : File outputBinding : glob : preview.png","title":"Example"},{"location":"how-to/cwl-how-to/01-output/return-output-file/#parameters","text":"The parameters file return-output-file.yml contains: tif : https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif","title":"Parameters"},{"location":"how-to/cwl-how-to/01-output/return-output-file/#run-this-how-to-on-code-server","text":"Open a new terminal Execute cwltool --no-container return-output-file.cwl return-output-file.yml This will return: INFO /srv/conda/envs/notebook/bin/cwltool 3.1.20220607081835 INFO Resolved 'return-output-file.cwl' to 'file:///home/jovyan/cwl-how-to.git/01-output/return-output-file.cwl' INFO [workflow ] start INFO [workflow ] starting step node_gdal INFO [step node_gdal] start INFO [job node_gdal] /tmp/dm_vv1x5$ gdal_translate \\ -of \\ PNG \\ -ot \\ Byte \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif \\ preview.png Input file size is 5490, 5490 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_gdal] Max memory used: 53MiB INFO [job node_gdal] completed success INFO [step node_gdal] completed success INFO [workflow ] completed success { \"preview\": { \"location\": \"file:///home/jovyan/cwl-how-to.git/01-output/preview.png\", \"basename\": \"preview.png\", \"class\": \"File\", \"checksum\": \"sha1$042f63c30a8a0ddb0d83fd8f3e84301c18957daf\", \"size\": 9217085, \"path\": \"/home/jovyan/cwl-how-to.git/01-output/preview.png\" } } INFO Final process status is success","title":"Run this how-to on Code Server"},{"location":"how-to/cwl-how-to/01-output/return-output-file/#key-points","text":"Outputs are described in the outputs section of a CWL description. The field outputBinding describes how to to set the value of each output parameter. Wildcards are allowed in the glob field.","title":"Key points"},{"location":"how-to/cwl-how-to/02-stdout/capture-stdout/","text":"How to capture the stdout Questions How do I capture the standard output stream of a command? Objectives Learn how to capture streamed output from a tool. CWL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 cwlVersion : v1.0 $graph : - class : Workflow id : main inputs : tif : type : string outputs : info : outputSource : gdal-info/info type : string steps : gdal-info : in : tif : tif out : - info run : \"#gdal\" - class : CommandLineTool id : gdal requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdalinfo stdout : message arguments : - valueFrom : | ${ if (inputs.tif.startsWith(\"http\")) { return \"/vsicurl/\" + inputs.tif; } else { return inputs.tif; } } inputs : tif : type : string outputs : info : type : Any outputBinding : glob : message loadContents : true outputEval : $( self[0].contents ) Parameters tif : /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif Key points Use the stdout field to specify a filename to capture streamed output. The corresponding output parameter must have type: stdout .","title":"How to capture the stdout"},{"location":"how-to/cwl-how-to/02-stdout/capture-stdout/#how-to-capture-the-stdout","text":"","title":"How to capture the stdout"},{"location":"how-to/cwl-how-to/02-stdout/capture-stdout/#questions","text":"How do I capture the standard output stream of a command?","title":"Questions"},{"location":"how-to/cwl-how-to/02-stdout/capture-stdout/#objectives","text":"Learn how to capture streamed output from a tool.","title":"Objectives"},{"location":"how-to/cwl-how-to/02-stdout/capture-stdout/#cwl","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 cwlVersion : v1.0 $graph : - class : Workflow id : main inputs : tif : type : string outputs : info : outputSource : gdal-info/info type : string steps : gdal-info : in : tif : tif out : - info run : \"#gdal\" - class : CommandLineTool id : gdal requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdalinfo stdout : message arguments : - valueFrom : | ${ if (inputs.tif.startsWith(\"http\")) { return \"/vsicurl/\" + inputs.tif; } else { return inputs.tif; } } inputs : tif : type : string outputs : info : type : Any outputBinding : glob : message loadContents : true outputEval : $( self[0].contents )","title":"CWL"},{"location":"how-to/cwl-how-to/02-stdout/capture-stdout/#parameters","text":"tif : /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif","title":"Parameters"},{"location":"how-to/cwl-how-to/02-stdout/capture-stdout/#key-points","text":"Use the stdout field to specify a filename to capture streamed output. The corresponding output parameter must have type: stdout .","title":"Key points"},{"location":"how-to/cwl-how-to/03-json-stdout/capture-json-stdout/","text":"How to capture JSON stdout and re-use it 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 cwlVersion : v1.0 $graph : - class : Workflow id : main requirements : - class : InlineJavascriptRequirement inputs : stac_item : type : string asset_id : type : string outputs : tif : outputSource : node_translate/tif type : File steps : node_stac : in : stac_item : stac_item out : - asset run : \"#stac\" node_translate : in : asset : source : node_stac/asset asset_id : asset_id out : - tif run : \"#translate\" - class : CommandLineTool id : stac requirements : InlineJavascriptRequirement : {} hints : DockerRequirement : dockerPull : docker.io/curlimages/curl:latest baseCommand : curl stdout : message arguments : - $( inputs.stac_item ) inputs : stac_item : type : string outputs : asset : type : Any outputBinding : glob : message loadContents : true outputEval : ${ return JSON.parse(self[0].contents).assets; } - class : CommandLineTool id : translate requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal:latest baseCommand : gdal_translate arguments : - valueFrom : | $( '/vsicurl/' + inputs.asset[inputs.asset_id].href ) - valueFrom : | $( inputs.asset[inputs.asset_id].href.split(\"/\").slice(-1)[0] ) inputs : asset : type : Any asset_id : type : string outputs : tif : type : File outputBinding : glob : \"*.tif\" stac_item : \"https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A\" asset_id : \"B01\"","title":"How to capture JSON stdout and re-use it"},{"location":"how-to/cwl-how-to/03-json-stdout/capture-json-stdout/#how-to-capture-json-stdout-and-re-use-it","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 cwlVersion : v1.0 $graph : - class : Workflow id : main requirements : - class : InlineJavascriptRequirement inputs : stac_item : type : string asset_id : type : string outputs : tif : outputSource : node_translate/tif type : File steps : node_stac : in : stac_item : stac_item out : - asset run : \"#stac\" node_translate : in : asset : source : node_stac/asset asset_id : asset_id out : - tif run : \"#translate\" - class : CommandLineTool id : stac requirements : InlineJavascriptRequirement : {} hints : DockerRequirement : dockerPull : docker.io/curlimages/curl:latest baseCommand : curl stdout : message arguments : - $( inputs.stac_item ) inputs : stac_item : type : string outputs : asset : type : Any outputBinding : glob : message loadContents : true outputEval : ${ return JSON.parse(self[0].contents).assets; } - class : CommandLineTool id : translate requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal:latest baseCommand : gdal_translate arguments : - valueFrom : | $( '/vsicurl/' + inputs.asset[inputs.asset_id].href ) - valueFrom : | $( inputs.asset[inputs.asset_id].href.split(\"/\").slice(-1)[0] ) inputs : asset : type : Any asset_id : type : string outputs : tif : type : File outputBinding : glob : \"*.tif\" stac_item : \"https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A\" asset_id : \"B01\"","title":"How to capture JSON stdout and re-use it"},{"location":"how-to/cwl-how-to/04-env/environment-variable/","text":"How to set environment variables Goal Tools run in a restricted environment and do not inherit most environment variables from the parent process. Environment variables are set explicitly. Recipe Environment variables are set using EnvVarRequirement . The CWL document below sets the environment variable PROJ_LIB used by gdal 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 cwlVersion : v1.0 $graph : - class : Workflow id : main requirements : - class : MultipleInputFeatureRequirement - class : ScatterFeatureRequirement inputs : red : type : string green : type : string blue : type : string outputs : preview : outputSource : node_gdal/preview type : File[] steps : node_gdal : in : band : [ red , green , blue ] out : - preview run : \"#gdal\" scatter : band scatterMethod : dotproduct - class : CommandLineTool id : gdal requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -of - PNG - -ot - Byte - -srcwin - \"100\" - \"100\" - \"100\" - \"100\" - valueFrom : $( inputs.band ) - valueFrom : $( inputs.band.split(\"/\").slice(-1)[0].replace(\".tif\", \".png\") ) inputs : band : type : string outputs : preview : type : File outputBinding : glob : \"*.png\" Execution Use the parameters: 1 2 3 red : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B04.tif' green : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B03.tif' blue : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B02.tif' The execution shows: INFO /srv/conda/bin/cwltool 3.1.20210803132435 INFO Resolved 'environment-variable.cwl' to 'file:///home/fbrito/work/guide/docs/how-to/cwl-how-to/environment-variable.cwl' INFO [workflow ] start INFO [workflow ] starting step node_gdal INFO [step node_gdal] start INFO ['docker', 'pull', 'docker.io/osgeo/gdal'] Using default tag: latest latest: Pulling from osgeo/gdal Digest: sha256:fd9cbc42d2854783451a2503d58d34f7893f42650afb07dbc91eb78a628a610d Status: Image is up to date for osgeo/gdal:latest docker.io/osgeo/gdal:latest INFO [job node_gdal] /tmp/fi5kdx7z$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/fi5kdx7z,target=/zlOvjL \\ --mount=type=bind,source=/tmp/kryustug,target=/tmp \\ --workdir=/zlOvjL \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/3re5iw68/20210908163154-211432.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/zlOvjL \\ --env=AWS_NO_SIGN_REQUEST=YES \\ --env=AWS_REGION=us-west-2 \\ docker.io/osgeo/gdal \\ gdal_translate \\ -of \\ PNG \\ -ot \\ Byte \\ -srcwin \\ 100 \\ 100 \\ 100 \\ 100 \\ /vsis3/landsat-pds/c1/L8/019/022/LC08_L1GT_019022_20170802_20170803_01_RT/LC08_L1GT_019022_20170802_20170803_01_RT_B4.TIF \\ LC08_L1GT_019022_20170802_20170803_01_RT_B4.png Input file size is 8121, 8201 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_gdal] Max memory used: 12MiB INFO [job node_gdal] completed success INFO [step node_gdal] start INFO [job node_gdal_2] /tmp/23wqf24v$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/23wqf24v,target=/zlOvjL \\ --mount=type=bind,source=/tmp/7b6chrm8,target=/tmp \\ --workdir=/zlOvjL \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/obywipov/20210908163157-530577.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/zlOvjL \\ --env=AWS_NO_SIGN_REQUEST=YES \\ --env=AWS_REGION=us-west-2 \\ docker.io/osgeo/gdal \\ gdal_translate \\ -of \\ PNG \\ -ot \\ Byte \\ -srcwin \\ 100 \\ 100 \\ 100 \\ 100 \\ /vsis3/landsat-pds/c1/L8/019/022/LC08_L1GT_019022_20170802_20170803_01_RT/LC08_L1GT_019022_20170802_20170803_01_RT_B3.TIF \\ LC08_L1GT_019022_20170802_20170803_01_RT_B3.png Input file size is 8121, 8201 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_gdal_2] Max memory used: 12MiB INFO [job node_gdal_2] completed success INFO [step node_gdal] start INFO [job node_gdal_3] /tmp/kezw74z7$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/kezw74z7,target=/zlOvjL \\ --mount=type=bind,source=/tmp/ekg38mvk,target=/tmp \\ --workdir=/zlOvjL \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/5cqb2_y9/20210908163159-929681.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/zlOvjL \\ --env=AWS_NO_SIGN_REQUEST=YES \\ --env=AWS_REGION=us-west-2 \\ docker.io/osgeo/gdal \\ gdal_translate \\ -of \\ PNG \\ -ot \\ Byte \\ -srcwin \\ 100 \\ 100 \\ 100 \\ 100 \\ /vsis3/landsat-pds/c1/L8/019/022/LC08_L1GT_019022_20170802_20170803_01_RT/LC08_L1GT_019022_20170802_20170803_01_RT_B2.TIF \\ LC08_L1GT_019022_20170802_20170803_01_RT_B2.png Input file size is 8121, 8201 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_gdal_3] Max memory used: 12MiB INFO [job node_gdal_3] completed success INFO [step node_gdal] completed success INFO [workflow ] completed success { \"preview\": [ { \"location\": \"file:///home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B4.png\", \"basename\": \"LC08_L1GT_019022_20170802_20170803_01_RT_B4.png\", \"class\": \"File\", \"checksum\": \"sha1$7888d33b413ecd247e733267cf5e9c431b04fd95\", \"size\": 90, \"path\": \"/home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B4.png\" }, { \"location\": \"file:///home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B3.png\", \"basename\": \"LC08_L1GT_019022_20170802_20170803_01_RT_B3.png\", \"class\": \"File\", \"checksum\": \"sha1$7888d33b413ecd247e733267cf5e9c431b04fd95\", \"size\": 90, \"path\": \"/home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B3.png\" }, { \"location\": \"file:///home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B2.png\", \"basename\": \"LC08_L1GT_019022_20170802_20170803_01_RT_B2.png\", \"class\": \"File\", \"checksum\": \"sha1$7888d33b413ecd247e733267cf5e9c431b04fd95\", \"size\": 90, \"path\": \"/home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B2.png\" } ] } INFO Final process status is success Reference EnvVarRequirement EnvironmentDef","title":"How to set environment variable"},{"location":"how-to/cwl-how-to/04-env/environment-variable/#how-to-set-environment-variables","text":"","title":"How to set environment variables"},{"location":"how-to/cwl-how-to/04-env/environment-variable/#goal","text":"Tools run in a restricted environment and do not inherit most environment variables from the parent process. Environment variables are set explicitly.","title":"Goal"},{"location":"how-to/cwl-how-to/04-env/environment-variable/#recipe","text":"Environment variables are set using EnvVarRequirement . The CWL document below sets the environment variable PROJ_LIB used by gdal 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 cwlVersion : v1.0 $graph : - class : Workflow id : main requirements : - class : MultipleInputFeatureRequirement - class : ScatterFeatureRequirement inputs : red : type : string green : type : string blue : type : string outputs : preview : outputSource : node_gdal/preview type : File[] steps : node_gdal : in : band : [ red , green , blue ] out : - preview run : \"#gdal\" scatter : band scatterMethod : dotproduct - class : CommandLineTool id : gdal requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -of - PNG - -ot - Byte - -srcwin - \"100\" - \"100\" - \"100\" - \"100\" - valueFrom : $( inputs.band ) - valueFrom : $( inputs.band.split(\"/\").slice(-1)[0].replace(\".tif\", \".png\") ) inputs : band : type : string outputs : preview : type : File outputBinding : glob : \"*.png\"","title":"Recipe"},{"location":"how-to/cwl-how-to/04-env/environment-variable/#execution","text":"Use the parameters: 1 2 3 red : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B04.tif' green : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B03.tif' blue : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B02.tif' The execution shows: INFO /srv/conda/bin/cwltool 3.1.20210803132435 INFO Resolved 'environment-variable.cwl' to 'file:///home/fbrito/work/guide/docs/how-to/cwl-how-to/environment-variable.cwl' INFO [workflow ] start INFO [workflow ] starting step node_gdal INFO [step node_gdal] start INFO ['docker', 'pull', 'docker.io/osgeo/gdal'] Using default tag: latest latest: Pulling from osgeo/gdal Digest: sha256:fd9cbc42d2854783451a2503d58d34f7893f42650afb07dbc91eb78a628a610d Status: Image is up to date for osgeo/gdal:latest docker.io/osgeo/gdal:latest INFO [job node_gdal] /tmp/fi5kdx7z$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/fi5kdx7z,target=/zlOvjL \\ --mount=type=bind,source=/tmp/kryustug,target=/tmp \\ --workdir=/zlOvjL \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/3re5iw68/20210908163154-211432.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/zlOvjL \\ --env=AWS_NO_SIGN_REQUEST=YES \\ --env=AWS_REGION=us-west-2 \\ docker.io/osgeo/gdal \\ gdal_translate \\ -of \\ PNG \\ -ot \\ Byte \\ -srcwin \\ 100 \\ 100 \\ 100 \\ 100 \\ /vsis3/landsat-pds/c1/L8/019/022/LC08_L1GT_019022_20170802_20170803_01_RT/LC08_L1GT_019022_20170802_20170803_01_RT_B4.TIF \\ LC08_L1GT_019022_20170802_20170803_01_RT_B4.png Input file size is 8121, 8201 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_gdal] Max memory used: 12MiB INFO [job node_gdal] completed success INFO [step node_gdal] start INFO [job node_gdal_2] /tmp/23wqf24v$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/23wqf24v,target=/zlOvjL \\ --mount=type=bind,source=/tmp/7b6chrm8,target=/tmp \\ --workdir=/zlOvjL \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/obywipov/20210908163157-530577.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/zlOvjL \\ --env=AWS_NO_SIGN_REQUEST=YES \\ --env=AWS_REGION=us-west-2 \\ docker.io/osgeo/gdal \\ gdal_translate \\ -of \\ PNG \\ -ot \\ Byte \\ -srcwin \\ 100 \\ 100 \\ 100 \\ 100 \\ /vsis3/landsat-pds/c1/L8/019/022/LC08_L1GT_019022_20170802_20170803_01_RT/LC08_L1GT_019022_20170802_20170803_01_RT_B3.TIF \\ LC08_L1GT_019022_20170802_20170803_01_RT_B3.png Input file size is 8121, 8201 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_gdal_2] Max memory used: 12MiB INFO [job node_gdal_2] completed success INFO [step node_gdal] start INFO [job node_gdal_3] /tmp/kezw74z7$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/kezw74z7,target=/zlOvjL \\ --mount=type=bind,source=/tmp/ekg38mvk,target=/tmp \\ --workdir=/zlOvjL \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/5cqb2_y9/20210908163159-929681.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/zlOvjL \\ --env=AWS_NO_SIGN_REQUEST=YES \\ --env=AWS_REGION=us-west-2 \\ docker.io/osgeo/gdal \\ gdal_translate \\ -of \\ PNG \\ -ot \\ Byte \\ -srcwin \\ 100 \\ 100 \\ 100 \\ 100 \\ /vsis3/landsat-pds/c1/L8/019/022/LC08_L1GT_019022_20170802_20170803_01_RT/LC08_L1GT_019022_20170802_20170803_01_RT_B2.TIF \\ LC08_L1GT_019022_20170802_20170803_01_RT_B2.png Input file size is 8121, 8201 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_gdal_3] Max memory used: 12MiB INFO [job node_gdal_3] completed success INFO [step node_gdal] completed success INFO [workflow ] completed success { \"preview\": [ { \"location\": \"file:///home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B4.png\", \"basename\": \"LC08_L1GT_019022_20170802_20170803_01_RT_B4.png\", \"class\": \"File\", \"checksum\": \"sha1$7888d33b413ecd247e733267cf5e9c431b04fd95\", \"size\": 90, \"path\": \"/home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B4.png\" }, { \"location\": \"file:///home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B3.png\", \"basename\": \"LC08_L1GT_019022_20170802_20170803_01_RT_B3.png\", \"class\": \"File\", \"checksum\": \"sha1$7888d33b413ecd247e733267cf5e9c431b04fd95\", \"size\": 90, \"path\": \"/home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B3.png\" }, { \"location\": \"file:///home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B2.png\", \"basename\": \"LC08_L1GT_019022_20170802_20170803_01_RT_B2.png\", \"class\": \"File\", \"checksum\": \"sha1$7888d33b413ecd247e733267cf5e9c431b04fd95\", \"size\": 90, \"path\": \"/home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B2.png\" } ] } INFO Final process status is success","title":"Execution"},{"location":"how-to/cwl-how-to/04-env/environment-variable/#reference","text":"EnvVarRequirement EnvironmentDef","title":"Reference"},{"location":"how-to/cwl-how-to/05-runtime/create-file-at-runtime/","text":"How to create a file at runtime Goal Create a file at runtime. Sometimes you need to create a file on the fly from input parameters, such as tools which expect to read their input configuration from a file rather than the command line parameters, or need a small wrapper shell script. To generate such files we can use the InitialWorkDirRequirement . Recipe The CWL document below shows a small wrapper shell script called run.sh that gets created at runtime. The basecommand is an array combining /bin/sh and the created file run.sh and it will execute the command /bin/sh run.sh . This will run the file we create in the shell. InitialWorkDirRequirement requires a listing. As the listing is a YAML array we need a - on the first line of each element of the array, in this case we have just one element. entryname : can have any value, but it must match what was specified in the baseCommand . The final part is entry :, this is followed by |- which is YAML quoting syntax, and means that you are using a multiline string (without it we would need to write the whole script on one line). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 cwlVersion : v1.0 $graph : - class : Workflow id : main requirements : - class : MultipleInputFeatureRequirement - class : ScatterFeatureRequirement inputs : red : type : string green : type : string blue : type : string outputs : preview : outputSource : node_gdal/preview type : File[] steps : node_gdal : in : band : [ red , green , blue ] out : - preview run : \"#gdal\" scatter : band scatterMethod : dotproduct - class : CommandLineTool id : gdal requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj InitialWorkDirRequirement : listing : - entryname : run.sh entry : |- gdal_translate \\ -of PNG \\ -ot Byte \\ -srcwin 1000 1000 500 500 \\ $( inputs.band ) \\ $( inputs.band.split(\"/\").slice(-1)[0].replace(\".tif\", \".png\") ) hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : [ '/bin/sh' , 'run.sh' ] arguments : [] inputs : band : type : string outputs : preview : type : File outputBinding : glob : \"*.png\" Execution Use the parameters: 1 2 3 red : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B04.tif' green : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B03.tif' blue : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B02.tif' The execution shows: INFO /srv/conda/bin/cwltool 3.1.20210803132435 INFO Resolved 'create-file-at-runtime.cwl' to 'file:///home/fbrito/work/guide/docs/how-to/cwl-how-to/create-file-at-runtime.cwl' INFO [workflow ] start INFO [workflow ] starting step node_gdal INFO [step node_gdal] start INFO ['docker', 'pull', 'docker.io/osgeo/gdal'] Using default tag: latest latest: Pulling from osgeo/gdal Digest: sha256:fd9cbc42d2854783451a2503d58d34f7893f42650afb07dbc91eb78a628a610d Status: Image is up to date for osgeo/gdal:latest docker.io/osgeo/gdal:latest INFO [job node_gdal] /tmp/50h8z4pj$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/50h8z4pj,target=/ziURtg \\ --mount=type=bind,source=/tmp/rqajh51c,target=/tmp \\ --workdir=/ziURtg \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/_igcz1hh/20210908155350-669810.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/ziURtg \\ --env=AWS_NO_SIGN_REQUEST=YES \\ --env=AWS_REGION=us-west-2 \\ docker.io/osgeo/gdal \\ /bin/sh \\ run.sh Input file size is 8121, 8201 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_gdal] Max memory used: 0MiB INFO [job node_gdal] completed success INFO [step node_gdal] start INFO [job node_gdal_2] /tmp/egb7trj8$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/egb7trj8,target=/ziURtg \\ --mount=type=bind,source=/tmp/jdzoi6gz,target=/tmp \\ --workdir=/ziURtg \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/xltuldrb/20210908155358-070807.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/ziURtg \\ --env=AWS_NO_SIGN_REQUEST=YES \\ --env=AWS_REGION=us-west-2 \\ docker.io/osgeo/gdal \\ /bin/sh \\ run.sh Input file size is 8121, 8201 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_gdal_2] Max memory used: 12MiB INFO [job node_gdal_2] completed success INFO [step node_gdal] start INFO [job node_gdal_3] /tmp/san4kbve$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/san4kbve,target=/ziURtg \\ --mount=type=bind,source=/tmp/rxdhcudk,target=/tmp \\ --workdir=/ziURtg \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/izgoa3x3/20210908155401-198012.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/ziURtg \\ --env=AWS_NO_SIGN_REQUEST=YES \\ --env=AWS_REGION=us-west-2 \\ docker.io/osgeo/gdal \\ /bin/sh \\ run.sh Input file size is 8121, 8201 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_gdal_3] Max memory used: 19MiB INFO [job node_gdal_3] completed success INFO [step node_gdal] completed success INFO [workflow ] completed success { \"preview\": [ { \"location\": \"file:///home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B4.png\", \"basename\": \"LC08_L1GT_019022_20170802_20170803_01_RT_B4.png\", \"class\": \"File\", \"checksum\": \"sha1$481bffe667120d2c41f5b9346c17db1541e56a28\", \"size\": 322, \"path\": \"/home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B4.png\" }, { \"location\": \"file:///home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B3.png\", \"basename\": \"LC08_L1GT_019022_20170802_20170803_01_RT_B3.png\", \"class\": \"File\", \"checksum\": \"sha1$481bffe667120d2c41f5b9346c17db1541e56a28\", \"size\": 322, \"path\": \"/home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B3.png\" }, { \"location\": \"file:///home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B2.png\", \"basename\": \"LC08_L1GT_019022_20170802_20170803_01_RT_B2.png\", \"class\": \"File\", \"checksum\": \"sha1$481bffe667120d2c41f5b9346c17db1541e56a28\", \"size\": 322, \"path\": \"/home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B2.png\" } ] } INFO Final process status is success Reference InitialWorkDirRequirement","title":"How to create a file at runtime"},{"location":"how-to/cwl-how-to/05-runtime/create-file-at-runtime/#how-to-create-a-file-at-runtime","text":"","title":"How to create a file at runtime"},{"location":"how-to/cwl-how-to/05-runtime/create-file-at-runtime/#goal","text":"Create a file at runtime. Sometimes you need to create a file on the fly from input parameters, such as tools which expect to read their input configuration from a file rather than the command line parameters, or need a small wrapper shell script. To generate such files we can use the InitialWorkDirRequirement .","title":"Goal"},{"location":"how-to/cwl-how-to/05-runtime/create-file-at-runtime/#recipe","text":"The CWL document below shows a small wrapper shell script called run.sh that gets created at runtime. The basecommand is an array combining /bin/sh and the created file run.sh and it will execute the command /bin/sh run.sh . This will run the file we create in the shell. InitialWorkDirRequirement requires a listing. As the listing is a YAML array we need a - on the first line of each element of the array, in this case we have just one element. entryname : can have any value, but it must match what was specified in the baseCommand . The final part is entry :, this is followed by |- which is YAML quoting syntax, and means that you are using a multiline string (without it we would need to write the whole script on one line). 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 cwlVersion : v1.0 $graph : - class : Workflow id : main requirements : - class : MultipleInputFeatureRequirement - class : ScatterFeatureRequirement inputs : red : type : string green : type : string blue : type : string outputs : preview : outputSource : node_gdal/preview type : File[] steps : node_gdal : in : band : [ red , green , blue ] out : - preview run : \"#gdal\" scatter : band scatterMethod : dotproduct - class : CommandLineTool id : gdal requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj InitialWorkDirRequirement : listing : - entryname : run.sh entry : |- gdal_translate \\ -of PNG \\ -ot Byte \\ -srcwin 1000 1000 500 500 \\ $( inputs.band ) \\ $( inputs.band.split(\"/\").slice(-1)[0].replace(\".tif\", \".png\") ) hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : [ '/bin/sh' , 'run.sh' ] arguments : [] inputs : band : type : string outputs : preview : type : File outputBinding : glob : \"*.png\"","title":"Recipe"},{"location":"how-to/cwl-how-to/05-runtime/create-file-at-runtime/#execution","text":"Use the parameters: 1 2 3 red : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B04.tif' green : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B03.tif' blue : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B02.tif' The execution shows: INFO /srv/conda/bin/cwltool 3.1.20210803132435 INFO Resolved 'create-file-at-runtime.cwl' to 'file:///home/fbrito/work/guide/docs/how-to/cwl-how-to/create-file-at-runtime.cwl' INFO [workflow ] start INFO [workflow ] starting step node_gdal INFO [step node_gdal] start INFO ['docker', 'pull', 'docker.io/osgeo/gdal'] Using default tag: latest latest: Pulling from osgeo/gdal Digest: sha256:fd9cbc42d2854783451a2503d58d34f7893f42650afb07dbc91eb78a628a610d Status: Image is up to date for osgeo/gdal:latest docker.io/osgeo/gdal:latest INFO [job node_gdal] /tmp/50h8z4pj$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/50h8z4pj,target=/ziURtg \\ --mount=type=bind,source=/tmp/rqajh51c,target=/tmp \\ --workdir=/ziURtg \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/_igcz1hh/20210908155350-669810.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/ziURtg \\ --env=AWS_NO_SIGN_REQUEST=YES \\ --env=AWS_REGION=us-west-2 \\ docker.io/osgeo/gdal \\ /bin/sh \\ run.sh Input file size is 8121, 8201 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_gdal] Max memory used: 0MiB INFO [job node_gdal] completed success INFO [step node_gdal] start INFO [job node_gdal_2] /tmp/egb7trj8$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/egb7trj8,target=/ziURtg \\ --mount=type=bind,source=/tmp/jdzoi6gz,target=/tmp \\ --workdir=/ziURtg \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/xltuldrb/20210908155358-070807.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/ziURtg \\ --env=AWS_NO_SIGN_REQUEST=YES \\ --env=AWS_REGION=us-west-2 \\ docker.io/osgeo/gdal \\ /bin/sh \\ run.sh Input file size is 8121, 8201 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_gdal_2] Max memory used: 12MiB INFO [job node_gdal_2] completed success INFO [step node_gdal] start INFO [job node_gdal_3] /tmp/san4kbve$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/san4kbve,target=/ziURtg \\ --mount=type=bind,source=/tmp/rxdhcudk,target=/tmp \\ --workdir=/ziURtg \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/izgoa3x3/20210908155401-198012.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/ziURtg \\ --env=AWS_NO_SIGN_REQUEST=YES \\ --env=AWS_REGION=us-west-2 \\ docker.io/osgeo/gdal \\ /bin/sh \\ run.sh Input file size is 8121, 8201 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_gdal_3] Max memory used: 19MiB INFO [job node_gdal_3] completed success INFO [step node_gdal] completed success INFO [workflow ] completed success { \"preview\": [ { \"location\": \"file:///home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B4.png\", \"basename\": \"LC08_L1GT_019022_20170802_20170803_01_RT_B4.png\", \"class\": \"File\", \"checksum\": \"sha1$481bffe667120d2c41f5b9346c17db1541e56a28\", \"size\": 322, \"path\": \"/home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B4.png\" }, { \"location\": \"file:///home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B3.png\", \"basename\": \"LC08_L1GT_019022_20170802_20170803_01_RT_B3.png\", \"class\": \"File\", \"checksum\": \"sha1$481bffe667120d2c41f5b9346c17db1541e56a28\", \"size\": 322, \"path\": \"/home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B3.png\" }, { \"location\": \"file:///home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B2.png\", \"basename\": \"LC08_L1GT_019022_20170802_20170803_01_RT_B2.png\", \"class\": \"File\", \"checksum\": \"sha1$481bffe667120d2c41f5b9346c17db1541e56a28\", \"size\": 322, \"path\": \"/home/fbrito/work/guide/docs/how-to/cwl-how-to/LC08_L1GT_019022_20170802_20170803_01_RT_B2.png\" } ] } INFO Final process status is success","title":"Execution"},{"location":"how-to/cwl-how-to/05-runtime/create-file-at-runtime/#reference","text":"InitialWorkDirRequirement","title":"Reference"},{"location":"how-to/cwl-how-to/06-nested-workflows/nested-workflow/","text":"How to create nested workflows 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 cwlVersion : v1.0 $graph : - class : Workflow id : main requirements : - class : ScatterFeatureRequirement - class : SubworkflowFeatureRequirement inputs : red : type : string green : type : string blue : type : string product : type : string[] outputs : preview : outputSource : node_clip/preview type : type : array items : type : array items : File steps : node_clip : run : \"#clipper\" in : red : red green : green blue : blue product : product out : - preview scatter : product scatterMethod : dotproduct - class : Workflow id : clipper requirements : - class : MultipleInputFeatureRequirement - class : ScatterFeatureRequirement inputs : red : type : string green : type : string blue : type : string product : type : string outputs : preview : outputSource : node_gdal/preview type : File[] steps : node_gdal : in : band : [ red , green , blue ] product : product out : - preview run : \"#gdal\" scatter : band scatterMethod : dotproduct - class : CommandLineTool id : gdal requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -of - PNG - -ot - Byte - -srcwin - \"1000\" - \"1000\" - \"500\" - \"500\" - valueFrom : $( inputs.product + \"/\" + inputs.band + \".tif\") - valueFrom : $( inputs.product.split(\"/\").slice(-1)[0] + \"_\" + inputs.band + \".png\" ) inputs : product : type : string band : type : string outputs : preview : type : File outputBinding : glob : \"*.png\" product : - 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A' - 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210723_0_L2A' red : \"B04\" green : \"B03\" blue : \"B02\"","title":"How to create nested workflows"},{"location":"how-to/cwl-how-to/06-nested-workflows/nested-workflow/#how-to-create-nested-workflows","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 cwlVersion : v1.0 $graph : - class : Workflow id : main requirements : - class : ScatterFeatureRequirement - class : SubworkflowFeatureRequirement inputs : red : type : string green : type : string blue : type : string product : type : string[] outputs : preview : outputSource : node_clip/preview type : type : array items : type : array items : File steps : node_clip : run : \"#clipper\" in : red : red green : green blue : blue product : product out : - preview scatter : product scatterMethod : dotproduct - class : Workflow id : clipper requirements : - class : MultipleInputFeatureRequirement - class : ScatterFeatureRequirement inputs : red : type : string green : type : string blue : type : string product : type : string outputs : preview : outputSource : node_gdal/preview type : File[] steps : node_gdal : in : band : [ red , green , blue ] product : product out : - preview run : \"#gdal\" scatter : band scatterMethod : dotproduct - class : CommandLineTool id : gdal requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -of - PNG - -ot - Byte - -srcwin - \"1000\" - \"1000\" - \"500\" - \"500\" - valueFrom : $( inputs.product + \"/\" + inputs.band + \".tif\") - valueFrom : $( inputs.product.split(\"/\").slice(-1)[0] + \"_\" + inputs.band + \".png\" ) inputs : product : type : string band : type : string outputs : preview : type : File outputBinding : glob : \"*.png\" product : - 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A' - 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210723_0_L2A' red : \"B04\" green : \"B03\" blue : \"B02\"","title":"How to create nested workflows"},{"location":"how-to/cwl-how-to/07-scatter-workflows/scatter-input-parameters/","text":"How to scatter on input parameters 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 cwlVersion : v1.0 $graph : - class : Workflow id : main requirements : - class : MultipleInputFeatureRequirement - class : ScatterFeatureRequirement inputs : red : type : string green : type : string blue : type : string outputs : preview : outputSource : node_gdal/preview type : File[] steps : node_gdal : in : band : [ red , green , blue ] out : - preview run : \"#gdal\" scatter : band scatterMethod : dotproduct - class : CommandLineTool id : gdal requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -of - PNG - -ot - Byte - -srcwin - \"100\" - \"100\" - \"100\" - \"100\" - valueFrom : | ${ if (inputs.band.startsWith(\"http\")) { return \"/vsicurl/\" + inputs.band; } else { return inputs.band; } } - valueFrom : | ${ if (inputs.band.startsWith(\"http\")) { return inputs.band.split(\"/\").slice(-1)[0].replace(\".tif\", \".png\"); } else { return inputs.band.replace(\".tif\", \".png\"); } } inputs : band : type : string outputs : preview : type : File outputBinding : glob : \"*.png\" red : 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B04.tif' green : 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B03.tif' blue : 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B02.tif'","title":"How to scatter on input parameters"},{"location":"how-to/cwl-how-to/07-scatter-workflows/scatter-input-parameters/#how-to-scatter-on-input-parameters","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 cwlVersion : v1.0 $graph : - class : Workflow id : main requirements : - class : MultipleInputFeatureRequirement - class : ScatterFeatureRequirement inputs : red : type : string green : type : string blue : type : string outputs : preview : outputSource : node_gdal/preview type : File[] steps : node_gdal : in : band : [ red , green , blue ] out : - preview run : \"#gdal\" scatter : band scatterMethod : dotproduct - class : CommandLineTool id : gdal requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -of - PNG - -ot - Byte - -srcwin - \"100\" - \"100\" - \"100\" - \"100\" - valueFrom : | ${ if (inputs.band.startsWith(\"http\")) { return \"/vsicurl/\" + inputs.band; } else { return inputs.band; } } - valueFrom : | ${ if (inputs.band.startsWith(\"http\")) { return inputs.band.split(\"/\").slice(-1)[0].replace(\".tif\", \".png\"); } else { return inputs.band.replace(\".tif\", \".png\"); } } inputs : band : type : string outputs : preview : type : File outputBinding : glob : \"*.png\" red : 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B04.tif' green : 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B03.tif' blue : 'https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B02.tif'","title":"How to scatter on input parameters"},{"location":"how-to/cwl-how-to/08-conditional-workflows/conditional-workflows/","text":"How to create conditional workflows 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 cwlVersion : v1.2 $graph : - class : Workflow id : main requirements : - class : MultipleInputFeatureRequirement - class : ScatterFeatureRequirement - class : InlineJavascriptRequirement inputs : red : type : string green : type : string blue : type : string epsg_code : type : string outputs : preview : type : File[] outputSource : - node_warp/preview - node_translate/preview pickValue : all_non_null linkMerge : merge_flattened steps : node_translate : in : band : [ red , green , blue ] epsg_code : epsg_code out : - preview run : \"#translate\" when : $( inputs.epsg_code == \"native\") scatter : band scatterMethod : dotproduct node_warp : in : band : [ red , green , blue ] epsg_code : epsg_code out : - preview run : \"#warp\" when : $( inputs.epsg_code != \"native\") scatter : band scatterMethod : dotproduct - class : CommandLineTool id : translate requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj NetworkAccess : networkAccess : true hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -of - COG - -ot - Byte - valueFrom : $( inputs.band ) - valueFrom : $( inputs.band.split(\"/\").slice(-1)[0] ) inputs : band : type : string outputs : preview : type : File outputBinding : glob : \"*.tif\" - class : CommandLineTool id : warp requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj NetworkAccess : networkAccess : true hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdalwarp arguments : - -of - COG - -ot - Byte - -t_srs - valueFrom : $( inputs.epsg_code ) - valueFrom : $( inputs.band ) - valueFrom : $( inputs.band.split(\"/\").slice(-1)[0].replace(\".TIF\", \".tif\") ) inputs : band : type : string epsg_code : type : string outputs : preview : type : File outputBinding : glob : \"*.tif\" red : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B04.tif' green : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B03.tif' blue : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B02.tif' epsg_code : \"EPSG:4326\" # epsg_code: \"native\" Reference Conditional_execution WorkflowOutputParameter PickValueMethod LinkMergeMethod","title":"How to create conditional workflows"},{"location":"how-to/cwl-how-to/08-conditional-workflows/conditional-workflows/#how-to-create-conditional-workflows","text":"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 cwlVersion : v1.2 $graph : - class : Workflow id : main requirements : - class : MultipleInputFeatureRequirement - class : ScatterFeatureRequirement - class : InlineJavascriptRequirement inputs : red : type : string green : type : string blue : type : string epsg_code : type : string outputs : preview : type : File[] outputSource : - node_warp/preview - node_translate/preview pickValue : all_non_null linkMerge : merge_flattened steps : node_translate : in : band : [ red , green , blue ] epsg_code : epsg_code out : - preview run : \"#translate\" when : $( inputs.epsg_code == \"native\") scatter : band scatterMethod : dotproduct node_warp : in : band : [ red , green , blue ] epsg_code : epsg_code out : - preview run : \"#warp\" when : $( inputs.epsg_code != \"native\") scatter : band scatterMethod : dotproduct - class : CommandLineTool id : translate requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj NetworkAccess : networkAccess : true hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdal_translate arguments : - -of - COG - -ot - Byte - valueFrom : $( inputs.band ) - valueFrom : $( inputs.band.split(\"/\").slice(-1)[0] ) inputs : band : type : string outputs : preview : type : File outputBinding : glob : \"*.tif\" - class : CommandLineTool id : warp requirements : InlineJavascriptRequirement : {} EnvVarRequirement : envDef : PROJ_LIB : /srv/conda/envs/notebook/share/proj NetworkAccess : networkAccess : true hints : DockerRequirement : dockerPull : docker.io/osgeo/gdal baseCommand : gdalwarp arguments : - -of - COG - -ot - Byte - -t_srs - valueFrom : $( inputs.epsg_code ) - valueFrom : $( inputs.band ) - valueFrom : $( inputs.band.split(\"/\").slice(-1)[0].replace(\".TIF\", \".tif\") ) inputs : band : type : string epsg_code : type : string outputs : preview : type : File outputBinding : glob : \"*.tif\" red : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B04.tif' green : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B03.tif' blue : '/vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/10/T/FK/2021/7/S2B_10TFK_20210713_0_L2A/B02.tif' epsg_code : \"EPSG:4326\" # epsg_code: \"native\"","title":"How to create conditional workflows"},{"location":"how-to/cwl-how-to/08-conditional-workflows/conditional-workflows/#reference","text":"Conditional_execution WorkflowOutputParameter PickValueMethod LinkMergeMethod","title":"Reference"},{"location":"how-to/cwl-how-to/08-conditional-workflows/inline-python/","text":"Inline Python","title":"Inline python"},{"location":"how-to/cwl-how-to/08-conditional-workflows/inline-python/#inline-python","text":"","title":"Inline Python"},{"location":"otb/","text":"Orfeo ToolBox (OTB)","title":"Orfeo ToolBox (OTB)"},{"location":"otb/#orfeo-toolbox-otb","text":"","title":"Orfeo ToolBox (OTB)"},{"location":"otb/bandmathx/","text":"BandMathX Objective This tutorial targets creating a CWL document wrapping the Orfeo Toolbox (OTB) octbcli-BandMathX : otbcli_BandMathX \\ -out \\ S2B_53HPA_20210723_0_L2A.tif \\ -exp \\ '(im3b1 == 8 or im3b1 == 9 or im3b1 == 0 or im3b1 == 1 or im3b1 == 2 or im3b1 == 10 or im3b1 == 11) ? -2 : (im1b1 - im2b1) / (im1b1 + im2b1)' \\ -il \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B12.tif \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/SCL.tif Use an editor to create the file band_math.cwl and copy/paste the CWL content below: class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : docker.io/terradue/otb-7.2.0 baseCommand : otbcli_BandMathX arguments : - -out - valueFrom : ${ return inputs.stac_item.split(\"/\").slice(-1)[0] + \".tif\"; } - -exp - '(im3b1 == 8 or im3b1 == 9 or im3b1 == 0 or im3b1 == 1 or im3b1 == 2 or im3b1 == 10 or im3b1 == 11) ? -2 : (im1b1 - im2b1) / (im1b1 + im2b1)' inputs : tifs : type : string[] inputBinding : position : 5 prefix : -il separate : true stac_item : type : string outputs : nbr : outputBinding : glob : \"*.tif\" type : File cwlVersion : v1.0 Now create the parameters file band_math.yml with: stac_item : \"https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A\" tifs : - /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif - /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B12.tif - /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/SCL.tif Use cwltool to trigger an execution: cwltool band_math.cwl band_math.yml The execution will generate: INFO /srv/conda/bin/cwltool 3.0.20210319143721 INFO Resolved 'band_math.cwl' to 'file:///home/fbrito/work/otb/bandmathx/band_math.cwl' INFO [job band_math.cwl] /tmp/auat4iwq$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/auat4iwq,target=/TpzBuz \\ --mount=type=bind,source=/tmp/f5kk5k5o,target=/tmp \\ --workdir=/TpzBuz \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/TpzBuz \\ --cidfile=/tmp/rt3b0xri/20210803121503-843162.cid \\ terradue/otb-7.2.0 \\ otbcli_BandMathX \\ -out \\ S2B_53HPA_20210723_0_L2A.tif \\ -exp \\ '(im3b1 == 8 or im3b1 == 9 or im3b1 == 0 or im3b1 == 1 or im3b1 == 2 or im3b1 == 10 or im3b1 == 11) ? -2 : (im1b1 - im2b1) / (im1b1 + im2b1)' \\ -il \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B12.tif \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/SCL.tif 2021-08-03 10:16:52 (INFO) BandMathX: Default RAM limit for OTB is 256 MB 2021-08-03 10:16:52 (INFO) BandMathX: GDAL maximum cache size is 3197 MB 2021-08-03 10:16:52 (INFO) BandMathX: OTB will use at most 16 threads 2021-08-03 10:16:52 (INFO) BandMathX: Image #1 has 1 components 2021-08-03 10:16:52 (INFO) BandMathX: Image #2 has 1 components 2021-08-03 10:16:52 (INFO) BandMathX: Image #3 has 1 components 2021-08-03 10:16:52 (INFO) BandMathX: Using expression: (im3b1 == 8 or im3b1 == 9 or im3b1 == 0 or im3b1 == 1 or im3b1 == 2 or im3b1 == 10 or im3b1 == 11) ? -2 : (im1b1 - im2b1) / (im1b1 + im2b1) 2021-08-03 10:16:52 (INFO): Estimated memory for full processing: 574.839MB (avail.: 256 MB), optimal image partitioning: 3 blocks 2021-08-03 10:16:52 (INFO): File S2B_53HPA_20210723_0_L2A.tif will be written in 4 blocks of 3072x3072 pixels Writing S2B_53HPA_20210723_0_L2A.tif...: 100% [**************************************************] (26s) INFO [job band_math.cwl] Max memory used: 338MiB INFO [job band_math.cwl] completed success { \"nbr\": { \"location\": \"file:///home/fbrito/work/otb/bandmathx/S2B_53HPA_20210723_0_L2A.tif\", \"basename\": \"S2B_53HPA_20210723_0_L2A.tif\", \"class\": \"File\", \"checksum\": \"sha1$6f1b9a5230e53d9bf30ee1c1b09b8aa2e9d45d6b\", \"size\": 120604786, \"path\": \"/home/fbrito/work/otb/bandmathx/S2B_53HPA_20210723_0_L2A.tif\" } } INFO Final process status is success","title":"BandMathX"},{"location":"otb/bandmathx/#bandmathx","text":"","title":"BandMathX"},{"location":"otb/bandmathx/#objective","text":"This tutorial targets creating a CWL document wrapping the Orfeo Toolbox (OTB) octbcli-BandMathX : otbcli_BandMathX \\ -out \\ S2B_53HPA_20210723_0_L2A.tif \\ -exp \\ '(im3b1 == 8 or im3b1 == 9 or im3b1 == 0 or im3b1 == 1 or im3b1 == 2 or im3b1 == 10 or im3b1 == 11) ? -2 : (im1b1 - im2b1) / (im1b1 + im2b1)' \\ -il \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B12.tif \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/SCL.tif Use an editor to create the file band_math.cwl and copy/paste the CWL content below: class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : docker.io/terradue/otb-7.2.0 baseCommand : otbcli_BandMathX arguments : - -out - valueFrom : ${ return inputs.stac_item.split(\"/\").slice(-1)[0] + \".tif\"; } - -exp - '(im3b1 == 8 or im3b1 == 9 or im3b1 == 0 or im3b1 == 1 or im3b1 == 2 or im3b1 == 10 or im3b1 == 11) ? -2 : (im1b1 - im2b1) / (im1b1 + im2b1)' inputs : tifs : type : string[] inputBinding : position : 5 prefix : -il separate : true stac_item : type : string outputs : nbr : outputBinding : glob : \"*.tif\" type : File cwlVersion : v1.0 Now create the parameters file band_math.yml with: stac_item : \"https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A\" tifs : - /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif - /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B12.tif - /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/SCL.tif Use cwltool to trigger an execution: cwltool band_math.cwl band_math.yml The execution will generate: INFO /srv/conda/bin/cwltool 3.0.20210319143721 INFO Resolved 'band_math.cwl' to 'file:///home/fbrito/work/otb/bandmathx/band_math.cwl' INFO [job band_math.cwl] /tmp/auat4iwq$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/auat4iwq,target=/TpzBuz \\ --mount=type=bind,source=/tmp/f5kk5k5o,target=/tmp \\ --workdir=/TpzBuz \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/TpzBuz \\ --cidfile=/tmp/rt3b0xri/20210803121503-843162.cid \\ terradue/otb-7.2.0 \\ otbcli_BandMathX \\ -out \\ S2B_53HPA_20210723_0_L2A.tif \\ -exp \\ '(im3b1 == 8 or im3b1 == 9 or im3b1 == 0 or im3b1 == 1 or im3b1 == 2 or im3b1 == 10 or im3b1 == 11) ? -2 : (im1b1 - im2b1) / (im1b1 + im2b1)' \\ -il \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B12.tif \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/SCL.tif 2021-08-03 10:16:52 (INFO) BandMathX: Default RAM limit for OTB is 256 MB 2021-08-03 10:16:52 (INFO) BandMathX: GDAL maximum cache size is 3197 MB 2021-08-03 10:16:52 (INFO) BandMathX: OTB will use at most 16 threads 2021-08-03 10:16:52 (INFO) BandMathX: Image #1 has 1 components 2021-08-03 10:16:52 (INFO) BandMathX: Image #2 has 1 components 2021-08-03 10:16:52 (INFO) BandMathX: Image #3 has 1 components 2021-08-03 10:16:52 (INFO) BandMathX: Using expression: (im3b1 == 8 or im3b1 == 9 or im3b1 == 0 or im3b1 == 1 or im3b1 == 2 or im3b1 == 10 or im3b1 == 11) ? -2 : (im1b1 - im2b1) / (im1b1 + im2b1) 2021-08-03 10:16:52 (INFO): Estimated memory for full processing: 574.839MB (avail.: 256 MB), optimal image partitioning: 3 blocks 2021-08-03 10:16:52 (INFO): File S2B_53HPA_20210723_0_L2A.tif will be written in 4 blocks of 3072x3072 pixels Writing S2B_53HPA_20210723_0_L2A.tif...: 100% [**************************************************] (26s) INFO [job band_math.cwl] Max memory used: 338MiB INFO [job band_math.cwl] completed success { \"nbr\": { \"location\": \"file:///home/fbrito/work/otb/bandmathx/S2B_53HPA_20210723_0_L2A.tif\", \"basename\": \"S2B_53HPA_20210723_0_L2A.tif\", \"class\": \"File\", \"checksum\": \"sha1$6f1b9a5230e53d9bf30ee1c1b09b8aa2e9d45d6b\", \"size\": 120604786, \"path\": \"/home/fbrito/work/otb/bandmathx/S2B_53HPA_20210723_0_L2A.tif\" } } INFO Final process status is success","title":"Objective"},{"location":"otb/landsat-8-mosaic/","text":"Pansharpened Landsat-8 mosaic This CWL workflow performs a mosaic of Landsat-8 acquisitions including the pan-sharpening","title":"True color mosaic"},{"location":"otb/landsat-8-mosaic/#pansharpened-landsat-8-mosaic","text":"This CWL workflow performs a mosaic of Landsat-8 acquisitions including the pan-sharpening","title":"Pansharpened Landsat-8 mosaic"},{"location":"otb/landsat-8-pan-sharpening/","text":"Landsat-8 pan-sharpening Goal Use CWL to orchestrate the steps required to create a pan-sharpened Landsat-8 RGB composite. Steps The CWL Workflow steps are depicted as a diagram: graph TD A[stac xs] --> C[subset xs] B[stac p] --> D[subset p] C --> E[concatenate xs] D --> F[bundle_to_perfect] E --> F Where: stac xs step resolves the Landsat-8 STAC item assets B4, B3, B2 hrefs. These steps are scattered by CWL stac p step resolves the Landsat-8 STAC item asset B6. subset xs and subset p use GDAL gdal_translate to clip the reference COG file to the area of interest (provided as a parameter) concatenate xs uses OTB otbcli_ConcatenateImages to stack the RGB bands as a single geotiff file bundle_to_perfect uses OTB otbcli_BundleToPerfectSensor to perform the pan-sharpening stac xs and stac p These steps invoke the asset.cwl CWL Workflow to resolve the Landsat-8 STAC Item asset href. The CommandLineTool uses curl and jq to get the Landsat-8 STAC Item and parse its JSON content: class : CommandLineTool requirements : DockerRequirement : dockerPull : terradue/jq ShellCommandRequirement : {} InlineJavascriptRequirement : {} baseCommand : curl arguments : - -s - $(inputs.stac_item) - \"|\" - jq - .assets.$(inputs.asset).href - \"|\" - tr - -d - '\\\"' #\\\"\" stdout : message inputs : stac_item : type : string asset : type : string outputs : asset_href : type : string outputBinding : glob : message loadContents : true outputEval : $( self[0].contents.split(\"\\n\").join(\"\") ) cwlVersion : v1.0 subset xs and subset p These steps invoke GDAL's gdal_translate to clip the COG to tha area of interest. class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - valueFrom : ${ return inputs.epsg; } - valueFrom : | ${ if (inputs.asset.startsWith(\"http\")) { return \"/vsicurl/\" + inputs.asset; } else { return inputs.asset; } } - valueFrom : ${ return inputs.asset.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset : type : string bbox : type : string epsg : type : string default : \"EPSG:4326\" outputs : tifs : outputBinding : glob : '*.tif' type : File stderr : stderr stdout : stdout cwlVersion : v1.0 concatenate xs class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : terradue/otb-7.2.0 baseCommand : otbcli_ConcatenateImages arguments : - -out - xs_stack.tif inputs : tifs : type : File[] inputBinding : position : 5 prefix : -il separate : true outputs : xs_stack : outputBinding : glob : \"xs_stack.tif\" type : File stderr : stderr stdout : stdout cwlVersion : v1.0 bundle_to_perfect class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : terradue/otb-7.2.0 baseCommand : otbcli_BundleToPerfectSensor arguments : - -out - pan-sharpen.tif inputs : xs : type : File inputBinding : position : 2 prefix : -inxs separate : true pan : type : File inputBinding : position : 3 prefix : -inp separate : true outputs : pan-sharpened : outputBinding : glob : \"*.tif\" type : File stderr : stderr stdout : stdout cwlVersion : v1.0 Workflow $graph : - class : Workflow label : Landsat-8 pan-sharpening doc : Landsat-8 pan-sharpening id : main requirements : - class : ScatterFeatureRequirement - class : MultipleInputFeatureRequirement inputs : stac_item : doc : Landsat-8 item type : string aoi : doc : area of interest as a bounding box type : string red : type : string default : \"B4\" green : type : string default : \"B3\" blue : type : string default : \"B2\" p_band : type : string default : \"B8\" outputs : ps_tif : outputSource : - node_bundle_to_perfect/pan-sharpened type : File steps : node_stac_xs : run : asset.cwl in : stac_item : stac_item asset : [ red , green , blue ] out : - asset_href scatter : asset_href scatterMethod : dotproduct node_stac_p : run : asset.cwl in : stac_item : stac_item asset : p_band out : - asset_href node_subset_xs : run : translate.cwl in : asset_href : source : node_stac_xs/asset_href bbox : aoi out : - tifs scatter : asset_href scatterMethod : dotproduct node_subset_p : run : translate.cwl in : asset : source : node_stac_p/asset_href bbox : aoi out : - tifs node_concatenate : run : concatenate.cwl in : tifs : source : [ node_subset_xs/tifs ] out : - xs_stack node_bundle_to_perfect : run : bundle_to_perfect.cwl in : xs : source : [ node_concatenate/xs_stack ] pan : source : [ node_subset_p/tifs ] out : - pan-sharpened cwlVersion : v1.0 Execute the Workflow The file pan-sharpening.yml contains the parameters to invoke the CWL Workflow: stac_item : \"https://landsat-stac.s3.amazonaws.com/landsat-8-l1/189/034/2020-04-27/LC81890342020118.json\" aoi : \"13.024,36.69,14.7,38.247\" The CWL workflow is executed with: cwltool --parallel pan-sharpening.cwl pan-sharpening.yml This will output: INFO /srv/conda/bin/cwltool 3.1.20210628163208 INFO Resolved 'pan-sharpening.cwl' to 'file:///home/fbrito/work/guide/docs/otb/landsat-8-pan-sharpening/pan-sharpening.cwl' INFO [workflow ] starting step node_stac_p INFO [step node_stac_p] start INFO [workflow ] start INFO [workflow ] starting step node_stac_xs INFO [step node_stac_xs] start INFO [step node_stac_xs] start INFO [step node_stac_xs] start INFO [job node_stac_p] /tmp/ocp1fize$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/ocp1fize,target=/SylLdp \\ --mount=type=bind,source=/tmp/rdlm1sb2,target=/tmp \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/_yul_u6l/20210804173603-213866.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ terradue/jq \\ /bin/sh \\ -c \\ 'curl' '-s' 'https://landsat-stac.s3.amazonaws.com/landsat-8-l1/189/034/2020-04-27/LC81890342020118.json' | 'jq' '.assets.B8.href' | 'tr' '-d' \\\" > /tmp/ocp1fize/message INFO [job node_stac_xs] /tmp/5hactbmn$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/5hactbmn,target=/SylLdp \\ --mount=type=bind,source=/tmp/jes964z4,target=/tmp \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/hj367hhm/20210804173603-232079.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ terradue/jq \\ /bin/sh \\ -c \\ 'curl' '-s' 'https://landsat-stac.s3.amazonaws.com/landsat-8-l1/189/034/2020-04-27/LC81890342020118.json' | 'jq' '.assets.B4.href' | 'tr' '-d' \\\" > /tmp/5hactbmn/message INFO [job node_stac_xs_2] /tmp/em8f13in$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/em8f13in,target=/SylLdp \\ --mount=type=bind,source=/tmp/88eyxi1x,target=/tmp \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/tbsqgf5p/20210804173603-235855.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ terradue/jq \\ /bin/sh \\ -c \\ 'curl' '-s' 'https://landsat-stac.s3.amazonaws.com/landsat-8-l1/189/034/2020-04-27/LC81890342020118.json' | 'jq' '.assets.B3.href' | 'tr' '-d' \\\" > /tmp/em8f13in/message INFO [job node_stac_xs_3] /tmp/xd0fmqxi$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/xd0fmqxi,target=/SylLdp \\ --mount=type=bind,source=/tmp/2clk49jo,target=/tmp \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/v7kn3_ek/20210804173603-242940.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ terradue/jq \\ /bin/sh \\ -c \\ 'curl' '-s' 'https://landsat-stac.s3.amazonaws.com/landsat-8-l1/189/034/2020-04-27/LC81890342020118.json' | 'jq' '.assets.B2.href' | 'tr' '-d' \\\" > /tmp/xd0fmqxi/message INFO [job node_stac_xs] Max memory used: 0MiB INFO [job node_stac_xs_2] Max memory used: 0MiB INFO [job node_stac_p] Max memory used: 0MiB INFO [job node_stac_xs_3] Max memory used: 0MiB INFO [job node_stac_xs] completed success INFO [job node_stac_xs_2] completed success INFO [job node_stac_p] completed success INFO [step node_stac_p] completed success INFO [workflow ] starting step node_subset_p INFO [step node_subset_p] start INFO [job node_stac_xs_3] completed success INFO [step node_stac_xs] completed success INFO [workflow ] starting step node_subset_xs INFO [step node_subset_xs] start INFO [step node_subset_xs] start INFO [step node_subset_xs] start INFO [job node_subset_p] /tmp/3zglf_2v$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/3zglf_2v,target=/SylLdp \\ --mount=type=bind,source=/tmp/0r8_x_fp,target=/tmp \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/rq8yfpxp/20210804173606-799825.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 13.024 \\ 38.247 \\ 14.7 \\ 36.69 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B8.TIF \\ LC08_L1TP_189034_20200427_20200509_01_T1_B8.tif > /tmp/3zglf_2v/stdout 2> /tmp/3zglf_2v/stderr INFO [job node_subset_xs_3] /tmp/stcmw6jr$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/stcmw6jr,target=/SylLdp \\ --mount=type=bind,source=/tmp/3hvmk29c,target=/tmp \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/vu17p2ii/20210804173606-835032.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 13.024 \\ 38.247 \\ 14.7 \\ 36.69 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B2.TIF \\ LC08_L1TP_189034_20200427_20200509_01_T1_B2.tif > /tmp/stcmw6jr/stdout 2> /tmp/stcmw6jr/stderr INFO [job node_subset_xs] /tmp/qyw2_zpj$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/qyw2_zpj,target=/SylLdp \\ --mount=type=bind,source=/tmp/i_rk2a9p,target=/tmp \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/l0jw9g8d/20210804173606-884892.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 13.024 \\ 38.247 \\ 14.7 \\ 36.69 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B4.TIF \\ LC08_L1TP_189034_20200427_20200509_01_T1_B4.tif > /tmp/qyw2_zpj/stdout 2> /tmp/qyw2_zpj/stderr INFO [job node_subset_xs_2] /tmp/ec2vd8nr$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/ec2vd8nr,target=/SylLdp \\ --mount=type=bind,source=/tmp/zv9w9ay4,target=/tmp \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/nek1kq3w/20210804173606-950912.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 13.024 \\ 38.247 \\ 14.7 \\ 36.69 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B3.TIF \\ LC08_L1TP_189034_20200427_20200509_01_T1_B3.tif > /tmp/ec2vd8nr/stdout 2> /tmp/ec2vd8nr/stderr INFO [job node_subset_xs_2] Max memory used: 140MiB INFO [job node_subset_xs_2] completed success INFO [job node_subset_xs_3] Max memory used: 140MiB INFO [job node_subset_xs_3] completed success INFO [job node_subset_xs] Max memory used: 140MiB INFO [job node_subset_xs] completed success INFO [step node_subset_xs] completed success INFO [workflow ] starting step node_concatenate INFO [step node_concatenate] start INFO [job node_concatenate] /tmp/knf2r9sb$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/knf2r9sb,target=/SylLdp \\ --mount=type=bind,source=/tmp/57egskol,target=/tmp \\ --mount=type=bind,source=/tmp/qyw2_zpj/LC08_L1TP_189034_20200427_20200509_01_T1_B4.tif,target=/var/lib/cwl/stgc5780791-8645-4e2c-9836-0d0ad562f697/LC08_L1TP_189034_20200427_20200509_01_T1_B4.tif,readonly \\ --mount=type=bind,source=/tmp/ec2vd8nr/LC08_L1TP_189034_20200427_20200509_01_T1_B3.tif,target=/var/lib/cwl/stg8b191124-00d3-441d-ab72-d0e74d86f48a/LC08_L1TP_189034_20200427_20200509_01_T1_B3.tif,readonly \\ --mount=type=bind,source=/tmp/stcmw6jr/LC08_L1TP_189034_20200427_20200509_01_T1_B2.tif,target=/var/lib/cwl/stgc634f2d6-acea-4c0d-9b56-37887c74cdc7/LC08_L1TP_189034_20200427_20200509_01_T1_B2.tif,readonly \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/3cqq714a/20210804173912-369708.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ terradue/otb-7.2.0 \\ otbcli_ConcatenateImages \\ -out \\ xs_stack.tif \\ -il \\ /var/lib/cwl/stgc5780791-8645-4e2c-9836-0d0ad562f697/LC08_L1TP_189034_20200427_20200509_01_T1_B4.tif \\ /var/lib/cwl/stg8b191124-00d3-441d-ab72-d0e74d86f48a/LC08_L1TP_189034_20200427_20200509_01_T1_B3.tif \\ /var/lib/cwl/stgc634f2d6-acea-4c0d-9b56-37887c74cdc7/LC08_L1TP_189034_20200427_20200509_01_T1_B2.tif > /tmp/knf2r9sb/stdout 2> /tmp/knf2r9sb/stderr INFO [job node_concatenate] Max memory used: 0MiB INFO [job node_concatenate] completed success INFO [step node_concatenate] completed success INFO [job node_subset_p] Max memory used: 479MiB INFO [job node_subset_p] completed success INFO [step node_subset_p] completed success INFO [workflow ] starting step node_bundle_to_perfect INFO [step node_bundle_to_perfect] start INFO [job node_bundle_to_perfect] /tmp/ax28u_oo$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/ax28u_oo,target=/SylLdp \\ --mount=type=bind,source=/tmp/mwg_945e,target=/tmp \\ --mount=type=bind,source=/tmp/3zglf_2v/LC08_L1TP_189034_20200427_20200509_01_T1_B8.tif,target=/var/lib/cwl/stge8932e00-551b-4600-bcc9-d1301605dceb/LC08_L1TP_189034_20200427_20200509_01_T1_B8.tif,readonly \\ --mount=type=bind,source=/tmp/knf2r9sb/xs_stack.tif,target=/var/lib/cwl/stg04227d2f-7f21-4ae5-82e1-2307f645229b/xs_stack.tif,readonly \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/fzdpqofo/20210804174224-963566.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ terradue/otb-7.2.0 \\ otbcli_BundleToPerfectSensor \\ -out \\ pan-sharpen.tif \\ -inxs \\ /var/lib/cwl/stg04227d2f-7f21-4ae5-82e1-2307f645229b/xs_stack.tif \\ -inp \\ /var/lib/cwl/stge8932e00-551b-4600-bcc9-d1301605dceb/LC08_L1TP_189034_20200427_20200509_01_T1_B8.tif > /tmp/ax28u_oo/stdout 2> /tmp/ax28u_oo/stderr INFO [job node_bundle_to_perfect] Max memory used: 831MiB INFO [job node_bundle_to_perfect] completed success INFO [step node_bundle_to_perfect] completed success INFO [workflow ] completed success { \"ps_tif\": { \"location\": \"file:///home/fbrito/work/guide/docs/otb/landsat-8-pan-sharpening/pan-sharpen.tif\", \"basename\": \"pan-sharpen.tif\", \"class\": \"File\", \"checksum\": \"sha1$d0d333d4ef042f77df8f8f9e5fef7d540fa2a107\", \"size\": 1360248796, \"path\": \"/home/fbrito/work/guide/docs/otb/landsat-8-pan-sharpening/pan-sharpen.tif\" } } INFO Final process status is success","title":"Pan-sharpening with OTB"},{"location":"otb/landsat-8-pan-sharpening/#landsat-8-pan-sharpening","text":"","title":"Landsat-8 pan-sharpening"},{"location":"otb/landsat-8-pan-sharpening/#goal","text":"Use CWL to orchestrate the steps required to create a pan-sharpened Landsat-8 RGB composite.","title":"Goal"},{"location":"otb/landsat-8-pan-sharpening/#steps","text":"The CWL Workflow steps are depicted as a diagram: graph TD A[stac xs] --> C[subset xs] B[stac p] --> D[subset p] C --> E[concatenate xs] D --> F[bundle_to_perfect] E --> F Where: stac xs step resolves the Landsat-8 STAC item assets B4, B3, B2 hrefs. These steps are scattered by CWL stac p step resolves the Landsat-8 STAC item asset B6. subset xs and subset p use GDAL gdal_translate to clip the reference COG file to the area of interest (provided as a parameter) concatenate xs uses OTB otbcli_ConcatenateImages to stack the RGB bands as a single geotiff file bundle_to_perfect uses OTB otbcli_BundleToPerfectSensor to perform the pan-sharpening","title":"Steps"},{"location":"otb/landsat-8-pan-sharpening/#stac-xs-and-stac-p","text":"These steps invoke the asset.cwl CWL Workflow to resolve the Landsat-8 STAC Item asset href. The CommandLineTool uses curl and jq to get the Landsat-8 STAC Item and parse its JSON content: class : CommandLineTool requirements : DockerRequirement : dockerPull : terradue/jq ShellCommandRequirement : {} InlineJavascriptRequirement : {} baseCommand : curl arguments : - -s - $(inputs.stac_item) - \"|\" - jq - .assets.$(inputs.asset).href - \"|\" - tr - -d - '\\\"' #\\\"\" stdout : message inputs : stac_item : type : string asset : type : string outputs : asset_href : type : string outputBinding : glob : message loadContents : true outputEval : $( self[0].contents.split(\"\\n\").join(\"\") ) cwlVersion : v1.0","title":"stac xs and stac p"},{"location":"otb/landsat-8-pan-sharpening/#subset-xs-and-subset-p","text":"These steps invoke GDAL's gdal_translate to clip the COG to tha area of interest. class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - valueFrom : ${ return inputs.epsg; } - valueFrom : | ${ if (inputs.asset.startsWith(\"http\")) { return \"/vsicurl/\" + inputs.asset; } else { return inputs.asset; } } - valueFrom : ${ return inputs.asset.split(\"/\").slice(-1)[0].replace(\"TIF\", \"tif\"); } inputs : asset : type : string bbox : type : string epsg : type : string default : \"EPSG:4326\" outputs : tifs : outputBinding : glob : '*.tif' type : File stderr : stderr stdout : stdout cwlVersion : v1.0","title":"subset xs and subset p"},{"location":"otb/landsat-8-pan-sharpening/#concatenate-xs","text":"class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : terradue/otb-7.2.0 baseCommand : otbcli_ConcatenateImages arguments : - -out - xs_stack.tif inputs : tifs : type : File[] inputBinding : position : 5 prefix : -il separate : true outputs : xs_stack : outputBinding : glob : \"xs_stack.tif\" type : File stderr : stderr stdout : stdout cwlVersion : v1.0","title":"concatenate xs"},{"location":"otb/landsat-8-pan-sharpening/#bundle_to_perfect","text":"class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : terradue/otb-7.2.0 baseCommand : otbcli_BundleToPerfectSensor arguments : - -out - pan-sharpen.tif inputs : xs : type : File inputBinding : position : 2 prefix : -inxs separate : true pan : type : File inputBinding : position : 3 prefix : -inp separate : true outputs : pan-sharpened : outputBinding : glob : \"*.tif\" type : File stderr : stderr stdout : stdout cwlVersion : v1.0","title":"bundle_to_perfect"},{"location":"otb/landsat-8-pan-sharpening/#workflow","text":"$graph : - class : Workflow label : Landsat-8 pan-sharpening doc : Landsat-8 pan-sharpening id : main requirements : - class : ScatterFeatureRequirement - class : MultipleInputFeatureRequirement inputs : stac_item : doc : Landsat-8 item type : string aoi : doc : area of interest as a bounding box type : string red : type : string default : \"B4\" green : type : string default : \"B3\" blue : type : string default : \"B2\" p_band : type : string default : \"B8\" outputs : ps_tif : outputSource : - node_bundle_to_perfect/pan-sharpened type : File steps : node_stac_xs : run : asset.cwl in : stac_item : stac_item asset : [ red , green , blue ] out : - asset_href scatter : asset_href scatterMethod : dotproduct node_stac_p : run : asset.cwl in : stac_item : stac_item asset : p_band out : - asset_href node_subset_xs : run : translate.cwl in : asset_href : source : node_stac_xs/asset_href bbox : aoi out : - tifs scatter : asset_href scatterMethod : dotproduct node_subset_p : run : translate.cwl in : asset : source : node_stac_p/asset_href bbox : aoi out : - tifs node_concatenate : run : concatenate.cwl in : tifs : source : [ node_subset_xs/tifs ] out : - xs_stack node_bundle_to_perfect : run : bundle_to_perfect.cwl in : xs : source : [ node_concatenate/xs_stack ] pan : source : [ node_subset_p/tifs ] out : - pan-sharpened cwlVersion : v1.0","title":"Workflow"},{"location":"otb/landsat-8-pan-sharpening/#execute-the-workflow","text":"The file pan-sharpening.yml contains the parameters to invoke the CWL Workflow: stac_item : \"https://landsat-stac.s3.amazonaws.com/landsat-8-l1/189/034/2020-04-27/LC81890342020118.json\" aoi : \"13.024,36.69,14.7,38.247\" The CWL workflow is executed with: cwltool --parallel pan-sharpening.cwl pan-sharpening.yml This will output: INFO /srv/conda/bin/cwltool 3.1.20210628163208 INFO Resolved 'pan-sharpening.cwl' to 'file:///home/fbrito/work/guide/docs/otb/landsat-8-pan-sharpening/pan-sharpening.cwl' INFO [workflow ] starting step node_stac_p INFO [step node_stac_p] start INFO [workflow ] start INFO [workflow ] starting step node_stac_xs INFO [step node_stac_xs] start INFO [step node_stac_xs] start INFO [step node_stac_xs] start INFO [job node_stac_p] /tmp/ocp1fize$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/ocp1fize,target=/SylLdp \\ --mount=type=bind,source=/tmp/rdlm1sb2,target=/tmp \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/_yul_u6l/20210804173603-213866.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ terradue/jq \\ /bin/sh \\ -c \\ 'curl' '-s' 'https://landsat-stac.s3.amazonaws.com/landsat-8-l1/189/034/2020-04-27/LC81890342020118.json' | 'jq' '.assets.B8.href' | 'tr' '-d' \\\" > /tmp/ocp1fize/message INFO [job node_stac_xs] /tmp/5hactbmn$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/5hactbmn,target=/SylLdp \\ --mount=type=bind,source=/tmp/jes964z4,target=/tmp \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/hj367hhm/20210804173603-232079.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ terradue/jq \\ /bin/sh \\ -c \\ 'curl' '-s' 'https://landsat-stac.s3.amazonaws.com/landsat-8-l1/189/034/2020-04-27/LC81890342020118.json' | 'jq' '.assets.B4.href' | 'tr' '-d' \\\" > /tmp/5hactbmn/message INFO [job node_stac_xs_2] /tmp/em8f13in$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/em8f13in,target=/SylLdp \\ --mount=type=bind,source=/tmp/88eyxi1x,target=/tmp \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/tbsqgf5p/20210804173603-235855.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ terradue/jq \\ /bin/sh \\ -c \\ 'curl' '-s' 'https://landsat-stac.s3.amazonaws.com/landsat-8-l1/189/034/2020-04-27/LC81890342020118.json' | 'jq' '.assets.B3.href' | 'tr' '-d' \\\" > /tmp/em8f13in/message INFO [job node_stac_xs_3] /tmp/xd0fmqxi$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/xd0fmqxi,target=/SylLdp \\ --mount=type=bind,source=/tmp/2clk49jo,target=/tmp \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/v7kn3_ek/20210804173603-242940.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ terradue/jq \\ /bin/sh \\ -c \\ 'curl' '-s' 'https://landsat-stac.s3.amazonaws.com/landsat-8-l1/189/034/2020-04-27/LC81890342020118.json' | 'jq' '.assets.B2.href' | 'tr' '-d' \\\" > /tmp/xd0fmqxi/message INFO [job node_stac_xs] Max memory used: 0MiB INFO [job node_stac_xs_2] Max memory used: 0MiB INFO [job node_stac_p] Max memory used: 0MiB INFO [job node_stac_xs_3] Max memory used: 0MiB INFO [job node_stac_xs] completed success INFO [job node_stac_xs_2] completed success INFO [job node_stac_p] completed success INFO [step node_stac_p] completed success INFO [workflow ] starting step node_subset_p INFO [step node_subset_p] start INFO [job node_stac_xs_3] completed success INFO [step node_stac_xs] completed success INFO [workflow ] starting step node_subset_xs INFO [step node_subset_xs] start INFO [step node_subset_xs] start INFO [step node_subset_xs] start INFO [job node_subset_p] /tmp/3zglf_2v$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/3zglf_2v,target=/SylLdp \\ --mount=type=bind,source=/tmp/0r8_x_fp,target=/tmp \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/rq8yfpxp/20210804173606-799825.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 13.024 \\ 38.247 \\ 14.7 \\ 36.69 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B8.TIF \\ LC08_L1TP_189034_20200427_20200509_01_T1_B8.tif > /tmp/3zglf_2v/stdout 2> /tmp/3zglf_2v/stderr INFO [job node_subset_xs_3] /tmp/stcmw6jr$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/stcmw6jr,target=/SylLdp \\ --mount=type=bind,source=/tmp/3hvmk29c,target=/tmp \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/vu17p2ii/20210804173606-835032.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 13.024 \\ 38.247 \\ 14.7 \\ 36.69 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B2.TIF \\ LC08_L1TP_189034_20200427_20200509_01_T1_B2.tif > /tmp/stcmw6jr/stdout 2> /tmp/stcmw6jr/stderr INFO [job node_subset_xs] /tmp/qyw2_zpj$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/qyw2_zpj,target=/SylLdp \\ --mount=type=bind,source=/tmp/i_rk2a9p,target=/tmp \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/l0jw9g8d/20210804173606-884892.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 13.024 \\ 38.247 \\ 14.7 \\ 36.69 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B4.TIF \\ LC08_L1TP_189034_20200427_20200509_01_T1_B4.tif > /tmp/qyw2_zpj/stdout 2> /tmp/qyw2_zpj/stderr INFO [job node_subset_xs_2] /tmp/ec2vd8nr$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/ec2vd8nr,target=/SylLdp \\ --mount=type=bind,source=/tmp/zv9w9ay4,target=/tmp \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/nek1kq3w/20210804173606-950912.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 13.024 \\ 38.247 \\ 14.7 \\ 36.69 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://landsat-pds.s3.amazonaws.com/c1/L8/189/034/LC08_L1TP_189034_20200427_20200509_01_T1/LC08_L1TP_189034_20200427_20200509_01_T1_B3.TIF \\ LC08_L1TP_189034_20200427_20200509_01_T1_B3.tif > /tmp/ec2vd8nr/stdout 2> /tmp/ec2vd8nr/stderr INFO [job node_subset_xs_2] Max memory used: 140MiB INFO [job node_subset_xs_2] completed success INFO [job node_subset_xs_3] Max memory used: 140MiB INFO [job node_subset_xs_3] completed success INFO [job node_subset_xs] Max memory used: 140MiB INFO [job node_subset_xs] completed success INFO [step node_subset_xs] completed success INFO [workflow ] starting step node_concatenate INFO [step node_concatenate] start INFO [job node_concatenate] /tmp/knf2r9sb$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/knf2r9sb,target=/SylLdp \\ --mount=type=bind,source=/tmp/57egskol,target=/tmp \\ --mount=type=bind,source=/tmp/qyw2_zpj/LC08_L1TP_189034_20200427_20200509_01_T1_B4.tif,target=/var/lib/cwl/stgc5780791-8645-4e2c-9836-0d0ad562f697/LC08_L1TP_189034_20200427_20200509_01_T1_B4.tif,readonly \\ --mount=type=bind,source=/tmp/ec2vd8nr/LC08_L1TP_189034_20200427_20200509_01_T1_B3.tif,target=/var/lib/cwl/stg8b191124-00d3-441d-ab72-d0e74d86f48a/LC08_L1TP_189034_20200427_20200509_01_T1_B3.tif,readonly \\ --mount=type=bind,source=/tmp/stcmw6jr/LC08_L1TP_189034_20200427_20200509_01_T1_B2.tif,target=/var/lib/cwl/stgc634f2d6-acea-4c0d-9b56-37887c74cdc7/LC08_L1TP_189034_20200427_20200509_01_T1_B2.tif,readonly \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/3cqq714a/20210804173912-369708.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ terradue/otb-7.2.0 \\ otbcli_ConcatenateImages \\ -out \\ xs_stack.tif \\ -il \\ /var/lib/cwl/stgc5780791-8645-4e2c-9836-0d0ad562f697/LC08_L1TP_189034_20200427_20200509_01_T1_B4.tif \\ /var/lib/cwl/stg8b191124-00d3-441d-ab72-d0e74d86f48a/LC08_L1TP_189034_20200427_20200509_01_T1_B3.tif \\ /var/lib/cwl/stgc634f2d6-acea-4c0d-9b56-37887c74cdc7/LC08_L1TP_189034_20200427_20200509_01_T1_B2.tif > /tmp/knf2r9sb/stdout 2> /tmp/knf2r9sb/stderr INFO [job node_concatenate] Max memory used: 0MiB INFO [job node_concatenate] completed success INFO [step node_concatenate] completed success INFO [job node_subset_p] Max memory used: 479MiB INFO [job node_subset_p] completed success INFO [step node_subset_p] completed success INFO [workflow ] starting step node_bundle_to_perfect INFO [step node_bundle_to_perfect] start INFO [job node_bundle_to_perfect] /tmp/ax28u_oo$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/ax28u_oo,target=/SylLdp \\ --mount=type=bind,source=/tmp/mwg_945e,target=/tmp \\ --mount=type=bind,source=/tmp/3zglf_2v/LC08_L1TP_189034_20200427_20200509_01_T1_B8.tif,target=/var/lib/cwl/stge8932e00-551b-4600-bcc9-d1301605dceb/LC08_L1TP_189034_20200427_20200509_01_T1_B8.tif,readonly \\ --mount=type=bind,source=/tmp/knf2r9sb/xs_stack.tif,target=/var/lib/cwl/stg04227d2f-7f21-4ae5-82e1-2307f645229b/xs_stack.tif,readonly \\ --workdir=/SylLdp \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --cidfile=/tmp/fzdpqofo/20210804174224-963566.cid \\ --env=TMPDIR=/tmp \\ --env=HOME=/SylLdp \\ terradue/otb-7.2.0 \\ otbcli_BundleToPerfectSensor \\ -out \\ pan-sharpen.tif \\ -inxs \\ /var/lib/cwl/stg04227d2f-7f21-4ae5-82e1-2307f645229b/xs_stack.tif \\ -inp \\ /var/lib/cwl/stge8932e00-551b-4600-bcc9-d1301605dceb/LC08_L1TP_189034_20200427_20200509_01_T1_B8.tif > /tmp/ax28u_oo/stdout 2> /tmp/ax28u_oo/stderr INFO [job node_bundle_to_perfect] Max memory used: 831MiB INFO [job node_bundle_to_perfect] completed success INFO [step node_bundle_to_perfect] completed success INFO [workflow ] completed success { \"ps_tif\": { \"location\": \"file:///home/fbrito/work/guide/docs/otb/landsat-8-pan-sharpening/pan-sharpen.tif\", \"basename\": \"pan-sharpen.tif\", \"class\": \"File\", \"checksum\": \"sha1$d0d333d4ef042f77df8f8f9e5fef7d540fa2a107\", \"size\": 1360248796, \"path\": \"/home/fbrito/work/guide/docs/otb/landsat-8-pan-sharpening/pan-sharpen.tif\" } } INFO Final process status is success","title":"Execute the Workflow"},{"location":"python/introduction/","text":"Introduction","title":"Introduction"},{"location":"python/introduction/#introduction","text":"","title":"Introduction"},{"location":"reference/cwl-clt/","text":"CWL Command Line Tool Description Standard The CWL Command Line Tool Description Standard specifies the document schema and execution semantics for wrapping and executing command line tools.","title":"CWL Command Line Tool Description"},{"location":"reference/cwl-clt/#cwl-command-line-tool-description-standard","text":"The CWL Command Line Tool Description Standard specifies the document schema and execution semantics for wrapping and executing command line tools.","title":"CWL Command Line Tool Description Standard"},{"location":"reference/cwl-workflow/","text":"CWL Workflow Description Standard The CWL Workflow Description Standard specifies the document schema and execution semantics for composing workflows from components such as command line tools and other workflows.","title":"CWL Workflow Description"},{"location":"reference/cwl-workflow/#cwl-workflow-description-standard","text":"The CWL Workflow Description Standard specifies the document schema and execution semantics for composing workflows from components such as command line tools and other workflows.","title":"CWL Workflow Description Standard"},{"location":"snap/","text":"","title":"Index"},{"location":"snap/101/","text":"SNAP 101 Graph Processing Framework The SNAP architecture provides a flexible Graph Processing Framework (GPF) allowing the creation of processing graphs for batch processing and customized processing chains. A graph is a set of nodes connected by edges. In this case, the nodes are the processing steps called operators. The edges will show the direction in which the data is being passed between nodes; therefore it will be a directed graph. A graph can have no loops or cycles, so it will be a Directed Acyclic Graph (DAG). The sources of the graph will be the data product readers, and the sinks can be either a product writer or an image displayed. An operator can have one or more image sources and other parameters that define the operation. Two or more operators may be connected together so that the first operator becomes an image source to the next operator. By linking one operator to another, an imaging graph or processing chain can be created The graph processor will not introduce any intermediate files unless a writer is optionally added anywhere in the sequence. Graphs offer the following advantages: no intermediate files written, no I/O overhead reusability of processing chains simple and comprehensive operator configuration reusability of operator configurations SNAP EO Data Processors are implemented as GPF operators and can be invoked using the GPF Graph Processing Tool gpt which can be found in the bin directory of a SNAP installation. The following command will dump the gpt print out a short description of what the tool is for and describes the arguments and options of the tool. A list of available operators is displayed according to the toolboxes installed. docker run --rm docker.io/snap-gpt gpt -h The partial output: Usage: gpt <op>|<graph-file> [options] [<source-file-1> <source-file-2> ...] Description: This tool is used to execute SNAP raster data operators in batch-mode. The operators can be used stand-alone or combined as a directed acyclic graph (DAG). Processing graphs are represented using XML. More info about processing graphs, the operator API, and the graph XML format can be found in the SNAP documentation. Arguments: <op> Name of an operator. See below for the list of <op>s. <graph-file> Operator graph file (XML format). <source-file-i> The <i>th source product file. The actual number of source file arguments is specified by <op>. May be optional for operators which use the -S option. Options: -h Displays command usage. If <op> is given, the specific operator usage is displayed. -e Displays more detailed error messages. Displays a stack trace, if an exception occurs. -t <file> The target file. Default value is 'target.dim'. -f <format> Output file format, e.g. 'GeoTIFF', 'HDF5', 'BEAM-DIMAP'. If not specified, format will be derived from the target filename extension, if any, otherwise the default format is 'BEAM-DIMAP'. Ony used, if the graph in <graph-file> does not specify its own 'Write' operator. -p <file> A (Java Properties) file containing processing parameters in the form <name>=<value> or a XML file containing a parameter DOM for the operator. Entries in this file are overwritten by the -P<name>=<value> command-line option (see below). The following variables are substituted in the parameters file: ${system.<java-sys-property>} ${operatorName} (given by the <op> argument) ${graphFile} (given by the <graph-file> argument) ${targetFile} (pull path given by the -t option) ${targetDir} (derived from -t option) ${targetName} (derived from -t option) ${targetBaseName} (derived from -t option) ${targetFormat} (given by the -f option) -c <cache-size> Sets the tile cache size in bytes. Value can be suffixed with 'K', 'M' and 'G'. Must be less than maximum available heap space. If equal to or less than zero, tile caching will be completely disabled. The default tile cache size is '1,073,741,824M'. -q <parallelism> Sets the maximum parallelism used for the computation, i.e. the maximum number of parallel (native) threads. The default parallelism is '16'. -x Clears the internal tile cache after writing a complete row of tiles to the target product file. This option may be useful if you run into memory problems. -S<source>=<file> Defines a source product. <source> is specified by the operator or the graph. In an XML graph, all occurrences of ${<source>} will be replaced with references to a source product located at <file>. -P<name>=<value> Defines a processing parameter, <name> is specific for the used operator or graph. In an XML graph, all occurrences of ${<name>} will be replaced with <value>. Overwrites parameter values specified by the '-p' option. -D<name>=<value> Defines a system property for this invocation. -v <dir> A directory containing any number of Velocity templates. Each template generates a text output file along with the target product. This feature has been added to support a flexible generation of metadata files. See http://velocity.apache.org/ and option -m. -m <file> A (Java Properties) file containing (constant) metadata in the form <name>=<value> or any XML file. Its primary usage is to provide an additional context to be used from within the Velocity templates. See option -v. --diag Displays version and diagnostic information. Operators: Aatsr.SST Computes sea surface temperature (SST) from (A)ATSR products. AATSR.Ungrid Ungrids (A)ATSR L1B products and extracts geolocation and pixel field of view data. AdaptiveThresholding Detect ships using Constant False Alarm Rate detector. AddElevation Creates a DEM band ... Warp Create Warp Function And Get Co-registrated Images WdviOp Weighted Difference Vegetation Index retrieves the Isovegetation lines parallel to soil line. Soil line has an arbitrary slope and passes through origin Wind-Field-Estimation Estimate wind speed and direction Write Writes a data product to a file. The gpt can process individual operators or a graph of connected operators. Type: docker run --rm docker.io/snap-gpt gpt <operator-name> \u2013h to get usage information of an operator provided via <operator-name> . The usage text of an operator also displays an XML template clipping of the operators configuration when used in a graph. Example: docker run --rm docker.io/snap-gpt gpt Calibration \u2013h This outputs: Usage: gpt Calibration [options] Description: Calibration of products Source Options: -Ssource=<file> Sets source 'source' to <filepath>. This is a mandatory source. Parameter Options: -PauxFile=<string> The auxiliary file Value must be one of 'Latest Auxiliary File', 'Product Auxiliary File', 'External Auxiliary File'. Default value is 'Latest Auxiliary File'. -PcreateBetaBand=<boolean> Create beta0 virtual band Default value is 'false'. -PcreateGammaBand=<boolean> Create gamma0 virtual band Default value is 'false'. -PexternalAuxFile=<file> The antenna elevation pattern gain auxiliary data file. -PoutputBetaBand=<boolean> Output beta0 band Default value is 'false'. -PoutputGammaBand=<boolean> Output gamma0 band Default value is 'false'. -PoutputImageInComplex=<boolean> Output image in complex Default value is 'false'. -PoutputImageScaleInDb=<boolean> Output image scale Default value is 'false'. -PoutputSigmaBand=<boolean> Output sigma0 band Default value is 'true'. -PselectedPolarisations=<string,string,string,...> The list of polarisations -PsourceBands=<string,string,string,...> The list of source bands. Graph XML Format: <graph id=\"someGraphId\"> <version>1.0</version> <node id=\"someNodeId\"> <operator>Calibration</operator> <sources> <source>${source}</source> </sources> <parameters> <sourceBands>string,string,string,...</sourceBands> <auxFile>string</auxFile> <externalAuxFile>file</externalAuxFile> <outputImageInComplex>boolean</outputImageInComplex> <outputImageScaleInDb>boolean</outputImageScaleInDb> <createGammaBand>boolean</createGammaBand> <createBetaBand>boolean</createBetaBand> <selectedPolarisations>string,string,string,...</selectedPolarisations> <outputSigmaBand>boolean</outputSigmaBand> <outputGammaBand>boolean</outputGammaBand> <outputBetaBand>boolean</outputBetaBand> </parameters> </node> </graph> Calling GPT with a Graph Rather than calling each operator and specifying all its parameters, it is more convenient to pass the required settings in an XML-encoded graph file. To run gpt on a graph file type: gpt <GraphFile.xml> [options] [<source-file-1> <source-file-2> ...] Creating a Graph File The basic format of a graph XML file is: <graph id= \"someGraphId\" > <version> 1.0 </version> <node id= \"someNodeId\" > <operator> OperatorName </operator> <sources> <sourceProducts> ${sourceProducts} </sourceProducts> </sources> <parameters> .... </parameters> </node> </graph> Insert variables in the form ${variableName} in place of a parameter value. variableName is then replaced with a value at the command line. For example, if a parameter for a file included the variable for ${myFilename} <parameters> <file> ${myFilename} </file> </parameters> gpt is then invoked with: gpt mygraph.xml \u2013PmyFilename=pathToMyFile Batch processing SNAP users often resort to scripts to batch process their SNAP graphs. Below two examples of such scripts: For all envisat products in folder c:\\ASAR run gpt Calibration and produce the output in the folder c:\\output for /r \"c:\\ASAR\" %%X in (*.N1) do (gpt Calibration \"%%X\" -t \"C:\\output\\%%~nX.dim\") A set of input Sentinel-2 products shall be processed with the Resample processor. #!/bin/bash # enable next line for debugging purpose # set -x ############################################ # User Configuration ############################################ # adapt this path to your needs export PATH = ~/progs/snap/bin: $PATH gptPath = \"gpt\" ############################################ # Command line handling ############################################ # first parameter is a path to the graph xml graphXmlPath = \" $1 \" # second parameter is a path to a parameter file parameterFilePath = \" $2 \" # use third parameter for path to source products sourceDirectory = \" $3 \" # use fourth parameter for path to target products targetDirectory = \" $4 \" # the fifth parameter is a file prefix for the target product name, typically indicating the type of processing targetFilePrefix = \" $5 \" ############################################ # Helper functions ############################################ removeExtension () { file = \" $1 \" echo \" $( echo \" $file \" | sed -r 's/\\.[^\\.]*$//' ) \" } ############################################ # Main processing ############################################ # Create the target directory mkdir -p \" ${ targetDirectory } \" # the d option limits the elemeents to loop over to directories. Remove it, if you want to use files. for F in $( ls -1d \" ${ sourceDirectory } \" /S2*.SAFE ) ; do sourceFile = \" $( realpath \" $F \" ) \" targetFile = \" ${ targetDirectory } / ${ targetFilePrefix } _ $( removeExtension \" $( basename ${ F } ) \" ) .dim\" ${ gptPath } ${ graphXmlPath } -e -p ${ parameterFilePath } -t ${ targetFile } ${ sourceFile } done While these are valid approaches, these scripts are not portable and hardly shareable. Jump to next section to learn how CWL can be used to process SNAP graphs.","title":"SNAP"},{"location":"snap/101/#snap-101","text":"","title":"SNAP 101"},{"location":"snap/101/#graph-processing-framework","text":"The SNAP architecture provides a flexible Graph Processing Framework (GPF) allowing the creation of processing graphs for batch processing and customized processing chains. A graph is a set of nodes connected by edges. In this case, the nodes are the processing steps called operators. The edges will show the direction in which the data is being passed between nodes; therefore it will be a directed graph. A graph can have no loops or cycles, so it will be a Directed Acyclic Graph (DAG). The sources of the graph will be the data product readers, and the sinks can be either a product writer or an image displayed. An operator can have one or more image sources and other parameters that define the operation. Two or more operators may be connected together so that the first operator becomes an image source to the next operator. By linking one operator to another, an imaging graph or processing chain can be created The graph processor will not introduce any intermediate files unless a writer is optionally added anywhere in the sequence. Graphs offer the following advantages: no intermediate files written, no I/O overhead reusability of processing chains simple and comprehensive operator configuration reusability of operator configurations SNAP EO Data Processors are implemented as GPF operators and can be invoked using the GPF Graph Processing Tool gpt which can be found in the bin directory of a SNAP installation. The following command will dump the gpt print out a short description of what the tool is for and describes the arguments and options of the tool. A list of available operators is displayed according to the toolboxes installed. docker run --rm docker.io/snap-gpt gpt -h The partial output: Usage: gpt <op>|<graph-file> [options] [<source-file-1> <source-file-2> ...] Description: This tool is used to execute SNAP raster data operators in batch-mode. The operators can be used stand-alone or combined as a directed acyclic graph (DAG). Processing graphs are represented using XML. More info about processing graphs, the operator API, and the graph XML format can be found in the SNAP documentation. Arguments: <op> Name of an operator. See below for the list of <op>s. <graph-file> Operator graph file (XML format). <source-file-i> The <i>th source product file. The actual number of source file arguments is specified by <op>. May be optional for operators which use the -S option. Options: -h Displays command usage. If <op> is given, the specific operator usage is displayed. -e Displays more detailed error messages. Displays a stack trace, if an exception occurs. -t <file> The target file. Default value is 'target.dim'. -f <format> Output file format, e.g. 'GeoTIFF', 'HDF5', 'BEAM-DIMAP'. If not specified, format will be derived from the target filename extension, if any, otherwise the default format is 'BEAM-DIMAP'. Ony used, if the graph in <graph-file> does not specify its own 'Write' operator. -p <file> A (Java Properties) file containing processing parameters in the form <name>=<value> or a XML file containing a parameter DOM for the operator. Entries in this file are overwritten by the -P<name>=<value> command-line option (see below). The following variables are substituted in the parameters file: ${system.<java-sys-property>} ${operatorName} (given by the <op> argument) ${graphFile} (given by the <graph-file> argument) ${targetFile} (pull path given by the -t option) ${targetDir} (derived from -t option) ${targetName} (derived from -t option) ${targetBaseName} (derived from -t option) ${targetFormat} (given by the -f option) -c <cache-size> Sets the tile cache size in bytes. Value can be suffixed with 'K', 'M' and 'G'. Must be less than maximum available heap space. If equal to or less than zero, tile caching will be completely disabled. The default tile cache size is '1,073,741,824M'. -q <parallelism> Sets the maximum parallelism used for the computation, i.e. the maximum number of parallel (native) threads. The default parallelism is '16'. -x Clears the internal tile cache after writing a complete row of tiles to the target product file. This option may be useful if you run into memory problems. -S<source>=<file> Defines a source product. <source> is specified by the operator or the graph. In an XML graph, all occurrences of ${<source>} will be replaced with references to a source product located at <file>. -P<name>=<value> Defines a processing parameter, <name> is specific for the used operator or graph. In an XML graph, all occurrences of ${<name>} will be replaced with <value>. Overwrites parameter values specified by the '-p' option. -D<name>=<value> Defines a system property for this invocation. -v <dir> A directory containing any number of Velocity templates. Each template generates a text output file along with the target product. This feature has been added to support a flexible generation of metadata files. See http://velocity.apache.org/ and option -m. -m <file> A (Java Properties) file containing (constant) metadata in the form <name>=<value> or any XML file. Its primary usage is to provide an additional context to be used from within the Velocity templates. See option -v. --diag Displays version and diagnostic information. Operators: Aatsr.SST Computes sea surface temperature (SST) from (A)ATSR products. AATSR.Ungrid Ungrids (A)ATSR L1B products and extracts geolocation and pixel field of view data. AdaptiveThresholding Detect ships using Constant False Alarm Rate detector. AddElevation Creates a DEM band ... Warp Create Warp Function And Get Co-registrated Images WdviOp Weighted Difference Vegetation Index retrieves the Isovegetation lines parallel to soil line. Soil line has an arbitrary slope and passes through origin Wind-Field-Estimation Estimate wind speed and direction Write Writes a data product to a file. The gpt can process individual operators or a graph of connected operators. Type: docker run --rm docker.io/snap-gpt gpt <operator-name> \u2013h to get usage information of an operator provided via <operator-name> . The usage text of an operator also displays an XML template clipping of the operators configuration when used in a graph. Example: docker run --rm docker.io/snap-gpt gpt Calibration \u2013h This outputs: Usage: gpt Calibration [options] Description: Calibration of products Source Options: -Ssource=<file> Sets source 'source' to <filepath>. This is a mandatory source. Parameter Options: -PauxFile=<string> The auxiliary file Value must be one of 'Latest Auxiliary File', 'Product Auxiliary File', 'External Auxiliary File'. Default value is 'Latest Auxiliary File'. -PcreateBetaBand=<boolean> Create beta0 virtual band Default value is 'false'. -PcreateGammaBand=<boolean> Create gamma0 virtual band Default value is 'false'. -PexternalAuxFile=<file> The antenna elevation pattern gain auxiliary data file. -PoutputBetaBand=<boolean> Output beta0 band Default value is 'false'. -PoutputGammaBand=<boolean> Output gamma0 band Default value is 'false'. -PoutputImageInComplex=<boolean> Output image in complex Default value is 'false'. -PoutputImageScaleInDb=<boolean> Output image scale Default value is 'false'. -PoutputSigmaBand=<boolean> Output sigma0 band Default value is 'true'. -PselectedPolarisations=<string,string,string,...> The list of polarisations -PsourceBands=<string,string,string,...> The list of source bands. Graph XML Format: <graph id=\"someGraphId\"> <version>1.0</version> <node id=\"someNodeId\"> <operator>Calibration</operator> <sources> <source>${source}</source> </sources> <parameters> <sourceBands>string,string,string,...</sourceBands> <auxFile>string</auxFile> <externalAuxFile>file</externalAuxFile> <outputImageInComplex>boolean</outputImageInComplex> <outputImageScaleInDb>boolean</outputImageScaleInDb> <createGammaBand>boolean</createGammaBand> <createBetaBand>boolean</createBetaBand> <selectedPolarisations>string,string,string,...</selectedPolarisations> <outputSigmaBand>boolean</outputSigmaBand> <outputGammaBand>boolean</outputGammaBand> <outputBetaBand>boolean</outputBetaBand> </parameters> </node> </graph>","title":"Graph Processing Framework"},{"location":"snap/101/#calling-gpt-with-a-graph","text":"Rather than calling each operator and specifying all its parameters, it is more convenient to pass the required settings in an XML-encoded graph file. To run gpt on a graph file type: gpt <GraphFile.xml> [options] [<source-file-1> <source-file-2> ...]","title":"Calling GPT with a Graph"},{"location":"snap/101/#creating-a-graph-file","text":"The basic format of a graph XML file is: <graph id= \"someGraphId\" > <version> 1.0 </version> <node id= \"someNodeId\" > <operator> OperatorName </operator> <sources> <sourceProducts> ${sourceProducts} </sourceProducts> </sources> <parameters> .... </parameters> </node> </graph> Insert variables in the form ${variableName} in place of a parameter value. variableName is then replaced with a value at the command line. For example, if a parameter for a file included the variable for ${myFilename} <parameters> <file> ${myFilename} </file> </parameters> gpt is then invoked with: gpt mygraph.xml \u2013PmyFilename=pathToMyFile","title":"Creating a Graph File"},{"location":"snap/101/#batch-processing","text":"SNAP users often resort to scripts to batch process their SNAP graphs. Below two examples of such scripts: For all envisat products in folder c:\\ASAR run gpt Calibration and produce the output in the folder c:\\output for /r \"c:\\ASAR\" %%X in (*.N1) do (gpt Calibration \"%%X\" -t \"C:\\output\\%%~nX.dim\") A set of input Sentinel-2 products shall be processed with the Resample processor. #!/bin/bash # enable next line for debugging purpose # set -x ############################################ # User Configuration ############################################ # adapt this path to your needs export PATH = ~/progs/snap/bin: $PATH gptPath = \"gpt\" ############################################ # Command line handling ############################################ # first parameter is a path to the graph xml graphXmlPath = \" $1 \" # second parameter is a path to a parameter file parameterFilePath = \" $2 \" # use third parameter for path to source products sourceDirectory = \" $3 \" # use fourth parameter for path to target products targetDirectory = \" $4 \" # the fifth parameter is a file prefix for the target product name, typically indicating the type of processing targetFilePrefix = \" $5 \" ############################################ # Helper functions ############################################ removeExtension () { file = \" $1 \" echo \" $( echo \" $file \" | sed -r 's/\\.[^\\.]*$//' ) \" } ############################################ # Main processing ############################################ # Create the target directory mkdir -p \" ${ targetDirectory } \" # the d option limits the elemeents to loop over to directories. Remove it, if you want to use files. for F in $( ls -1d \" ${ sourceDirectory } \" /S2*.SAFE ) ; do sourceFile = \" $( realpath \" $F \" ) \" targetFile = \" ${ targetDirectory } / ${ targetFilePrefix } _ $( removeExtension \" $( basename ${ F } ) \" ) .dim\" ${ gptPath } ${ graphXmlPath } -e -p ${ parameterFilePath } -t ${ targetFile } ${ sourceFile } done While these are valid approaches, these scripts are not portable and hardly shareable. Jump to next section to learn how CWL can be used to process SNAP graphs.","title":"Batch processing"},{"location":"snap/snap-cwl/graph-as-a-file/","text":"SNAP Graph as File SNAP gpt is wrapped as a CWL CommandLineTool with: class : CommandLineTool id : sar-calibration requirements : DockerRequirement : dockerPull : snap-gpt EnvVarRequirement : envDef : PATH : /srv/conda/envs/env_snap/snap/bin:/usr/share/java/maven/bin:/usr/share/java/maven/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin ResourceRequirement : {} baseCommand : gpt inputs : snap_graph : inputBinding : position : 1 type : File polarization : inputBinding : position : 2 prefix : -PselPol= separate : false type : string safe : inputBinding : position : 2 prefix : -PinFile= separate : false type : Directory outputs : results : outputBinding : glob : . type : Directory cwlVersion : v1.0 This CWL document takes three inputs: class : CommandLineTool id : sar-calibration requirements : DockerRequirement : dockerPull : snap-gpt EnvVarRequirement : envDef : PATH : /srv/conda/envs/env_snap/snap/bin:/usr/share/java/maven/bin:/usr/share/java/maven/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin ResourceRequirement : {} baseCommand : gpt inputs : snap_graph : inputBinding : position : 1 type : File polarization : inputBinding : position : 2 prefix : -PselPol= separate : false type : string safe : inputBinding : position : 2 prefix : -PinFile= separate : false type : Directory outputs : results : outputBinding : glob : . type : Directory cwlVersion : v1.0 to construct a gpt invocation: gpt <snap_graph> -PselPol=<polarization> -PinFile=<safe> It is a best practice to create a CWL Workflow to wrap the CommandLineTool : $graph : - class : Workflow id : main doc : SNAP Sentinel-1 GRD Calibration label : SNAP Sentinel-1 GRD Calibration inputs : polarization : doc : Polarization channel label : Polarization channel type : string snap_graph : doc : SNAP Graph label : SNAP Graph type : File safe : doc : Sentinel-1 GRD product SAFE Directory label : Sentinel-1 GRD product SAFE Directory type : Directory outputs : - id : wf_outputs outputSource : - node_1/results type : Directory requirements : SubworkflowFeatureRequirement : {} steps : node_1 : in : snap_graph : snap_graph polarization : polarization safe : safe out : - results run : '#sar-calibration' - class : CommandLineTool id : sar-calibration requirements : DockerRequirement : dockerPull : snap-gpt EnvVarRequirement : envDef : PATH : /srv/conda/envs/env_snap/snap/bin:/usr/share/java/maven/bin:/usr/share/java/maven/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin ResourceRequirement : {} baseCommand : gpt inputs : snap_graph : inputBinding : position : 1 type : File polarization : inputBinding : position : 2 prefix : -PselPol= separate : false type : string safe : inputBinding : position : 2 prefix : -PinFile= separate : false type : Directory outputs : results : outputBinding : glob : . type : Directory stderr : std.err stdout : std.out cwlVersion : v1.0 The CWL parameters file to run this CWL document contains: polarization : 'VV' snap_graph : { class : File , path : ./sar-calibration.xml } safe : { 'class' : 'Directory' , 'path' : './S1A_IW_GRDH_1SDV_20210621T165648_20210621T165713_038441_04893A_EFF6.SAFE' } Finally, the execution is triggered with: cwltool sar-calibration-file.cwl sar-calibration-file.yml","title":"SNAP Graph as File"},{"location":"snap/snap-cwl/graph-as-a-file/#snap-graph-as-file","text":"SNAP gpt is wrapped as a CWL CommandLineTool with: class : CommandLineTool id : sar-calibration requirements : DockerRequirement : dockerPull : snap-gpt EnvVarRequirement : envDef : PATH : /srv/conda/envs/env_snap/snap/bin:/usr/share/java/maven/bin:/usr/share/java/maven/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin ResourceRequirement : {} baseCommand : gpt inputs : snap_graph : inputBinding : position : 1 type : File polarization : inputBinding : position : 2 prefix : -PselPol= separate : false type : string safe : inputBinding : position : 2 prefix : -PinFile= separate : false type : Directory outputs : results : outputBinding : glob : . type : Directory cwlVersion : v1.0 This CWL document takes three inputs: class : CommandLineTool id : sar-calibration requirements : DockerRequirement : dockerPull : snap-gpt EnvVarRequirement : envDef : PATH : /srv/conda/envs/env_snap/snap/bin:/usr/share/java/maven/bin:/usr/share/java/maven/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin ResourceRequirement : {} baseCommand : gpt inputs : snap_graph : inputBinding : position : 1 type : File polarization : inputBinding : position : 2 prefix : -PselPol= separate : false type : string safe : inputBinding : position : 2 prefix : -PinFile= separate : false type : Directory outputs : results : outputBinding : glob : . type : Directory cwlVersion : v1.0 to construct a gpt invocation: gpt <snap_graph> -PselPol=<polarization> -PinFile=<safe> It is a best practice to create a CWL Workflow to wrap the CommandLineTool : $graph : - class : Workflow id : main doc : SNAP Sentinel-1 GRD Calibration label : SNAP Sentinel-1 GRD Calibration inputs : polarization : doc : Polarization channel label : Polarization channel type : string snap_graph : doc : SNAP Graph label : SNAP Graph type : File safe : doc : Sentinel-1 GRD product SAFE Directory label : Sentinel-1 GRD product SAFE Directory type : Directory outputs : - id : wf_outputs outputSource : - node_1/results type : Directory requirements : SubworkflowFeatureRequirement : {} steps : node_1 : in : snap_graph : snap_graph polarization : polarization safe : safe out : - results run : '#sar-calibration' - class : CommandLineTool id : sar-calibration requirements : DockerRequirement : dockerPull : snap-gpt EnvVarRequirement : envDef : PATH : /srv/conda/envs/env_snap/snap/bin:/usr/share/java/maven/bin:/usr/share/java/maven/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin ResourceRequirement : {} baseCommand : gpt inputs : snap_graph : inputBinding : position : 1 type : File polarization : inputBinding : position : 2 prefix : -PselPol= separate : false type : string safe : inputBinding : position : 2 prefix : -PinFile= separate : false type : Directory outputs : results : outputBinding : glob : . type : Directory stderr : std.err stdout : std.out cwlVersion : v1.0 The CWL parameters file to run this CWL document contains: polarization : 'VV' snap_graph : { class : File , path : ./sar-calibration.xml } safe : { 'class' : 'Directory' , 'path' : './S1A_IW_GRDH_1SDV_20210621T165648_20210621T165713_038441_04893A_EFF6.SAFE' } Finally, the execution is triggered with: cwltool sar-calibration-file.cwl sar-calibration-file.yml","title":"SNAP Graph as File"},{"location":"snap/snap-cwl/graph-inline/","text":"SNAP Graph inline CWL allows creating files using the InitialWorkDirRequirement : InitialWorkDirRequirement : listing : - entryname : graph.xml entry : |- The file graph.xml is created before executing the CommandLineTool. This approach is thus used to create the SNAP Graph with the content provided in the CWL document. This approach removes the File parameter used in the previous section and provides a self-standing CWL document: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 class : CommandLineTool id : sar-calibration requirements : DockerRequirement : dockerPull : snap-gpt EnvVarRequirement : envDef : PATH : /srv/conda/envs/env_snap/snap/bin:/usr/share/java/maven/bin:/usr/share/java/maven/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin ResourceRequirement : {} InitialWorkDirRequirement : listing : - entryname : calibration.xml entry : |- <graph id=\"Graph\"> <version>1.0</version> <node id=\"Read\"> <operator>Read</operator> <sources/> <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\"> <file>${inFile}</file> <formatName>SENTINEL-1</formatName> </parameters> </node> <node id=\"Calibration\"> <operator>Calibration</operator> <sources> <sourceProduct refid=\"Read\"/> </sources> <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\"> <sourceBands/> <auxFile>Product Auxiliary File</auxFile> <externalAuxFile/> <outputImageInComplex>false</outputImageInComplex> <outputImageScaleInDb>false</outputImageScaleInDb> <createGammaBand>false</createGammaBand> <createBetaBand>false</createBetaBand> <selectedPolarisations>${selPol}</selectedPolarisations> <outputSigmaBand>true</outputSigmaBand> <outputGammaBand>false</outputGammaBand> <outputBetaBand>false</outputBetaBand> </parameters> </node> <node id=\"Write\"> <operator>Write</operator> <sources> <sourceProduct refid=\"Calibration\"/> </sources> <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\"> <file>./cal.dim</file> <formatName>BEAM-DIMAP</formatName> </parameters> </node> </graph> baseCommand : [ gpt , calibration.xml ] inputs : polarization : inputBinding : position : 1 prefix : -PselPol= separate : false type : string safe : inputBinding : position : 2 prefix : -PinFile= separate : false type : Directory outputs : results : outputBinding : glob : . type : Directory stderr : std.err stdout : std.out cwlVersion : v1.0 The baseCommand is updated to add the calibration.xml argument: 54 55 56 57 58 </graph> baseCommand : [ gpt , calibration.xml ] inputs : The Workflow is updated accordingly: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 $graph : - class : Workflow id : main doc : SNAP Sentinel-1 GRD Calibration label : SNAP Sentinel-1 GRD Calibration inputs : polarization : doc : Polarization channel label : Polarization channel type : string safe : doc : Sentinel-1 GRD product SAFE Directory label : Sentinel-1 GRD product SAFE Directory type : Directory outputs : - id : wf_outputs outputSource : - node_1/results type : Directory requirements : SubworkflowFeatureRequirement : {} steps : node_1 : in : snap_graph : snap_graph polarization : polarization out : - results run : '#sar-calibration' - class : CommandLineTool id : sar-calibration requirements : DockerRequirement : dockerPull : snap-gpt EnvVarRequirement : envDef : PATH : /srv/conda/envs/env_snap/snap/bin:/usr/share/java/maven/bin:/usr/share/java/maven/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin ResourceRequirement : {} InitialWorkDirRequirement : listing : - entryname : calibration.xml entry : |- <graph id=\"Graph\"> <version>1.0</version> <node id=\"Read\"> <operator>Read</operator> <sources/> <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\"> <file>${inFile}</file> <formatName>SENTINEL-1</formatName> </parameters> </node> <node id=\"Calibration\"> <operator>Calibration</operator> <sources> <sourceProduct refid=\"Read\"/> </sources> <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\"> <sourceBands/> <auxFile>Product Auxiliary File</auxFile> <externalAuxFile/> <outputImageInComplex>false</outputImageInComplex> <outputImageScaleInDb>false</outputImageScaleInDb> <createGammaBand>false</createGammaBand> <createBetaBand>false</createBetaBand> <selectedPolarisations>${selPol}</selectedPolarisations> <outputSigmaBand>true</outputSigmaBand> <outputGammaBand>false</outputGammaBand> <outputBetaBand>false</outputBetaBand> </parameters> </node> <node id=\"Write\"> <operator>Write</operator> <sources> <sourceProduct refid=\"Calibration\"/> </sources> <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\"> <file>./cal.dim</file> <formatName>BEAM-DIMAP</formatName> </parameters> </node> </graph> baseCommand : [ gpt , calibration.xml ] inputs : polarization : inputBinding : position : 2 prefix : -PselPol= separate : false type : string safe : inputBinding : position : 2 prefix : -PinFile= separate : false type : Directory outputs : results : outputBinding : glob : . type : Directory stderr : std.err stdout : std.out cwlVersion : v1.0","title":"SNAP Graph inline"},{"location":"snap/snap-cwl/graph-inline/#snap-graph-inline","text":"CWL allows creating files using the InitialWorkDirRequirement : InitialWorkDirRequirement : listing : - entryname : graph.xml entry : |- The file graph.xml is created before executing the CommandLineTool. This approach is thus used to create the SNAP Graph with the content provided in the CWL document. This approach removes the File parameter used in the previous section and provides a self-standing CWL document: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 class : CommandLineTool id : sar-calibration requirements : DockerRequirement : dockerPull : snap-gpt EnvVarRequirement : envDef : PATH : /srv/conda/envs/env_snap/snap/bin:/usr/share/java/maven/bin:/usr/share/java/maven/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin ResourceRequirement : {} InitialWorkDirRequirement : listing : - entryname : calibration.xml entry : |- <graph id=\"Graph\"> <version>1.0</version> <node id=\"Read\"> <operator>Read</operator> <sources/> <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\"> <file>${inFile}</file> <formatName>SENTINEL-1</formatName> </parameters> </node> <node id=\"Calibration\"> <operator>Calibration</operator> <sources> <sourceProduct refid=\"Read\"/> </sources> <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\"> <sourceBands/> <auxFile>Product Auxiliary File</auxFile> <externalAuxFile/> <outputImageInComplex>false</outputImageInComplex> <outputImageScaleInDb>false</outputImageScaleInDb> <createGammaBand>false</createGammaBand> <createBetaBand>false</createBetaBand> <selectedPolarisations>${selPol}</selectedPolarisations> <outputSigmaBand>true</outputSigmaBand> <outputGammaBand>false</outputGammaBand> <outputBetaBand>false</outputBetaBand> </parameters> </node> <node id=\"Write\"> <operator>Write</operator> <sources> <sourceProduct refid=\"Calibration\"/> </sources> <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\"> <file>./cal.dim</file> <formatName>BEAM-DIMAP</formatName> </parameters> </node> </graph> baseCommand : [ gpt , calibration.xml ] inputs : polarization : inputBinding : position : 1 prefix : -PselPol= separate : false type : string safe : inputBinding : position : 2 prefix : -PinFile= separate : false type : Directory outputs : results : outputBinding : glob : . type : Directory stderr : std.err stdout : std.out cwlVersion : v1.0 The baseCommand is updated to add the calibration.xml argument: 54 55 56 57 58 </graph> baseCommand : [ gpt , calibration.xml ] inputs : The Workflow is updated accordingly: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 $graph : - class : Workflow id : main doc : SNAP Sentinel-1 GRD Calibration label : SNAP Sentinel-1 GRD Calibration inputs : polarization : doc : Polarization channel label : Polarization channel type : string safe : doc : Sentinel-1 GRD product SAFE Directory label : Sentinel-1 GRD product SAFE Directory type : Directory outputs : - id : wf_outputs outputSource : - node_1/results type : Directory requirements : SubworkflowFeatureRequirement : {} steps : node_1 : in : snap_graph : snap_graph polarization : polarization out : - results run : '#sar-calibration' - class : CommandLineTool id : sar-calibration requirements : DockerRequirement : dockerPull : snap-gpt EnvVarRequirement : envDef : PATH : /srv/conda/envs/env_snap/snap/bin:/usr/share/java/maven/bin:/usr/share/java/maven/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin ResourceRequirement : {} InitialWorkDirRequirement : listing : - entryname : calibration.xml entry : |- <graph id=\"Graph\"> <version>1.0</version> <node id=\"Read\"> <operator>Read</operator> <sources/> <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\"> <file>${inFile}</file> <formatName>SENTINEL-1</formatName> </parameters> </node> <node id=\"Calibration\"> <operator>Calibration</operator> <sources> <sourceProduct refid=\"Read\"/> </sources> <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\"> <sourceBands/> <auxFile>Product Auxiliary File</auxFile> <externalAuxFile/> <outputImageInComplex>false</outputImageInComplex> <outputImageScaleInDb>false</outputImageScaleInDb> <createGammaBand>false</createGammaBand> <createBetaBand>false</createBetaBand> <selectedPolarisations>${selPol}</selectedPolarisations> <outputSigmaBand>true</outputSigmaBand> <outputGammaBand>false</outputGammaBand> <outputBetaBand>false</outputBetaBand> </parameters> </node> <node id=\"Write\"> <operator>Write</operator> <sources> <sourceProduct refid=\"Calibration\"/> </sources> <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\"> <file>./cal.dim</file> <formatName>BEAM-DIMAP</formatName> </parameters> </node> </graph> baseCommand : [ gpt , calibration.xml ] inputs : polarization : inputBinding : position : 2 prefix : -PselPol= separate : false type : string safe : inputBinding : position : 2 prefix : -PinFile= separate : false type : Directory outputs : results : outputBinding : glob : . type : Directory stderr : std.err stdout : std.out cwlVersion : v1.0","title":"SNAP Graph inline"},{"location":"snap/snap-cwl/snap-cwl/","text":"Process SNAP graphs with CWL The described method targets processing Earth Observation data with the SNAP Graph Processing Tool (GPT) using docker and CWL. CWL is used to invoke the SNAP gpt command line tool and deals with all the docker volume mounts required to process a Graph and EO data available on the host. The examples rely on a simple SNAP graph applying the Calibration operator to a Sentinel-1 GRD acquisition: <graph id= \"Graph\" > <version> 1.0 </version> <node id= \"Read\" > <operator> Read </operator> <sources/> <parameters class= \"com.bc.ceres.binding.dom.XppDomElement\" > <file> ${inFile} </file> <formatName> SENTINEL-1 </formatName> </parameters> </node> <node id= \"Calibration\" > <operator> Calibration </operator> <sources> <sourceProduct refid= \"Read\" /> </sources> <parameters class= \"com.bc.ceres.binding.dom.XppDomElement\" > <sourceBands/> <auxFile> Product Auxiliary File </auxFile> <externalAuxFile/> <outputImageInComplex> false </outputImageInComplex> <outputImageScaleInDb> false </outputImageScaleInDb> <createGammaBand> false </createGammaBand> <createBetaBand> false </createBetaBand> <selectedPolarisations> ${selPol} </selectedPolarisations> <outputSigmaBand> true </outputSigmaBand> <outputGammaBand> false </outputGammaBand> <outputBetaBand> false </outputBetaBand> </parameters> </node> <node id= \"Write\" > <operator> Write </operator> <sources> <sourceProduct refid= \"Calibration\" /> </sources> <parameters class= \"com.bc.ceres.binding.dom.XppDomElement\" > <file> ./cal.dim </file> <formatName> BEAM-DIMAP </formatName> </parameters> </node> </graph> This SNAP graph contains parameters: ${inFile} is the path to the Sentinel-1 manifest.xml file. This parameter is used in the Read Operator ${selPol} is the selected polarization and thus leaving an option to process VV or VH (typically). This parameter is used in the Calibration Operator CWL is used to wrap the SNAP gpt executable: gpt sar-calibration.xml -PselPol=${selPol} -PinFile=${inFile} There are two approaches described to process this graph using CWL: The SNAP graph is a local file and thus passed to CWL as a File (as a reference) The SNAP graph XML content is part of the CWL (included as a value)","title":"SNAP with CWL"},{"location":"snap/snap-cwl/snap-cwl/#process-snap-graphs-with-cwl","text":"The described method targets processing Earth Observation data with the SNAP Graph Processing Tool (GPT) using docker and CWL. CWL is used to invoke the SNAP gpt command line tool and deals with all the docker volume mounts required to process a Graph and EO data available on the host. The examples rely on a simple SNAP graph applying the Calibration operator to a Sentinel-1 GRD acquisition: <graph id= \"Graph\" > <version> 1.0 </version> <node id= \"Read\" > <operator> Read </operator> <sources/> <parameters class= \"com.bc.ceres.binding.dom.XppDomElement\" > <file> ${inFile} </file> <formatName> SENTINEL-1 </formatName> </parameters> </node> <node id= \"Calibration\" > <operator> Calibration </operator> <sources> <sourceProduct refid= \"Read\" /> </sources> <parameters class= \"com.bc.ceres.binding.dom.XppDomElement\" > <sourceBands/> <auxFile> Product Auxiliary File </auxFile> <externalAuxFile/> <outputImageInComplex> false </outputImageInComplex> <outputImageScaleInDb> false </outputImageScaleInDb> <createGammaBand> false </createGammaBand> <createBetaBand> false </createBetaBand> <selectedPolarisations> ${selPol} </selectedPolarisations> <outputSigmaBand> true </outputSigmaBand> <outputGammaBand> false </outputGammaBand> <outputBetaBand> false </outputBetaBand> </parameters> </node> <node id= \"Write\" > <operator> Write </operator> <sources> <sourceProduct refid= \"Calibration\" /> </sources> <parameters class= \"com.bc.ceres.binding.dom.XppDomElement\" > <file> ./cal.dim </file> <formatName> BEAM-DIMAP </formatName> </parameters> </node> </graph> This SNAP graph contains parameters: ${inFile} is the path to the Sentinel-1 manifest.xml file. This parameter is used in the Read Operator ${selPol} is the selected polarization and thus leaving an option to process VV or VH (typically). This parameter is used in the Calibration Operator CWL is used to wrap the SNAP gpt executable: gpt sar-calibration.xml -PselPol=${selPol} -PinFile=${inFile} There are two approaches described to process this graph using CWL: The SNAP graph is a local file and thus passed to CWL as a File (as a reference) The SNAP graph XML content is part of the CWL (included as a value)","title":"Process SNAP graphs with CWL"},{"location":"stac/","text":"STAC CWL examples to consume STAC resources such as Element84 Sentinel-2 STAC items","title":"Introduction"},{"location":"stac/#stac","text":"CWL examples to consume STAC resources such as Element84 Sentinel-2 STAC items","title":"STAC"},{"location":"stac/sentinel-2-asset-resolution/","text":"Sentinel-2 asset resolution This CWL document takes an URL to a Sentinel-2 STAC Item and resolves the asset key provided as input parameter. It relies on curl and jq to get the STAC Item and parse its JSON content. CWL CommandLineTool The CWL document contains a CommandLineTool element that invoques the command: curl -s 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A' | jq '.assets.B8A.href' | tr -d '\"' The CWL document content is: class : CommandLineTool requirements : DockerRequirement : dockerPull : terradue/jq ShellCommandRequirement : {} InlineJavascriptRequirement : {} baseCommand : curl arguments : - -s - valueFrom : ${ return inputs.stac_item; } - \"|\" - jq - valueFrom : ${ return \".assets.\" + inputs.asset + \".href\"; } - \"|\" - tr - -d - '\\\"' #\\\"\" stdout : message inputs : stac_item : type : string asset : type : string outputs : asset_href : type : string outputBinding : glob : message loadContents : true outputEval : $( self[0].contents.split(\"\\n\").join(\"\") ) cwlVersion : v1.0 CWL Workflow The CommandLineTool above is now included in a single step Workflow : $graph : - class : Workflow label : Resolve STAC asset href doc : This workflow resolves a STAC asset href using its key id : main inputs : stac_item : type : string asset : type : string outputs : asset_href : outputSource : - node_stac/asset_href type : string steps : node_stac : run : \"#asset\" in : stac_item : stac_item asset : asset out : - asset_href - class : CommandLineTool id : asset requirements : DockerRequirement : dockerPull : terradue/jq ShellCommandRequirement : {} InlineJavascriptRequirement : {} baseCommand : curl arguments : - -s - valueFrom : ${ return inputs.stac_item; } - \"|\" - jq - valueFrom : ${ return \".assets.\" + inputs.asset + \".href\"; } - \"|\" - tr - -d - '\\\"' #\\\"\" stdout : message inputs : stac_item : type : string asset : type : string outputs : asset_href : type : string outputBinding : glob : message loadContents : true outputEval : $( self[0].contents.split(\"\\n\").join(\"\") ) cwlVersion : v1.0 Execution It may be run with the parameters: stac_item : \"https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A\" asset : \"B8A\" And: cwltool asset.cwl asset.yml The execution will generate: INFO /srv/conda/bin/cwltool 3.0.20210319143721 INFO Resolved 'asset.cwl' to 'file:///home/fbrito/work/stac/sentinel-2-asset-resolution/asset.cwl' INFO [workflow ] start INFO [workflow ] starting step node_stac INFO [step node_stac] start INFO [job node_stac] /tmp/baqarwll$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/baqarwll,target=/mvOEKM \\ --mount=type=bind,source=/tmp/hc2s_c5k,target=/tmp \\ --workdir=/mvOEKM \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/mvOEKM \\ --cidfile=/tmp/quxi1nlw/20210803134014-592685.cid \\ terradue/jq \\ /bin/sh \\ -c \\ 'curl' '-s' 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A' | 'jq' '.assets.B8A.href' | 'tr' '-d' \\\" > /tmp/baqarwll/message INFO [job node_stac] Max memory used: 0MiB INFO [job node_stac] completed success INFO [step node_stac] completed success INFO [workflow ] completed success { \"asset_href\": \"https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif\" } INFO Final process status is success","title":"Sentinel-2 asset resolution"},{"location":"stac/sentinel-2-asset-resolution/#sentinel-2-asset-resolution","text":"This CWL document takes an URL to a Sentinel-2 STAC Item and resolves the asset key provided as input parameter. It relies on curl and jq to get the STAC Item and parse its JSON content.","title":"Sentinel-2 asset resolution"},{"location":"stac/sentinel-2-asset-resolution/#cwl-commandlinetool","text":"The CWL document contains a CommandLineTool element that invoques the command: curl -s 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A' | jq '.assets.B8A.href' | tr -d '\"' The CWL document content is: class : CommandLineTool requirements : DockerRequirement : dockerPull : terradue/jq ShellCommandRequirement : {} InlineJavascriptRequirement : {} baseCommand : curl arguments : - -s - valueFrom : ${ return inputs.stac_item; } - \"|\" - jq - valueFrom : ${ return \".assets.\" + inputs.asset + \".href\"; } - \"|\" - tr - -d - '\\\"' #\\\"\" stdout : message inputs : stac_item : type : string asset : type : string outputs : asset_href : type : string outputBinding : glob : message loadContents : true outputEval : $( self[0].contents.split(\"\\n\").join(\"\") ) cwlVersion : v1.0","title":"CWL CommandLineTool"},{"location":"stac/sentinel-2-asset-resolution/#cwl-workflow","text":"The CommandLineTool above is now included in a single step Workflow : $graph : - class : Workflow label : Resolve STAC asset href doc : This workflow resolves a STAC asset href using its key id : main inputs : stac_item : type : string asset : type : string outputs : asset_href : outputSource : - node_stac/asset_href type : string steps : node_stac : run : \"#asset\" in : stac_item : stac_item asset : asset out : - asset_href - class : CommandLineTool id : asset requirements : DockerRequirement : dockerPull : terradue/jq ShellCommandRequirement : {} InlineJavascriptRequirement : {} baseCommand : curl arguments : - -s - valueFrom : ${ return inputs.stac_item; } - \"|\" - jq - valueFrom : ${ return \".assets.\" + inputs.asset + \".href\"; } - \"|\" - tr - -d - '\\\"' #\\\"\" stdout : message inputs : stac_item : type : string asset : type : string outputs : asset_href : type : string outputBinding : glob : message loadContents : true outputEval : $( self[0].contents.split(\"\\n\").join(\"\") ) cwlVersion : v1.0","title":"CWL Workflow"},{"location":"stac/sentinel-2-asset-resolution/#execution","text":"It may be run with the parameters: stac_item : \"https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A\" asset : \"B8A\" And: cwltool asset.cwl asset.yml The execution will generate: INFO /srv/conda/bin/cwltool 3.0.20210319143721 INFO Resolved 'asset.cwl' to 'file:///home/fbrito/work/stac/sentinel-2-asset-resolution/asset.cwl' INFO [workflow ] start INFO [workflow ] starting step node_stac INFO [step node_stac] start INFO [job node_stac] /tmp/baqarwll$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/baqarwll,target=/mvOEKM \\ --mount=type=bind,source=/tmp/hc2s_c5k,target=/tmp \\ --workdir=/mvOEKM \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/mvOEKM \\ --cidfile=/tmp/quxi1nlw/20210803134014-592685.cid \\ terradue/jq \\ /bin/sh \\ -c \\ 'curl' '-s' 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A' | 'jq' '.assets.B8A.href' | 'tr' '-d' \\\" > /tmp/baqarwll/message INFO [job node_stac] Max memory used: 0MiB INFO [job node_stac] completed success INFO [step node_stac] completed success INFO [workflow ] completed success { \"asset_href\": \"https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif\" } INFO Final process status is success","title":"Execution"},{"location":"workflows/sentinel-2-nbr/","text":"Sentinel-2 Normalized Burn Ratio (NBR) The goal is to produce a Sentinel-2 NBR geotif using CWl to orchestrate gdal and OTB. The processing steps are: use gdal_translate to clip the COG over the area of interest expressed as a bounding box for the NIR, SWIR22 and Scene Classification use OTB's otbcli_BandMathX to do the band arithmetic and generate the NBR Data used The data used are Sentinel-2 products that were converted to COG and STAC and published on publicly accessible URLs. Inputs The inputs are: A Sentinel-2 STAC Item URL An area of interest expressed as a bounding box Steps STAC asset href resolution NBR requires the NIR, SWIR Sentinel-2 assets and we'll use the Scene Classification to process the normalized burn ratio only over valid pixels (e.g. avoid clouds, water, etc.). The first workflow step is getting the B8A (NIR), B12 (SWIR22) and the Scene Classification hrefs. This is done with the CWL CommandLineTool available in the asset.cwl file: class : CommandLineTool requirements : DockerRequirement : dockerPull : terradue/jq ShellCommandRequirement : {} InlineJavascriptRequirement : {} baseCommand : curl arguments : - -s - valueFrom : ${ return inputs.stac_item; } - \"|\" - jq - valueFrom : ${ return \".assets.\" + inputs.asset + \".href\"; } - \"|\" - tr - -d - '\\\"' #\\\"\" stdout : message inputs : stac_item : type : string asset : type : string outputs : asset_href : type : string outputBinding : glob : message loadContents : true outputEval : $( self[0].contents.split(\"\\n\").join(\"\") ) cwlVersion : v1.0 Extract the data over the area of interest gdal_translate can take VSI URLs as input and extract an area of interest. This step takes the resolved STAC assets href and produces clips of the original Sentinel-2 acquisition. This is achieved with the CWL CommandLineTool available in the translate.cwl file: class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - valueFrom : ${ return inputs.epsg; } - valueFrom : | ${ if (inputs.asset.startsWith(\"http\")) { return \"/vsicurl/\" + inputs.asset; } else { return inputs.asset; } } - valueFrom : ${ return inputs.asset.split(\"/\").slice(-1)[0]; } inputs : asset : type : string bbox : type : string epsg : type : string default : \"EPSG:4326\" outputs : tifs : outputBinding : glob : '*.tif' type : File cwlVersion : v1.0 Normalized difference using the clipped tifs. The final step uses OTB's otbcli_BandMathX to do the band arithmetic and generate the NBR. The CWl CommandLineTool to accomplish that is available in the band_math.cwl file: class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : terradue/otb-7.2.0 baseCommand : otbcli_BandMathX arguments : - -out - valueFrom : ${ return inputs.stac_item.split(\"/\").slice(-1)[0] + \".tif\"; } - -exp - '(im3b1 == 8 or im3b1 == 9 or im3b1 == 0 or im3b1 == 1 or im3b1 == 2 or im3b1 == 10 or im3b1 == 11) ? -2 : (im1b1 - im2b1) / (im1b1 + im2b1)' inputs : tifs : type : File[] inputBinding : position : 5 prefix : -il separate : true stac_item : type : string outputs : nbr : outputBinding : glob : \"*.tif\" type : File cwlVersion : v1.0 Putting the pieces together The single CWL documents encapsulating the different steps of the final workflow are orchestrated as CWL Workflow . class : Workflow label : NBR - produce the normalized difference between NIR and SWIR 22 doc : NBR - produce the normalized difference between NIR and SWIR 22 id : main requirements : - class : ScatterFeatureRequirement inputs : stac_item : doc : Sentinel-2 item type : string aoi : doc : area of interest as a bounding box type : string bands : type : string[] default : [ \"B8A\" , \"B12\" , \"SCL\" ] outputs : nbr : outputSource : - node_nbr/nbr type : File steps : node_stac : run : asset.cwl in : stac_item : stac_item asset : bands out : - asset_href scatter : asset scatterMethod : dotproduct node_subset : run : translate.cwl in : asset : source : node_stac/asset_href bbox : aoi out : - tifs scatter : asset scatterMethod : dotproduct node_nbr : run : band_math.cwl in : stac_item : stac_item tifs : source : [ node_subset/tifs ] out : - nbr cwlVersion : v1.0 The workflow uses CWL's ScatterFeatureRequirement to run some of the steps in parallel: Each asset is resolved as an individual process Each gdal_translate is invoked individually The final node aggregates the inputs into a the NBR product. This CWL Workflow can be invoked with the parameters: stac_item : \"https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A\" aoi : \"136.659,-35.96,136.923,-35.791\" And using cwltool : cwltool --parallel nbr.cwl nbr.yml This will output: INFO /srv/conda/bin/cwltool 3.0.20210319143721 INFO Resolved 'nbr.cwl' to 'file:///home/fbrito/work/sentinel-2-nbr/nbr.cwl' INFO [workflow ] starting step node_stac INFO [step node_stac] start INFO [workflow ] start INFO [step node_stac] start INFO [step node_stac] start INFO [job node_stac] /tmp/6z7ooxq4$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/6z7ooxq4,target=/AHORGP \\ --mount=type=bind,source=/tmp/fxfeqivt,target=/tmp \\ --workdir=/AHORGP \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/AHORGP \\ --cidfile=/tmp/36mv9qqs/20210803131208-777472.cid \\ terradue/jq \\ /bin/sh \\ -c \\ 'curl' '-s' 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A' | 'jq' '.assets.B8A.href' | 'tr' '-d' \\\" > /tmp/6z7ooxq4/message INFO [job node_stac_2] /tmp/lukn7xa_$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/lukn7xa_,target=/AHORGP \\ --mount=type=bind,source=/tmp/j3ojpzbw,target=/tmp \\ --workdir=/AHORGP \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/AHORGP \\ --cidfile=/tmp/2pbnjsek/20210803131208-803455.cid \\ terradue/jq \\ /bin/sh \\ -c \\ 'curl' '-s' 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A' | 'jq' '.assets.B12.href' | 'tr' '-d' \\\" > /tmp/lukn7xa_/message INFO [job node_stac_3] /tmp/8susbghr$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/8susbghr,target=/AHORGP \\ --mount=type=bind,source=/tmp/w3eo95ll,target=/tmp \\ --workdir=/AHORGP \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/AHORGP \\ --cidfile=/tmp/wgl0e8p6/20210803131208-816645.cid \\ terradue/jq \\ /bin/sh \\ -c \\ 'curl' '-s' 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A' | 'jq' '.assets.SCL.href' | 'tr' '-d' \\\" > /tmp/8susbghr/message INFO [job node_stac] Max memory used: 0MiB INFO [job node_stac_3] Max memory used: 0MiB INFO [job node_stac_2] Max memory used: 0MiB INFO [job node_stac] completed success INFO [job node_stac_3] completed success INFO [job node_stac_2] completed success INFO [step node_stac] completed success INFO [workflow ] starting step node_subset INFO [step node_subset] start INFO [step node_subset] start INFO [step node_subset] start INFO [job node_subset] /tmp/354unm3n$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/354unm3n,target=/AHORGP \\ --mount=type=bind,source=/tmp/rna17u4f,target=/tmp \\ --workdir=/AHORGP \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/AHORGP \\ --cidfile=/tmp/bu2jkwzt/20210803131211-498283.cid \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 136.659 \\ -35.791 \\ 136.923 \\ -35.96 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif \\ B8A.tif INFO [job node_subset_2] /tmp/4wetamd3$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/4wetamd3,target=/AHORGP \\ --mount=type=bind,source=/tmp/lb07hcp3,target=/tmp \\ --workdir=/AHORGP \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/AHORGP \\ --cidfile=/tmp/op_rhfej/20210803131211-569257.cid \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 136.659 \\ -35.791 \\ 136.923 \\ -35.96 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B12.tif \\ B12.tif INFO [job node_subset_3] /tmp/zd2y8jwn$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/zd2y8jwn,target=/AHORGP \\ --mount=type=bind,source=/tmp/vr39h9nm,target=/tmp \\ --workdir=/AHORGP \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/AHORGP \\ --cidfile=/tmp/3yl71gjr/20210803131211-604042.cid \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 136.659 \\ -35.791 \\ 136.923 \\ -35.96 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/SCL.tif \\ SCL.tif Input file size is 5490, 5490 0Input file size is 5490, 5490 0Input file size is 5490, 5490 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_subset_3] Max memory used: 19MiB INFO [job node_subset_3] completed success ...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_subset] Max memory used: 25MiB INFO [job node_subset] completed success ...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_subset_2] Max memory used: 25MiB INFO [job node_subset_2] completed success INFO [step node_subset] completed success INFO [workflow ] starting step node_nbr INFO [step node_nbr] start INFO [job node_nbr] /tmp/ufuo4sxs$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/ufuo4sxs,target=/AHORGP \\ --mount=type=bind,source=/tmp/85nzo8d3,target=/tmp \\ --mount=type=bind,source=/tmp/354unm3n/B8A.tif,target=/var/lib/cwl/stg68264295-cc93-4bd9-989f-7c8c5fe1d55b/B8A.tif,readonly \\ --mount=type=bind,source=/tmp/4wetamd3/B12.tif,target=/var/lib/cwl/stg38a3dc1d-5b7e-4ed9-aff5-42564f25ca03/B12.tif,readonly \\ --mount=type=bind,source=/tmp/zd2y8jwn/SCL.tif,target=/var/lib/cwl/stg89b3a6a0-9c1d-4d16-bae9-1dfa1da681a5/SCL.tif,readonly \\ --workdir=/AHORGP \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/AHORGP \\ --cidfile=/tmp/hzj6lygr/20210803131224-614651.cid \\ terradue/otb-7.2.0 \\ otbcli_BandMathX \\ -out \\ S2B_53HPA_20210723_0_L2A.tif \\ -exp \\ '(im3b1 == 8 or im3b1 == 9 or im3b1 == 0 or im3b1 == 1 or im3b1 == 2 or im3b1 == 10 or im3b1 == 11) ? -2 : (im1b1 - im2b1) / (im1b1 + im2b1)' \\ -il \\ /var/lib/cwl/stg68264295-cc93-4bd9-989f-7c8c5fe1d55b/B8A.tif \\ /var/lib/cwl/stg38a3dc1d-5b7e-4ed9-aff5-42564f25ca03/B12.tif \\ /var/lib/cwl/stg89b3a6a0-9c1d-4d16-bae9-1dfa1da681a5/SCL.tif 2021-08-03 11:12:24 (INFO) BandMathX: Default RAM limit for OTB is 256 MB 2021-08-03 11:12:24 (INFO) BandMathX: GDAL maximum cache size is 3197 MB 2021-08-03 11:12:24 (INFO) BandMathX: OTB will use at most 16 threads 2021-08-03 11:12:24 (INFO) BandMathX: Image #1 has 1 components 2021-08-03 11:12:24 (INFO) BandMathX: Image #2 has 1 components 2021-08-03 11:12:24 (INFO) BandMathX: Image #3 has 1 components 2021-08-03 11:12:24 (INFO) BandMathX: Using expression: (im3b1 == 8 or im3b1 == 9 or im3b1 == 0 or im3b1 == 1 or im3b1 == 2 or im3b1 == 10 or im3b1 == 11) ? -2 : (im1b1 - im2b1) / (im1b1 + im2b1) 2021-08-03 11:12:24 (INFO): Estimated memory for full processing: 21.4543MB (avail.: 256 MB), optimal image partitioning: 1 blocks 2021-08-03 11:12:24 (INFO): File S2B_53HPA_20210723_0_L2A.tif will be written in 1 blocks of 1175x959 pixels Writing S2B_53HPA_20210723_0_L2A.tif...: 100% [**************************************************] (0s) INFO [job node_nbr] Max memory used: 0MiB INFO [job node_nbr] completed success INFO [step node_nbr] completed success INFO [workflow ] completed success { \"nbr\": { \"location\": \"file:///home/fbrito/work/sentinel-2-nbr/S2B_53HPA_20210723_0_L2A.tif\", \"basename\": \"S2B_53HPA_20210723_0_L2A.tif\", \"class\": \"File\", \"checksum\": \"sha1$62ca971658766d3a8c0e975fce87ce850ce5f180\", \"size\": 4515438, \"path\": \"/home/fbrito/work/sentinel-2-nbr/S2B_53HPA_20210723_0_L2A.tif\" } } INFO Final process status is success","title":"Sentinel-2 NBR"},{"location":"workflows/sentinel-2-nbr/#sentinel-2-normalized-burn-ratio-nbr","text":"The goal is to produce a Sentinel-2 NBR geotif using CWl to orchestrate gdal and OTB. The processing steps are: use gdal_translate to clip the COG over the area of interest expressed as a bounding box for the NIR, SWIR22 and Scene Classification use OTB's otbcli_BandMathX to do the band arithmetic and generate the NBR","title":"Sentinel-2 Normalized Burn Ratio (NBR)"},{"location":"workflows/sentinel-2-nbr/#data-used","text":"The data used are Sentinel-2 products that were converted to COG and STAC and published on publicly accessible URLs.","title":"Data used"},{"location":"workflows/sentinel-2-nbr/#inputs","text":"The inputs are: A Sentinel-2 STAC Item URL An area of interest expressed as a bounding box","title":"Inputs"},{"location":"workflows/sentinel-2-nbr/#steps","text":"","title":"Steps"},{"location":"workflows/sentinel-2-nbr/#stac-asset-href-resolution","text":"NBR requires the NIR, SWIR Sentinel-2 assets and we'll use the Scene Classification to process the normalized burn ratio only over valid pixels (e.g. avoid clouds, water, etc.). The first workflow step is getting the B8A (NIR), B12 (SWIR22) and the Scene Classification hrefs. This is done with the CWL CommandLineTool available in the asset.cwl file: class : CommandLineTool requirements : DockerRequirement : dockerPull : terradue/jq ShellCommandRequirement : {} InlineJavascriptRequirement : {} baseCommand : curl arguments : - -s - valueFrom : ${ return inputs.stac_item; } - \"|\" - jq - valueFrom : ${ return \".assets.\" + inputs.asset + \".href\"; } - \"|\" - tr - -d - '\\\"' #\\\"\" stdout : message inputs : stac_item : type : string asset : type : string outputs : asset_href : type : string outputBinding : glob : message loadContents : true outputEval : $( self[0].contents.split(\"\\n\").join(\"\") ) cwlVersion : v1.0","title":"STAC asset href resolution"},{"location":"workflows/sentinel-2-nbr/#extract-the-data-over-the-area-of-interest","text":"gdal_translate can take VSI URLs as input and extract an area of interest. This step takes the resolved STAC assets href and produces clips of the original Sentinel-2 acquisition. This is achieved with the CWL CommandLineTool available in the translate.cwl file: class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : osgeo/gdal baseCommand : gdal_translate arguments : - -projwin - valueFrom : ${ return inputs.bbox.split(\",\")[0]; } - valueFrom : ${ return inputs.bbox.split(\",\")[3]; } - valueFrom : ${ return inputs.bbox.split(\",\")[2]; } - valueFrom : ${ return inputs.bbox.split(\",\")[1]; } - -projwin_srs - valueFrom : ${ return inputs.epsg; } - valueFrom : | ${ if (inputs.asset.startsWith(\"http\")) { return \"/vsicurl/\" + inputs.asset; } else { return inputs.asset; } } - valueFrom : ${ return inputs.asset.split(\"/\").slice(-1)[0]; } inputs : asset : type : string bbox : type : string epsg : type : string default : \"EPSG:4326\" outputs : tifs : outputBinding : glob : '*.tif' type : File cwlVersion : v1.0","title":"Extract the data over the area of interest"},{"location":"workflows/sentinel-2-nbr/#normalized-difference-using-the-clipped-tifs","text":"The final step uses OTB's otbcli_BandMathX to do the band arithmetic and generate the NBR. The CWl CommandLineTool to accomplish that is available in the band_math.cwl file: class : CommandLineTool requirements : InlineJavascriptRequirement : {} DockerRequirement : dockerPull : terradue/otb-7.2.0 baseCommand : otbcli_BandMathX arguments : - -out - valueFrom : ${ return inputs.stac_item.split(\"/\").slice(-1)[0] + \".tif\"; } - -exp - '(im3b1 == 8 or im3b1 == 9 or im3b1 == 0 or im3b1 == 1 or im3b1 == 2 or im3b1 == 10 or im3b1 == 11) ? -2 : (im1b1 - im2b1) / (im1b1 + im2b1)' inputs : tifs : type : File[] inputBinding : position : 5 prefix : -il separate : true stac_item : type : string outputs : nbr : outputBinding : glob : \"*.tif\" type : File cwlVersion : v1.0","title":"Normalized difference using the clipped tifs."},{"location":"workflows/sentinel-2-nbr/#putting-the-pieces-together","text":"The single CWL documents encapsulating the different steps of the final workflow are orchestrated as CWL Workflow . class : Workflow label : NBR - produce the normalized difference between NIR and SWIR 22 doc : NBR - produce the normalized difference between NIR and SWIR 22 id : main requirements : - class : ScatterFeatureRequirement inputs : stac_item : doc : Sentinel-2 item type : string aoi : doc : area of interest as a bounding box type : string bands : type : string[] default : [ \"B8A\" , \"B12\" , \"SCL\" ] outputs : nbr : outputSource : - node_nbr/nbr type : File steps : node_stac : run : asset.cwl in : stac_item : stac_item asset : bands out : - asset_href scatter : asset scatterMethod : dotproduct node_subset : run : translate.cwl in : asset : source : node_stac/asset_href bbox : aoi out : - tifs scatter : asset scatterMethod : dotproduct node_nbr : run : band_math.cwl in : stac_item : stac_item tifs : source : [ node_subset/tifs ] out : - nbr cwlVersion : v1.0 The workflow uses CWL's ScatterFeatureRequirement to run some of the steps in parallel: Each asset is resolved as an individual process Each gdal_translate is invoked individually The final node aggregates the inputs into a the NBR product. This CWL Workflow can be invoked with the parameters: stac_item : \"https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A\" aoi : \"136.659,-35.96,136.923,-35.791\" And using cwltool : cwltool --parallel nbr.cwl nbr.yml This will output: INFO /srv/conda/bin/cwltool 3.0.20210319143721 INFO Resolved 'nbr.cwl' to 'file:///home/fbrito/work/sentinel-2-nbr/nbr.cwl' INFO [workflow ] starting step node_stac INFO [step node_stac] start INFO [workflow ] start INFO [step node_stac] start INFO [step node_stac] start INFO [job node_stac] /tmp/6z7ooxq4$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/6z7ooxq4,target=/AHORGP \\ --mount=type=bind,source=/tmp/fxfeqivt,target=/tmp \\ --workdir=/AHORGP \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/AHORGP \\ --cidfile=/tmp/36mv9qqs/20210803131208-777472.cid \\ terradue/jq \\ /bin/sh \\ -c \\ 'curl' '-s' 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A' | 'jq' '.assets.B8A.href' | 'tr' '-d' \\\" > /tmp/6z7ooxq4/message INFO [job node_stac_2] /tmp/lukn7xa_$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/lukn7xa_,target=/AHORGP \\ --mount=type=bind,source=/tmp/j3ojpzbw,target=/tmp \\ --workdir=/AHORGP \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/AHORGP \\ --cidfile=/tmp/2pbnjsek/20210803131208-803455.cid \\ terradue/jq \\ /bin/sh \\ -c \\ 'curl' '-s' 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A' | 'jq' '.assets.B12.href' | 'tr' '-d' \\\" > /tmp/lukn7xa_/message INFO [job node_stac_3] /tmp/8susbghr$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/8susbghr,target=/AHORGP \\ --mount=type=bind,source=/tmp/w3eo95ll,target=/tmp \\ --workdir=/AHORGP \\ --read-only=true \\ --log-driver=none \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/AHORGP \\ --cidfile=/tmp/wgl0e8p6/20210803131208-816645.cid \\ terradue/jq \\ /bin/sh \\ -c \\ 'curl' '-s' 'https://earth-search.aws.element84.com/v0/collections/sentinel-s2-l2a-cogs/items/S2B_53HPA_20210723_0_L2A' | 'jq' '.assets.SCL.href' | 'tr' '-d' \\\" > /tmp/8susbghr/message INFO [job node_stac] Max memory used: 0MiB INFO [job node_stac_3] Max memory used: 0MiB INFO [job node_stac_2] Max memory used: 0MiB INFO [job node_stac] completed success INFO [job node_stac_3] completed success INFO [job node_stac_2] completed success INFO [step node_stac] completed success INFO [workflow ] starting step node_subset INFO [step node_subset] start INFO [step node_subset] start INFO [step node_subset] start INFO [job node_subset] /tmp/354unm3n$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/354unm3n,target=/AHORGP \\ --mount=type=bind,source=/tmp/rna17u4f,target=/tmp \\ --workdir=/AHORGP \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/AHORGP \\ --cidfile=/tmp/bu2jkwzt/20210803131211-498283.cid \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 136.659 \\ -35.791 \\ 136.923 \\ -35.96 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B8A.tif \\ B8A.tif INFO [job node_subset_2] /tmp/4wetamd3$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/4wetamd3,target=/AHORGP \\ --mount=type=bind,source=/tmp/lb07hcp3,target=/tmp \\ --workdir=/AHORGP \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/AHORGP \\ --cidfile=/tmp/op_rhfej/20210803131211-569257.cid \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 136.659 \\ -35.791 \\ 136.923 \\ -35.96 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B12.tif \\ B12.tif INFO [job node_subset_3] /tmp/zd2y8jwn$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/zd2y8jwn,target=/AHORGP \\ --mount=type=bind,source=/tmp/vr39h9nm,target=/tmp \\ --workdir=/AHORGP \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/AHORGP \\ --cidfile=/tmp/3yl71gjr/20210803131211-604042.cid \\ osgeo/gdal \\ gdal_translate \\ -projwin \\ 136.659 \\ -35.791 \\ 136.923 \\ -35.96 \\ -projwin_srs \\ EPSG:4326 \\ /vsicurl/https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/SCL.tif \\ SCL.tif Input file size is 5490, 5490 0Input file size is 5490, 5490 0Input file size is 5490, 5490 0...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_subset_3] Max memory used: 19MiB INFO [job node_subset_3] completed success ...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_subset] Max memory used: 25MiB INFO [job node_subset] completed success ...10...20...30...40...50...60...70...80...90...100 - done. INFO [job node_subset_2] Max memory used: 25MiB INFO [job node_subset_2] completed success INFO [step node_subset] completed success INFO [workflow ] starting step node_nbr INFO [step node_nbr] start INFO [job node_nbr] /tmp/ufuo4sxs$ docker \\ run \\ -i \\ --mount=type=bind,source=/tmp/ufuo4sxs,target=/AHORGP \\ --mount=type=bind,source=/tmp/85nzo8d3,target=/tmp \\ --mount=type=bind,source=/tmp/354unm3n/B8A.tif,target=/var/lib/cwl/stg68264295-cc93-4bd9-989f-7c8c5fe1d55b/B8A.tif,readonly \\ --mount=type=bind,source=/tmp/4wetamd3/B12.tif,target=/var/lib/cwl/stg38a3dc1d-5b7e-4ed9-aff5-42564f25ca03/B12.tif,readonly \\ --mount=type=bind,source=/tmp/zd2y8jwn/SCL.tif,target=/var/lib/cwl/stg89b3a6a0-9c1d-4d16-bae9-1dfa1da681a5/SCL.tif,readonly \\ --workdir=/AHORGP \\ --read-only=true \\ --user=1000:1000 \\ --rm \\ --env=TMPDIR=/tmp \\ --env=HOME=/AHORGP \\ --cidfile=/tmp/hzj6lygr/20210803131224-614651.cid \\ terradue/otb-7.2.0 \\ otbcli_BandMathX \\ -out \\ S2B_53HPA_20210723_0_L2A.tif \\ -exp \\ '(im3b1 == 8 or im3b1 == 9 or im3b1 == 0 or im3b1 == 1 or im3b1 == 2 or im3b1 == 10 or im3b1 == 11) ? -2 : (im1b1 - im2b1) / (im1b1 + im2b1)' \\ -il \\ /var/lib/cwl/stg68264295-cc93-4bd9-989f-7c8c5fe1d55b/B8A.tif \\ /var/lib/cwl/stg38a3dc1d-5b7e-4ed9-aff5-42564f25ca03/B12.tif \\ /var/lib/cwl/stg89b3a6a0-9c1d-4d16-bae9-1dfa1da681a5/SCL.tif 2021-08-03 11:12:24 (INFO) BandMathX: Default RAM limit for OTB is 256 MB 2021-08-03 11:12:24 (INFO) BandMathX: GDAL maximum cache size is 3197 MB 2021-08-03 11:12:24 (INFO) BandMathX: OTB will use at most 16 threads 2021-08-03 11:12:24 (INFO) BandMathX: Image #1 has 1 components 2021-08-03 11:12:24 (INFO) BandMathX: Image #2 has 1 components 2021-08-03 11:12:24 (INFO) BandMathX: Image #3 has 1 components 2021-08-03 11:12:24 (INFO) BandMathX: Using expression: (im3b1 == 8 or im3b1 == 9 or im3b1 == 0 or im3b1 == 1 or im3b1 == 2 or im3b1 == 10 or im3b1 == 11) ? -2 : (im1b1 - im2b1) / (im1b1 + im2b1) 2021-08-03 11:12:24 (INFO): Estimated memory for full processing: 21.4543MB (avail.: 256 MB), optimal image partitioning: 1 blocks 2021-08-03 11:12:24 (INFO): File S2B_53HPA_20210723_0_L2A.tif will be written in 1 blocks of 1175x959 pixels Writing S2B_53HPA_20210723_0_L2A.tif...: 100% [**************************************************] (0s) INFO [job node_nbr] Max memory used: 0MiB INFO [job node_nbr] completed success INFO [step node_nbr] completed success INFO [workflow ] completed success { \"nbr\": { \"location\": \"file:///home/fbrito/work/sentinel-2-nbr/S2B_53HPA_20210723_0_L2A.tif\", \"basename\": \"S2B_53HPA_20210723_0_L2A.tif\", \"class\": \"File\", \"checksum\": \"sha1$62ca971658766d3a8c0e975fce87ce850ce5f180\", \"size\": 4515438, \"path\": \"/home/fbrito/work/sentinel-2-nbr/S2B_53HPA_20210723_0_L2A.tif\" } } INFO Final process status is success","title":"Putting the pieces together"}]}